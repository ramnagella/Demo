{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramnagella/Demo/blob/master/Data_Analysis_Roles_basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Data analysis with Python\n",
        "#---Data Analyst,Data scintist/M L engineer,Data Engineer,AI Engineer,---Roles and Responsibilities\n",
        "#Data Analysis Tools\n",
        "#Data Analyst----Ex--Swiggy ,Zomato--Problem definition--recomendations--recomend releveant food options to the users--\n",
        "#----------------Data Aquition---Collection,deom different sources\n",
        "#----------------Data Cleaning and Preparation---Handling missing values ,formatting inconstancies ,Remocing errors\n",
        "#----------------EDA---identify Trends ,patterns--Analysing the data,relationships,different categories 70% will use this\n",
        "#----------------Statistical methods*mean,mode),data visualisation techniques(report)\n",
        "#----------------Predicstion some times for creating model only (20%),\n",
        "#----------------Dash boards using power BI,Tableu,data story telling /insights,reports\n",
        "#----------------offline engineer\n",
        "#----------------"
      ],
      "metadata": {
        "id": "FTz630iPmvwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Engineer ---Realtime infrastrucure ---ETL---\n",
        "#-----------------System design and design nuild data pipelines ---ingest the real time data streams\n",
        "#-----------------What is the Soutce and target of data,\n",
        "#-----------------data ingestion--Real time data on swiggy or zomato orders--Restaurant avilability for delivery\n",
        "#-----------------Collect the real time data\n",
        "#-----------------Data transformation ----Whether need apply any business logic for the columns or tables\n",
        "#-----------------As per the business requirement it will be loaded into the target tables\n",
        "#-----------------Data Transformation--Format suitable for our requirement (like what is there in the restaurant for break fast and lunch)\n",
        "#-----------------Format suitable for our analysis and itegration with other systems\n",
        "#-----------------Foramt like horizontal to vertical or vertical to horizontal, only few field ssitale for analysis\n",
        "#-----------------Data filtering,aggregation,normalization,storing\n",
        "#-----------------Storing or loadig the final transformed data --into target source\n",
        "#-----------------Data quality monitoring --identify any issues with data ingestion  or processing\n",
        "#-----------------"
      ],
      "metadata": {
        "id": "y1gjwYo9n_Lf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Scientist and ML Engineer\n",
        "#-------Combined role ,recommendation engine,predction.\n",
        "#-------Data analyst will give the problem defintion to the DS and M engineer\n",
        "#-------For Example in apparal retail business DA will give the info like top selling product ,\n",
        "#-------top sellers ,top performing stores,in how many days the particular product going to sold out so tha they can bromng more products in time\n",
        "#-------inventory recoimendation.\n",
        "#-------DA will gkive problem defintion to the DS and ML nehineer\n",
        "#-------DS amd ML engineer will refine the problem based DA insights and business goals\n",
        "#-------Pizza recomendation problem .Already DA prepared problem defintion ..\n",
        "#------DS will consoder business goals also and refines the problem defintion.\n",
        "#------Prepare the data for model creation and prepare the data to improve the model perfomance\n",
        "#------Model seletction and training --again and again the train the model to improve and accuracy also improves\n",
        "#------Like attemptng many model papers for preapring competetive exams\n",
        "#------Model evalaution ---Evaluate the performance of the model on unseen data--Improving the performance of the model\n",
        "#------Model deployment and monitoring into the (Ex Swiggy App)\n",
        "#-----Refine the problem,data preparation,Mocdel selection and training,Nodel Evaluation,Model Deployment\n"
      ],
      "metadata": {
        "id": "YNhmlhfFn-zA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#AI Engineer\n",
        "#------If you want to add additional features like NLP,FenAI,Virtual assistant,chatbot(old),Open CV tool,Face detection\n",
        "#------Face tracking ,attendance system\n",
        "#"
      ],
      "metadata": {
        "id": "Z-s4jy2ji-An"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DA (data Analysis)\n",
        "#Comprehensive method of incpecting,cleaning,transforming ,Modelling ,draw Conclusion,decision making\n",
        "#Reporting,Storing telling usning Tableu,Power BI ,support decision making ,Predict trends,inprove operational efficiency\n",
        "#Strategic planning in business ex e -commerce company buyers behaviour ,prefrences, way of oredering is  patren is approach\n",
        "#forecast sales,customer exp ,market strategies\n",
        "# DA Process----EX Voting system of India---Objective Why people are not voting in AP and Larnataka\n",
        "#Means define ojective First---and questions in clear manner.Analysis going to answer\n",
        "#Like how many people voted for NOTA,How many people are there diff age groups\n",
        "#--People from village ---towns,cities,educated ,uneduucated,day of voting like summer ,winter\n",
        "#how many people living above 70 yrs,60 yrs\n",
        "#understand the problem,objective  ,based on objective formulate qestions\n",
        "#2 Step::--Data Collection from diff sources,methods,service ,interviews ,observation,extract from existing data\n",
        "#---------Data may be numerical\n",
        "#3 STEP::;---Data Cleaning ,very IMP because lot of errors ,inconsistancies corrections,Quality and reliability of the data\n",
        "#4 STEP::--Data Analysis---Identify trends,patterns,relationships,statistical methods (mean,mode)\n",
        "#5 STEP:::---Data interpretation and visualisation\n",
        "# 6 STEP::: Data story telling ,reports,dashboards---for non-techincal gys to understand better\n",
        "#---Python,GO,R language,Excel,SQl (Programming Languages),numpy,pandas,seaborn,scikitlearn,matplotlib,scipy\n",
        "#pytorch,tensor flow,keras--for DL,pyspark--data bricks\n",
        "#Pandas spports single node ,pyspark multinode for processing the data\n",
        "#Visualsing tools ---Power BI,Tableu,Click View,AWS Quick sight\n",
        "#Types of DA----purpose s nique and everything is not same\n",
        "#---1 Descriptive analysis 2 diagnistic ,predictive analytics,Prescriptive\n",
        "#1----What happened so far--raw data ,like summarisation ,historical data--ex---avh monthly sales of last year\n",
        "#2----Why did it happened---why some thing happened,dales dropped last year why--reason\n",
        "#3---Predictive --Waht will heppen---statistical models ,graphs,based on past data predict fture ,risk assessment,marketi ng ,sales forecasting\n",
        "#4---how we can make it happen---most adv type DA ---give suggestons, actionss to benifit from these predictions,best marketing strategies\n",
        "#---how we can make it happen\n",
        "# 1 and 2 will be done by DA,, 3 one is done ML and DA 4 th one is DS"
      ],
      "metadata": {
        "id": "J12WFBiDkFOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!7-07---After Roles Session\n",
        "#DA techiniques ---EDA--Missing data,test assumptions,visualize the data.\n",
        "#Regression Analsis --Statistical methods--Model,understand the relationship netween variables,time series modellimg\n",
        "#Factor Analysis ---Image recognition,R mostly uses ,python is less,  Like reducing large no of variables into less fewer factors,used n market reseacrh ,image recomgnition.\n",
        "#Monte Carlo simulation-Risk analysis,decision making\n",
        "#Cluster Analysis--image segmantation,market segmantion,rexomendatin---DS /ML guys uses tgis technique,k-meaning\n",
        "#heirarchical analysis ,\n",
        "#Time serires analysis--trend analysis using statistics advance level DA techniques---All roles\n",
        "#Sentiment anakysis ---AI Engineer,NLP,to extract text and analyse,social media monitoring---AI engineer\n",
        "#cohort analysis --subset of behaviour analysis--AI amd ML engineer,\n",
        "#Depends on project and depends on requirement we use differenr data analysis techniques\n",
        "#---DA--EDA,Regresion analysis,time series analysis,rest analysis are taken care by DS,ML engineer,\n",
        "#---AI engineer--cohort,factor,monte calro analysis ,sentoment analysis\n",
        "\n"
      ],
      "metadata": {
        "id": "w9aHOoYmGM7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Agenda----Variables ,data types,i/o formats ,basic methods.control structures,funcions ,file handling ,list comprehension\n",
        "#----------DA with Python---Pre--requisites\n",
        "#---Variables,data types and I/O formatting\n",
        "#---Data structures----list,tuple,dict,string,set\n",
        "#---Control structures,functions,File handling,exception handling,\n",
        "#---List comprehension,Advanced list processing,Lambda,filter,reduce,map\n",
        "#---import libraries--modules and packages\n",
        "#---\n"
      ],
      "metadata": {
        "id": "zX3U9ToQIcSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##In Pythin everythiung considered as object.\n",
        "#Variables,Data types and I/O formatting\n",
        "#----In python no need to mention data type like this int or string or float ,everything is dynamic\n",
        "name=\"Ram\"\n",
        "print(name)\n",
        "#type(name)\n",
        "print(type(name))\n",
        "#Data types available in python--numerical--int,float,complex--in python > 2.0\n",
        "#in Python 2.0 many data types are available like long int ,int float ,long float\n"
      ],
      "metadata": {
        "id": "uAEcMjPNqc2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25194302-827a-4156-dd19-14e06545dcef"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ram\n",
            "<class 'str'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wa02vqu6nvBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a=10000000000000000000000\n",
        "print(type(a))\n",
        "#in Python 2.0 it will print as long"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBZ6eYPqBhme",
        "outputId": "21bbecb1-fc26-4dcb-97a8-5178c99643d1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'int'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a=10.500000\n",
        "print(type(a))"
      ],
      "metadata": {
        "id": "ggLaIx-JuxdM",
        "outputId": "3279a5cb-c706-441e-daf2-0ff6ae6972a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'float'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a=10+5J\n",
        "print(type(a))"
      ],
      "metadata": {
        "id": "hoC4yylvu3MI",
        "outputId": "d56da424-e51c-46fe-950a-2c184a7d2160",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'complex'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Types,---Numerical---int,float,complex\n",
        "#---list,tuple,dictionary,string,set,frozenset"
      ],
      "metadata": {
        "id": "QHVgPhvsw9C3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome to Colab",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}