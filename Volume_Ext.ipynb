{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramnagella/Demo/blob/master/Volume_Ext.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "groupadd appteam\n",
        "cat /etc/group\n",
        "\n",
        "useradd -d /home/salam  -m \"salam\" -c \"CAMS-91\"\n",
        "useradd -d /home/mkumar  -m \"mkumar\" -c \"CAMS-91\"\n",
        "useradd -d /home/ssaxena  -m \"ssaxena\" -c \"CAMS-91\"\n",
        "\n",
        "\n",
        "cat /home/salam/.ssh/id_rsa.pub >> /home/salam/.ssh/authorized_keys\n",
        "\n",
        "cat /home/mkumar/.ssh/id_rsa.pub >> /home/mkumar/.ssh/authorized_keys\n",
        "\n",
        "cat /home/ssaxena/.ssh/id_rsa.pub >> /home/ssaxena/.ssh/authorized_keys\n",
        "\n",
        "su salam to verify and exit\n",
        "\n",
        "passwd mkumar   \n",
        "passwd ssaxena   \n",
        "\n",
        "useradd -g appteam mkumar\n",
        "useradd -g appteam ssaxena\n",
        "seradd -g appteam salam\n",
        "mkumar\n",
        "ssaxena\n",
        "\n",
        "ipa user-mod user --sshpubkey=\"ssh-rsa AAAAB3Nza...SNc5dv== client.example.com\"\n",
        "\n",
        "\n",
        "#####useradd -G AppTeam SSAlam\n",
        "\n",
        "sudo groupadd demo\n",
        "\n",
        "sudo groupadd -g 1009 demo1\n",
        "\n",
        "usermod --append --groups demo user1\n",
        "\n",
        "\n",
        "usermod -aG groupname username--- It should work\n",
        "\n",
        "usermod -aG demo user2\n",
        "\n",
        "\n",
        "useradd -G AppTeam Sarfaraj.Alam\n",
        "\n",
        "Hi Team,\n",
        "\n",
        "We want to move the below two Instances in PREPROD compartment into PRODUCTION compartment\n",
        "\n",
        "Below are the deatils of the instances which are now in PREPROD compartment\n",
        "\n",
        "drpext----\n",
        "172.30.5.212 drpext.erpprescott.canyonaero.com\n",
        "ocid1.instance.oc1.iad.anuwcljtl7lirwacinkfjqqryslkkwfedymbyu5e36q5mflizndmnrbkebnq\n",
        "\n",
        "drpint----\n",
        "172.30.5.33 drpint.erpprescott.canyonaero.com\n",
        "ocid1.instance.oc1.iad.anuwcljtl7lirwacsjiu3fbauzhws55ew6af426l4qle2cvza4zq3k4eb65q\n",
        "\n",
        "Compartment:tdgprescottoci (root)/tdgprescott/PREPROD\n",
        "Capacity type:On-demand\n",
        "\n",
        "Subnet:PVTSubnet-tdgprescott\n",
        "\n",
        "Prod instance details for reference\n",
        "\n",
        "Subnet: PVTSubnet-tdgprescott\n",
        "\n",
        "Compartment: tdgprescottoci (root)/tdgprescott/PRODUCTION\n",
        "Capacity type: On-demand\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "[root@ebsapppts01 .ssh]# cat authorized_keys\n",
        "no-port-forwarding,no-agent-forwarding,no-X11-forwarding,command=\"echo 'Please login as the user \\\"opc\\\" rather than the user \\\"root\\\".';echo;sleep 10\" ssh-rsa AAAAB3NzaC1yc2EAAAABJQAAAQEAgtD4EzWkhGhJSLsE9ZUfE/q1FRuSl7IqfD6vy0rMakKTmEnl14TKoGh7GOVJST2HHSdclS5z52v72tf8fMwXtfXo1xCKyX0xE21cVA7lto6p5wiutL6lF02lPrNyvkUkkPclHKbr2F1K/t2MJb/ANbhMSMc/RtdJhqTEiOy8/L/eBY0g5igFkagCwXgLwVvAgoL/YDyJPZ8F3PYYYuzoeBtJLB9m4BUynLMi64YRjO4c39Rl06eV10z/UfAfuJfPT1YU6mNlXuNFsqKN+wAnyEWAuJFRG8yt3b/seQknmQjDAfm/zP7PD6g4Vrs/A6JCzQtDiSxxk7EPeupghacvlQ==\n",
        "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDPmdFIKM4IIEpaMn00wN18uikML8c6c0zhLxplnfNhCWPkWzrqz2MPTMJ4fB9T6ydLxP5NnptPG77IJWh1NwHcVWuUXzoCI3jNGUuKBVtEYhaLtpcVyT0vnPXECH/DDVLJeKfnFMoVhurw5k5XKARxbNMKZliZf6gcogNPtoOqEoLQrsKLoh7cHsSCX+M4Iduc2vRl/GghwUaGnb5lRSSb+7/1ykiKkH7oHbIIj77h+/dYGdn318Ky8zDlRev7dGr5Qkani0O3iB/k5kVVKxSOeXHo+74V0Y3Ocwfdq4XA7wxczUsUjpmXcaIdk1Eb1QXwYuV4rGJC1ZW0rspBY7jd root@testinstance\n",
        "\n",
        "\n",
        "\n",
        " mkumar@spinnakersupport.com\n",
        "\n",
        "  ssh-keygen -t rsa -C user@example.com\n",
        "\n",
        "  ssh-keygen -t rsa -C mkumar\n",
        "  \n",
        "  \n",
        "  ipa user-mod mkumar --sshpubkey=\"ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAmM4i+YVrcw2uKOTmgsrAXhADAiYPyvclz8oH9+kSP4eNRcvJmkHbPSBjI0BSha0qepu/Q6yPDWI47uzPy7ZAsGZoXfh1fFbh0PFjBXz74khjXB5XVHsnD5zEA+VYnn7jARqUDn9wMfkogEk/VO2ECLNFW9QkN9kUghMJN9BLzHpEXBOuaH96Ji6aELD3H4J9hQ+7U3x7l4pqb4YJ6LNquYF0oQstlGIsk8hEty+J28PiNRtEQFB4u5dpXpF7oGBiSEMIuap0ibwE7i83IkTApprXJ/H/r2fJoG1Qi3iLb8T9/UR4YNWXGzOO+YYKK/rw8Yve7L1kxhFBvzkV8uWFKw== mkumar\"\n",
        "  \n",
        "  \n",
        "  ipa user-mod user --sshpubkey=\"$(cat ~/.ssh/id_rsa.pub)\" --sshpubkey=\"$(cat ~/.ssh/id_rsa2.pub)\"\n",
        "  \n",
        "  \n",
        "EBSPRD\n",
        "miliebsprd-app1.millicom.com----------10.18.150.64\n",
        "\n",
        "AW01EBSM01P-EBSPRD-APP1-----i-071487bb7c1ea79bb\n",
        "\n",
        "/dev/sda1-----------vol-03f8439e79f37f900\t/dev/sda1\t50\n",
        "\n",
        "NishawuwtEsPbv05KtILsM\n",
        "\n",
        "useradd -d /home/ocimonitor  -m \"ocimonitor/\" -c \"CAMS-169\\8\"\n",
        "\n",
        "\n",
        "ls -ld $AU_TOP/forms/US\n",
        "\n",
        "chmod 775 $AU_TOP/forms/US\n",
        "\n",
        "ls -ld $AP_TOP\n",
        "\n",
        "chmod 775 $AP_TOP/forms/US\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "kumar:x:54326:54327:CAMS-91:/home/mkumar:/bin/bash\n",
        "ssaxena:x:54327:54328:CAMS-91:/home/ssaxena:/bin/bash\n",
        "\n",
        "\n",
        "\n",
        "Demo\n",
        "mkumar:x:54324:54325:CAMS-91:/home/mkumar:/bin/bash\n",
        "ssaxena:x:54325:54326:CAMS-91:/home/ssaxena:/bin/bash\n",
        "\n",
        "\n",
        "setfacl -m u:salam:rwx US\n",
        "\n",
        "setfacl -m u:salam:rwx 12.0.0\n",
        "\n",
        "setfacl -m u:salam:rwx ebspts\n",
        "\n",
        "setfacl -m u:mkumar:rwx ebspts\n",
        "setfacl -m u:ssaxena:rwx ebspts\n",
        "\n",
        "\n",
        "V1r3thk0h1i\n",
        "\n",
        "\n",
        "\n",
        " vol-03f8439e79f37f900-------\n",
        "\n",
        " The root volume noted some elevated usages around the 9:20-9:30 window only. These were however, well within the limits:\n",
        "\n",
        "vol-070ed67c97069bd80--------\n",
        "\n",
        "For this volume,  noted that the usage elevated and reached the maximum throughput at 125MBps with increased queue length as well:\n",
        "\n",
        "\n",
        "vol-04642bb6035c5a5c7\n",
        "\n",
        "For this volume, noted multiple spikes and throughput reaching the volume limit.\n",
        "\n",
        "\n",
        "From the above datapoints, it is clearly visible that there had been an elevated load at the instance volumes.\n",
        " This in turn seems to have contributed to a throttled performance at the application and services running at the instance as well and\n",
        " might have resulted in killing of services at the OS level.\n",
        "This can lead to the visible reboots at the OS level as well.4.2 Copy the content of id_rsa.pub paste in the authorized_keys\t13\n",
        "\n",
        "\n",
        "\n",
        "usermod -aG oinstall salam\n",
        "\n",
        "\n",
        "\n",
        "useradd -d /home/ocimonitor  -m \"ocimonitor\" -c \"CAMS-168\"\n",
        "\n",
        "\n",
        "\n",
        "It would be .\n",
        "\n",
        "Take the backup of the root volume if the apprications runnig on the instances are very critical\n",
        "Other wise backup i console and make a n ote of the instance details. Below are the deatils of the instances which are now in PREPROD compartment\n",
        "\n",
        "drpext----\n",
        "172.30.5.212 drpext.erpprescott.canyonaero.com\n",
        "ocid1.instance.oc1.iad.anuwcljtl7lirwacinkfjqqryslkkwfedymbyu5e36q5mflizndmnrbkebnq\n",
        "\n",
        "drpint----\n",
        "172.30.5.33 drpint.erpprescott.canyonaero.com\n",
        "ocid1.instance.oc1.iad.anuwcljtl7lirwacsjiu3fbauzhws55ew6af426l4qle2cvza4zq3k4eb65q\n",
        "\n",
        "Compartment:tdgprescottoci (root)/tdgprescott/PREPROD\n",
        "Capacity type:On-demand\n",
        "\n",
        "Subnet:PVTSubnet-tdgprescott\n",
        "\n",
        "Prod instances compartment details for reference\n",
        "\n",
        "Subnet: PVTSubnet-tdgprescott\n",
        "\n",
        "Compartment: tdgprescottoci (root)/tdgprescott/PRODUCTION\n",
        "Capacity type: On-demand\n",
        "\n",
        "\n",
        "We need 30 to 40 minutes of time do complete this activity and it would be better to do this during off busines hours ..\n",
        "\n",
        "Please provide your approval and suitable time to perform this activity.\n",
        "\n",
        "We need to take the backup of the root volume if the apprications runnig on these instances are very critical\n",
        "Other wise backup is not required . Below are the deatils of the instances which are now in PREPROD compartment which will be moved to\n",
        "PROD compartment.\n",
        "\n",
        "drpext----\n",
        "172.30.5.212 drpext.erpprescott.canyonaero.com\n",
        "ocid1.instance.oc1.iad.anuwcljtl7lirwacinkfjqqryslkkwfedymbyu5e36q5mflizndmnrbkebnq\n",
        "\n",
        "drpint----\n",
        "172.30.5.33 drpint.erpprescott.canyonaero.com\n",
        "ocid1.instance.oc1.iad.anuwcljtl7lirwacsjiu3fbauzhws55ew6af426l4qle2cvza4zq3k4eb65q\n",
        "\n",
        "Login to the OCI Console and perform the below steps.\n",
        "\n",
        "1)Go o to menu and click or select desired instances to move\n",
        "2)Click on to more actions and select move resource option\n",
        "3)Select destination compartment to move the desired instances\n",
        "4)monitor the progress for some time and Login to the instance and verify once activity is completed.\n",
        "\n",
        "\n",
        "\n",
        "Taken the snapshot backup of worksoft instances\n",
        "Weekly start and stop of Worksoft instances\n",
        "Staring Canyon project non-Prod instances\n",
        "Prepared and shared the plan in moving the Canyon project instances from non-prod to prod compartmet\n",
        "Worked on Logic monitor configuration and setup\n",
        "Completed and shared the logs of the quartely linux patching on non-prod instances and awating for customer verification.\n",
        "\n",
        "\n",
        "Taken the snapshot backup of worksoft instances\n",
        "Preparing the plan to restore the RMAN backup files from S3 storage to Local file system.\n",
        "Weekly start and stop of Worksoft instances\n",
        "Starting Canyon project non-Prod instances\n",
        "Proivided access for Canyon Project team members in pre-prod and demo isntances\n",
        "\n",
        "\n",
        "Taken the snapshot backup of worksoft instances\n",
        "Weekly start and stop of Worksoft instances\n",
        "Staring Canyon project non-Prod instances\n",
        "Working on moving the Canyon project instances from non-prod to prod compartment .\n",
        "Provided and verified access in PREPROD environments to Canyon Project Logic Monitor user.\n",
        "Completed the Oracle Linux Bulletin April 2024 - Patching on non-prod instances.\n",
        "\n",
        "gp3  iops 3000 throuuh put 125   us-east-1a\n",
        "\n",
        "\n",
        "i-07fb3c63c6c8c3fc5\n",
        "\n",
        "\n",
        "Successfully created volume vol-0902b7e6e9d3a8bfd.---Need to delete\n",
        "\n",
        "\n",
        "\n",
        "Successfully created volume vol-07189d98362737b46.---Need to delete\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Successfully created volume vol-02db0eb2f7b6be580.\n",
        "\n",
        "\n",
        "https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/volume_limits.html#shared-limit\n",
        "\n",
        "\n",
        "https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/volume_limits.html#shared-limit\n",
        "\n",
        "\n",
        "\n",
        "The current instance (ebspreprd ) type is r6i.4xlarge --> can only support up to 28 volume attachments (for example,\n",
        "with one instance with one network, that means you can only have 27 EBS volumes attached)\n",
        "\n",
        "There are two options are available for us to work on this activity.\n",
        "1) You may consider updating to M7i.4xlarge -> which can support up to 32 volumes\n",
        "2) We can detach any of the voilume that is mot in use of 27 volumes , so that we can create new larger volume an dattach to the instance .\n",
        "\n",
        "Please suggest here .\n",
        "\n",
        "\n",
        "\n",
        "lsblk -o +SERIAL\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "[root@miliebspreprd-rac1 ~]# lsblk -o +SERIAL\n",
        "NAME         MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT SERIAL\n",
        "nvme15n1     259:26   0  500G  0 disk            vol05d81f3407d14b808\n",
        "└─nvme15n1p1 259:34   0  500G  0 part\n",
        "nvme0n1      259:1    0   50G  0 disk            vol06e1171570c8a7576\n",
        "└─nvme0n1p1  259:3    0   50G  0 part /\n",
        "nvme18n1     259:23   0  800G  0 disk            vol0b498eef531f8585f\n",
        "└─nvme18n1p1 259:24   0  800G  0 part\n",
        "nvme3n1      259:8    0  1.9T  0 disk            vol0d2088c65f5050c3e\n",
        "└─nvme3n1p1  259:15   0  1.9T  0 part\n",
        "nvme20n1     259:47   0  800G  0 disk            vol0361cc84f6c2f1ce2\n",
        "└─nvme20n1p1 259:50   0  800G  0 part\n",
        "nvme6n1      259:19   0  500G  0 disk            vol0fec756d99c95e000\n",
        "└─nvme6n1p1  259:28   0  500G  0 part /u01\n",
        "nvme11n1     259:17   0   25G  0 disk [SWAP]     vol09032e51d64723aac\n",
        "nvme23n1     259:22   0  1.9T  0 disk            vol0a8cf8e80bd04efab\n",
        "└─nvme23n1p1 259:36   0  1.9T  0 part\n",
        "nvme9n1      259:27   0  1.9T  0 disk            vol030744048bc515b3f\n",
        "└─nvme9n1p1  259:37   0  1.9T  0 part\n",
        "nvme14n1     259:7    0  1.9T  0 disk            vol0e0acaa9cca05126d\n",
        "└─nvme14n1p1 259:13   0  1.9T  0 part\n",
        "nvme26n1     259:46   0  1.9T  0 disk            vol0e50fd612b640a874\n",
        "└─nvme26n1p1 259:49   0  1.9T  0 part\n",
        "nvme17n1     259:5    0 1000G  0 disk            vol077bd18747a680733\n",
        "└─nvme17n1p1 259:14   0 1000G  0 part\n",
        "nvme2n1      259:12   0  1.9T  0 disk            vol0fdb75b54cc124cd9\n",
        "└─nvme2n1p1  259:18   0  1.9T  0 part\n",
        "nvme5n1      259:16   0  1.9T  0 disk            vol079c888d72f850ad4\n",
        "└─nvme5n1p1  259:30   0  1.9T  0 part\n",
        "nvme10n1     259:6    0  1.6T  0 disk            vol0b8f4eb48bbfb0c7d\n",
        "└─nvme10n1p1 259:9    0  1.6T  0 part\n",
        "nvme22n1     259:10   0  800G  0 disk            vol0318845980755fd2e\n",
        "└─nvme22n1p1 259:20   0  800G  0 part\n",
        "nvme8n1      259:21   0  1.8T  0 disk            vol03015030a92564f54\n",
        "└─nvme8n1p1  259:31   0  1.8T  0 part\n",
        "nvme13n1     259:11   0   20G  0 disk            vol0b0e133f61be3ac3e\n",
        "nvme25n1     259:33   0  1.9T  0 disk            vol0b27b27b8b0305315\n",
        "└─nvme25n1p1 259:41   0  1.9T  0 part\n",
        "nvme16n1     259:32   0    1T  0 disk            vol03cd2ca29fdab2b61\n",
        "└─nvme16n1p1 259:39   0 1024G  0 part\n",
        "nvme1n1      259:0    0  1.9T  0 disk            vol0a190d5c1da026b34\n",
        "└─nvme1n1p1  259:52   0  1.9T  0 part\n",
        "nvme19n1     259:29   0  800G  0 disk            vol02fd59151a08cbe04\n",
        "└─nvme19n1p1 259:38   0  800G  0 part\n",
        "nvme4n1      259:44   0    1G  0 disk            vol0c549b8b157401dbc\n",
        "└─nvme4n1p1  259:48   0 1023M  0 part /shared\n",
        "nvme21n1     259:25   0 1000G  0 disk            vol090fcd9032b0c95d7\n",
        "└─nvme21n1p1 259:35   0 1000G  0 part\n",
        "nvme7n1      259:4    0  1.9T  0 disk            vol0acfa4af8990a65c0\n",
        "└─nvme7n1p1  259:2    0  1.9T  0 part\n",
        "nvme12n1     259:45   0  1.4T  0 disk            vol0347fe98d73804907\n",
        "└─nvme12n1p1 259:43   0  1.4T  0 part\n",
        "nvme24n1     259:40   0  1.9T  0 disk            vol0eda59c813df49980\n",
        "└─nvme24n1p1 259:42   0  1.9T  0 part\n",
        "[root@miliebspreprd-rac1 ~]#\n",
        "\n",
        "https://docs.aws.amazon.com/ebs/latest/userguide/requesting-ebs-volume-modifications.html\n",
        "\n",
        "> (Optional) Before modifying a volume that contains valuable data,\n",
        " it is a best practice to create a snapshot of the volume in case you need to roll back your changes.\n",
        "however, because you are dealing with Oracle as the manager of those volumes, a snapshot may not be sufficient.\n",
        "better ask the Oracle database administrator to take their backups\n",
        "that's the only advise I can give.. the rest is more administrative things that you will find under \"Considerations\" page above.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "after 6 hours only we can re-modify the volume size once after the volume is increased first time\n",
        "\n",
        "\n",
        "\n",
        "nvme18n1     259:23   0  800G  0 disk\n",
        "└─nvme18n1p1\n",
        "\n",
        "gdisk -l /dev/nvme18n1\n",
        "\n",
        "\n",
        "[root@miliebspreprd-rac1 ~]# lsblk -o +SERIAL | grep nvme18n1\n",
        "nvme18n1     259:23   0  800G  0 disk            vol0b498eef531f8585f\n",
        "└─nvme18n1p1 259:24   0  800G  0 part\n",
        "[root@miliebspreprd-rac1 ~]# gdisk -l /dev/nvme18n1\n",
        "GPT fdisk (gdisk) version 0.8.10\n",
        "\n",
        "Partition table scan:\n",
        "  MBR: MBR only\n",
        "  BSD: not present\n",
        "  APM: not present\n",
        "  GPT: not present\n",
        "\n",
        "\n",
        "miliebspreprd_/dev/xvdu_SS_BKP_29_May2024\n",
        "\n",
        "\n",
        "miliebspreprd_/dev/xvdu_SS_BKP_29_May2024\n",
        "\n",
        "Successfully created snapshot snap-07cf119245d33c3a3 from volume vol-0b498eef531f8585f.\n",
        "\n",
        "\n",
        "https://docs.aws.amazon.com/ebs/latest/userguide/recognize-expanded-volume-linux.html?icmpid=docs_ec2_console\n",
        "\n",
        "https://docs.aws.amazon.com/ebs/latest/userguide/recognize-expanded-volume-linux.html?icmpid=docs_ec2_console\n",
        "\n",
        "https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/volume_limits.html#shared-limit\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "4343---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Taken the snapshot backup of worksoft instances\n",
        "Weekly start and stop of Worksoft instances\n",
        "Added the disk space on EBSPREPRD for the Refresh from Production\n",
        "\n",
        "Staring Canyon project non-Prod instances\n",
        "\n",
        "\n",
        "1)  Taking everyday (including weekends) snapshot of instances based on client requirement\n",
        "2)  Optimizing existing EBS volumes of all the instances in AWS\n",
        "3)  Setup Load balancers in AWS and move the traffic from OTD to ELB\n",
        "4)  Restoration to be done through AWS using AWS backup /AMI’s\n",
        "5)  Creating Volumes and attaching it to the servers\n",
        "6)  Conversion of Instance type  of AWS instances from old to new and new to old\n",
        "7)  Uploading new S3 keys to users in all the instances\n",
        "8)  Raising support requests with AWS for any issues -\n",
        "9)  Automating the AWS instances start/stop activities\n",
        "10) Linux admin support activities\n",
        "11) Linux Quarterly patching analysis and implementation( More than 50 Linux servers)--Can be automated  using AWS system manager or third party tools\n",
        "12) Troubleshooting Linux File system Issues\n",
        "13) Linux Security and firewall configuration\n",
        "14) Installing and configuring third party application tools-\n",
        "15) Linux Mailx server issues\n",
        "16) Normal daily support activities from client if any\n",
        "17) Analyzing and optimizing the AWS resources\n",
        "18) Preparing and uploading SOP in share point for all the activities\n",
        "19) stopping the AWS instances based on client requirement\n",
        "\n",
        "Creating Volumes and attaching it to the servers and optimizing existing EBS volumes of all the instances in AWS  \n",
        "Automating the AWS instance maintance activities and Conversion of Instance type  of AWS instances based ont he project requirement\n",
        "Maintainingand torubleshooting linux instances and applying patches based on recomendations.\n",
        "Provided AWS admin suppurt for all the AWS resources\n",
        "\n",
        "Detailed Assessment on AWS Services and the configuration like VPC’s, Private and Public Subnets\n",
        "\n",
        "Role Based Access Control - IAM\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PJVglXs1gZ3V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lFginXbigZqI"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome to Colab",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}