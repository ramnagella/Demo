{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramnagella/Demo/blob/master/CountVectorization%20and%20TFDF%20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count Vectorization Steps\n",
        "\n",
        "\n",
        "step-by-step explanation of how vocabulary is created in Count Vectorization\n",
        "Step-by-Step: Vocabulary Creation in Count Vectorization\n",
        "1. Input Collection:\n",
        "a. You start with a collection of documents or sentences, called a corpus.\n",
        "b. Example:\n",
        "i. Document 1: \"I love machine learning\"\n",
        "ii. Document 2: \"Machine learning is fun\"\n",
        "2. Text Normalization (optional but typical):\n",
        "a. Convert all text to lowercase to ensure consistency.\n",
        "b. Result:\n",
        "i. \"i love machine learning\"\n",
        "ii. \"machine learning is fun\"\n",
        "3. Tokenization:\n",
        "a. Break each document into individual words (tokens).\n",
        "b. Document 1: [\"i\", \"love\", \"machine\", \"learning\"]\n",
        "c. Document 2: [\"machine\", \"learning\", \"is\", \"fun\"]\n",
        "4. Unique Word Identification:\n",
        "a. Combine tokens from all documents.\n",
        "b. Identify all unique words (this becomes your vocabulary).\n",
        "c. From the example:\n",
        "i. All tokens combined: [\"i\", \"love\", \"machine\", \"learning\", \"machine\",\n",
        "\"learning\", \"is\", \"fun\"]\n",
        "ii. Unique words (vocabulary): [\"i\", \"love\", \"machine\", \"learning\", \"is\",\n",
        "\"fun\"]\n",
        "5. Assigning Indexes to Words:\n",
        "a. Each unique word in the vocabulary is assigned a fixed index.\n",
        "b. Example:\n",
        "i. \"i\" → 0\n",
        "ii. \"love\" → 1\n",
        "iii. \"machine\" → 2\n",
        "iv. \"learning\" → 3\n",
        "v. \"is\" →\n",
        "This dictionary of word → index is the vocabulary.\n",
        "6. Result:\n",
        "a. The vocabulary is now a mapping of each unique word to an index.\n",
        "b. This vocabulary is later used to transform any input text into a count vector\n",
        "(word frequency vector).\n",
        "\n",
        "\n",
        "#############################################333\n",
        "\n",
        "Count Vectorization Steps\n",
        "step-by-step explanation of how vocabulary is created in Count Vectorization\n",
        "Step-by-Step: Vocabulary Creation in Count Vectorization\n",
        "1. Input Collection:\n",
        "a. You start with a collection of documents or sentences, called a corpus.\n",
        "b. Example:\n",
        "i. Document 1: \"I love machine learning\"\n",
        "ii. Document 2: \"Machine learning is fun\"\n",
        "2. Text Normalization (optional but typical):\n",
        "a. Convert all text to lowercase to ensure consistency.\n",
        "b. Result:\n",
        "i. \"i love machine learning\"\n",
        "ii. \"machine learning is fun\"\n",
        "3. Tokenization:\n",
        "a. Break each document into individual words (tokens).\n",
        "b. Document 1: [\"i\", \"love\", \"machine\", \"learning\"]\n",
        "c. Document 2: [\"machine\", \"learning\", \"is\", \"fun\"]\n",
        "4. Unique Word Identification:\n",
        "a. Combine tokens from all documents.\n",
        "b. Identify all unique words (this becomes your vocabulary).\n",
        "c. From the example:\n",
        "i. All tokens combined: [\"i\", \"love\", \"machine\", \"learning\", \"machine\",\n",
        "\"learning\", \"is\", \"fun\"]\n",
        "ii. Unique words (vocabulary): [\"i\", \"love\", \"machine\", \"learning\", \"is\",\n",
        "\"fun\"]\n",
        "5. Assigning Indexes to Words:\n",
        "a. Each unique word in the vocabulary is assigned a fixed index.\n",
        "b. Example:\n",
        "i. \"i\" → 0\n",
        "ii. \"love\" → 1\n",
        "iii. \"machine\" → 2\n",
        "iv. \"learning\" → 3\n",
        "v. \"is\" →\n",
        "This dictionary of word → index is the vocabulary.\n",
        "6. Result:\n",
        "a. The vocabulary is now a mapping of each unique word to an index.\n",
        "b. This vocabulary is later used to transform any input text into a count vector\n",
        "(word frequency vector).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nrhJpaO7chtN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count Vectorization Steps\n",
        "step-by-step explanation of how vocabulary is created in Count Vectorization\n",
        "Step-by-Step: Vocabulary Creation in Count Vectorization\n",
        "1. Input Collection:\n",
        "a. You start with a collection of documents or sentences, called a corpus.\n",
        "b. Example:\n",
        "i. Document 1: \"I love machine learning\"\n",
        "ii. Document 2: \"Machine learning is fun\"\n",
        "2. Text Normalization (optional but typical):\n",
        "a. Convert all text to lowercase to ensure consistency.\n",
        "b. Result:\n",
        "i. \"i love machine learning\"\n",
        "ii. \"machine learning is fun\"\n",
        "3. Tokenization:\n",
        "a. Break each document into individual words (tokens).\n",
        "b. Document 1: [\"i\", \"love\", \"machine\", \"learning\"]\n",
        "c. Document 2: [\"machine\", \"learning\", \"is\", \"fun\"]\n",
        "4. Unique Word Identification:\n",
        "a. Combine tokens from all documents.\n",
        "b. Identify all unique words (this becomes your vocabulary).\n",
        "c. From the example:\n",
        "i. All tokens combined: [\"i\", \"love\", \"machine\", \"learning\", \"machine\",\n",
        "\"learning\", \"is\", \"fun\"]\n",
        "ii. Unique words (vocabulary): [\"i\", \"love\", \"machine\", \"learning\", \"is\",\n",
        "\"fun\"]\n",
        "5. Assigning Indexes to Words:\n",
        "a. Each unique word in the vocabulary is assigned a fixed index.\n",
        "b. Example:\n",
        "i. \"i\" → 0\n",
        "ii. \"love\" → 1\n",
        "iii. \"machine\" → 2\n",
        "iv. \"learning\" → 3\n",
        "v. \"is\" → 4\n",
        "vi. \"fun\" → 5\n",
        "This dictionary of word → index is the vocabulary.\n",
        "6. Result:\n",
        "a. The vocabulary is now a mapping of each unique word to an index.\n",
        "b. This vocabulary is later used to transform any input text into a count vector\n",
        "(word frequency vector)"
      ],
      "metadata": {
        "id": "nylRalfdcilB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PA\n",
        "\n",
        "#############################################################################\n",
        "\n",
        "Redshift Login\n",
        "\n",
        "dev-ice-redshift-cluster.ce5gi07ha18p.us-east-.redshift.amazonaws.com---Not working\n",
        "\n",
        "dev-ice-redshift-cluster.ce5gi07ha18p.us-east-1.redshift.amazonaws.com\n",
        "\n",
        "Admin user and pass\n",
        "host  dev-ice-redshift-cluster.ce5gi07ha18p.us-east-1.redshift.amazonaws.com\n",
        "\n",
        "admin\n",
        "EChdNNUgnXMnbaCLu5Kn\n",
        "#####################################################################\n",
        "prod-ice-redshift-cluster.cx3g8i1gfddj.us-east-1.redshift.amazonaws.com\n",
        "\n",
        "admin\n",
        "\n",
        "qQTdCcrVSeHEUL5spH\n",
        "######################################################################\n",
        "\n",
        "create user RNagella password 'L4s&9W#yzev'\n",
        "\n",
        "Users to be added  to the below group  so that they can access all the schemas\n",
        "\n",
        "etl_user_group\n",
        "\n",
        "\n",
        "\n",
        "skumarsingh\n",
        "select * from pg_user;\n",
        "\n",
        "drop user if exists skumarsingh\n",
        "\n",
        "SQL Error [55006]: ERROR: user \"skumarsingh\" cannot be dropped because the user has a privilege on some object\n",
        "\n",
        "select * from pg_user;\n",
        "\n",
        "drop user if exists skumarsingh;\n",
        "\n",
        "REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA public FROM skumarsingh;\n",
        "REVOKE ALL PRIVILEGES ON ALL SEQUENCES IN SCHEMA public FROM skumarsingh;\n",
        "REVOKE ALL PRIVILEGES ON SCHEMA public FROM skumarsingh;\n",
        "\n",
        "ALTER USER skumarsingh PASSWORD 'Ironclad#1'\n",
        "\n",
        "https://docs.aws.amazon.com/redshift/latest/dg/r_REVOKE.html\n",
        "\n",
        "\n",
        "SELECT\n",
        "    u.usename AS username,\n",
        "    g.groname AS groupname\n",
        "FROM\n",
        "    pg_user u\n",
        "JOIN\n",
        "    pg_group g ON u.usesysid = ANY(g.grolist)\n",
        "WHERE\n",
        "    u.usename = 'skumarsingh';\n",
        "ALTER GROUP etl_user_group DROP USER skumarsingh;\n",
        "\n",
        "\n",
        "ALTER GROUP etl_user_group ADD USER pyaminipriya,apraveen,rnagella,btilaganji;\n",
        "\n",
        "SELECT\n",
        "    u.usename AS username,\n",
        "    g.groname AS groupname\n",
        "FROM\n",
        "    pg_user u\n",
        "JOIN\n",
        "    pg_group g ON u.usesysid = ANY(g.grolist)\n",
        "WHERE\n",
        "    u.usename  in('skumarsingh', 'pyaminipriya','apraveen','rnagella','btilaganji');\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "rlutz@ironcladenvironmental.com\n",
        "\n",
        "rlutz\n",
        "\n",
        "Rebecca Lutz\n",
        "\n",
        "\n",
        "select * from pg_user;\n",
        "\n",
        "select * from pg_user;\n",
        "\n",
        "For Dev and Prod same queries we can run\n",
        "select * from pg_user;\n",
        "create user rlutz password 'ICE#2024kcv$';\n",
        "select * from pg_user;\n",
        "Select * from  pg_user where usename like '%lutz%';\n",
        "ALTER GROUP etl_user_group ADD USER rlutz;\n",
        "GRANT CREATE ON DATABASE ice_edh TO rlutz;\n",
        "\n",
        "\n",
        "\n",
        "UPushpanjali@IroncladEnvironmental.com\n",
        "hm-uppara.pushpanjali\n",
        "Firstname Uppara,\n",
        "lastname pushpanjali\n",
        "\n",
        "\n",
        "select * from pg_user;\n",
        "create user upushpanjali password 'ICE#2024upAT$';\n",
        "select * from pg_user;\n",
        "Select * from  pg_user where usename like '%pushpanjali%';\n",
        "ALTER GROUP etl_user_group ADD USER upushpanjali;\n",
        "GRANT CREATE ON DATABASE ice_edh TO upushpanjali;\n",
        "\n",
        "Select * from  pg_user where usename like '%pyaminipriya%';\n",
        "\n",
        "\n",
        "READ Only access to Redshift\n",
        "\n",
        "change schema name and user group name\n",
        "\n",
        "GRANT USAGE ON SCHEMA schema_name TO user_or_group;\n",
        "GRANT SELECT ON ALL TABLES IN SCHEMA schema_name TO user_or_group;\n",
        "ALTER DEFAULT PRIVILEGES IN SCHEMA schema_name GRANT SELECT ON TABLES TO user_or_group\n",
        "\n",
        "\n",
        "\n",
        "REVOKE ALL PRIVILEGES ON DATABASE ice_edh FROM pyaminipriya;\n",
        "\n",
        "ALTER GROUP etl_user_group ADD USER pyaminipriya, btilaganji;\n",
        "\n",
        "\n",
        "create user btilaganji password 'ICE#2024Vsr$';\n",
        "\n",
        "create user btilaganji password 'ICE#2024Vsr$';\n",
        "\n",
        "create user btilaganji password 'ICE#2024Vsr$';\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "create user btilaganji password 'ICE#2024Vsr$';\n",
        "\n",
        "create user btilaganji password 'ice_prod_bTila123';\n",
        "\n",
        "drop user if exists btilagani\n",
        "\n",
        "\n",
        "\n",
        "sarumugam@ironcladenvironmental.com\n",
        "\n",
        "select * from pg_user;\n",
        "create user sarumugam password 'ICE#2024upAT$WE';\n",
        "select * from pg_user;\n",
        "Select * from  pg_user where usename like '%sarumugam%';\n",
        "ALTER GROUP etl_user_group ADD USER sarumugam;\n",
        "GRANT CREATE ON DATABASE ice_edh TO sarumugam;\n",
        "\n",
        "aprajapati@ironcladenvironmental.com\n",
        "\n",
        "select * from pg_user;\n",
        "create user aprajapati password 'ICE#2024upAWET$';\n",
        "select * from pg_user;\n",
        "Select * from  pg_user where usename like '%aprajapati%';\n",
        "ALTER GROUP etl_user_group ADD USER aprajapati;\n",
        "GRANT CREATE ON DATABASE ice_edh TO aprajapati;\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Site to site VPN setup to access AWS services like redshift EC2 and Power Bi\n",
        "\n",
        "\n",
        "Ironclad Data center 10.100.0.0/24\n",
        "\n",
        "Public IP 156.146.110.37\n",
        "\n",
        "\n",
        "Host: 10.70.11.10\n",
        "Database.Schema: WSDATAIC\n",
        "Username: icwebsvc\n",
        "password:dfa35akC!9\n",
        "\n",
        "\n",
        ":prod-ice-redshift-cluster.cx3g8i1gfddj.us-east-1.redshift.amazonaws.com\n",
        "   \n",
        "   \n",
        "   DB2 connections jeremoe comments\n",
        "   \n",
        "   What is the PEER address of the current VPN tunnel that is being utilized for the current ODBC DB2 connections over your internal 10.50.1.0/25 addresses?\n",
        "\n",
        "Connectria our Hosting company is trying to find this tunnel so they can add the additional network of 10.50.2.0/24 per your request.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "$ aws ram create-resource-share --name TGW_Prod_Dev_Shared --no-allow-external-principals --principals arn:aws:organizations::877417598177:organization/o-yd0lt28dva\n",
        "\n",
        "$ aws ram associate-resource-share --resource-share arn:aws:ram:us-east-1:877417598177:resource-share/b494a4f6-4b23-477e-b395-b111b965b80a --resource-arns arn:aws:ec2:us-east-1:877417598177:transit-gateway/tgw-055fb173576ac74e0\n",
        "\n",
        "\n",
        "\n",
        "o-yd0lt28dva\n",
        "\n",
        "877417598177\n",
        "\n",
        "\n",
        "aws ram create-resource-share --name TGW_Prod_Dev_Shared --no-allow-external-principals --principals arn:aws:organizations::877417598177:organization/o-yd0lt28dva\n",
        "\n",
        "\n",
        "arn:aws:ec2:us-east-1:877417598177:transit-gateway/tgw-055fb173576ac74e0\n",
        "\n",
        "\n",
        "{\n",
        "    \"resourceShare\": {\n",
        "        \"resourceShareArn\": \"arn:aws:ram:us-east-1:877417598177:resource-share/b494a4f6-4b23-477e-b395-b111b965b80a\",\n",
        "        \"name\": \"TGW_Prod_Dev_Shared\",\n",
        "        \"owningAccountId\": \"877417598177\",\n",
        "        \"allowExternalPrincipals\": false,\n",
        "        \"status\": \"ACTIVE\",\n",
        "        \"tags\": [],\n",
        "        \"creationTime\": \"2024-09-09T07:21:50.965000+00:00\",\n",
        "        \"lastUpdatedTime\": \"2024-09-09T07:21:50.965000+00:00\"\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "aws ram associate-resource-share --resource-share arn:aws:ram:us-east-1:877417598177:resource-share/b494a4f6-4b23-477e-b395-b111b965b80a --resource-arns arn:aws:ec2:us-east-1:877417598177:transit-gateway/tgw-055fb173576ac74e0\n",
        "\n",
        "\n",
        "\n",
        "aws ram associate-resource-share --resource-share arn:aws:ram:us-east-1:877417598177:resource-share/b494a4f6-4b23-477e-b395-b111b965b80a --resource-arns arn:aws:ec2:us-east-1:877417598177:transit-gateway/tgw-055fb173576ac74e0\n",
        "\n",
        "{\n",
        "    \"resourceShareAssociations\": [\n",
        "        {\n",
        "            \"resourceShareArn\": \"arn:aws:ram:us-east-1:877417598177:resource-share/b494a4f6-4b23-477e-b395-b111b965b80a\",\n",
        "            \"associatedEntity\": \"arn:aws:ec2:us-east-1:877417598177:transit-gateway/tgw-055fb173576ac74e0\",\n",
        "            \"associationType\": \"RESOURCE\",\n",
        "            \"status\": \"ASSOCIATING\",\n",
        "            \"external\": false\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "[cloudshell-user@ip-10-134-57-9 ~]$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "select * from pg_user;\n",
        "\n",
        "drop user if exists AKumarPatra;\n",
        "\n",
        "REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA public FROM AKumarPatra;\n",
        "REVOKE ALL PRIVILEGES ON ALL SEQUENCES IN SCHEMA public FROM AKumarPatra;\n",
        "REVOKE ALL PRIVILEGES ON SCHEMA public FROM AKumarPatra;\n",
        "\n",
        "ALTER USER AKumarPatra PASSWORD 'Ironclad#1'\n",
        "\n",
        "\n",
        "pyaminipriya   Anjum---no access in redshift, Deevan, Annanta and Yogesh.\n",
        "\n",
        "AKumarPatra@IroncladEnvironmental.com\n",
        "\n",
        "YThippeswamy@IroncladEnvironmental.com--user doent exist\n",
        "\n",
        "TKumar@IroncladEnvironmental.com--user doesnt exist\n",
        "UPushpanjali@IroncladEnvironmental.com\n",
        "APraveen@IroncladEnvironmental.com\n",
        "PYaminipriya@IroncladEnvironmental.com\n",
        "\n",
        "\n",
        "Select * from  pg_user where usename like '%Deevan%';\n",
        "\n",
        "AWS Access Deleted ---Deevan ,Annata,Anjum,YaminiPriya,Pusjpanjali\n",
        "\n",
        "\n",
        "ALTER GROUP etl_user_group DROP USER AKumarPatra;\n",
        "drop user if exists AKumarPatra;\n",
        "\n",
        "-- Revoke database access\n",
        "REVOKE ALL PRIVILEGES ON DATABASE ice_edh FROM UPushpanjali;\n",
        "\n",
        "-- Revoke schema access\n",
        "REVOKE ALL PRIVILEGES ON SCHEMA ice_edh FROM UPushpanjali;----\n",
        "\n",
        "-- Revoke access on all existing tables\n",
        "REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA ice_edh FROM APraveen;-----\n",
        "\n",
        "-- Revoke access on future tables (default privileges)\n",
        "ALTER DEFAULT PRIVILEGES IN SCHEMA ice_edh REVOKE ALL ON TABLES FROM UPushpanjali;----\n",
        ","
      ],
      "metadata": {
        "id": "aqkwxMQ32GjM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Creating Volumes and attaching it to the servers and optimizing existing EBS volumes of all the instances in AWS  \n",
        "Automating the AWS instance maintenance activities and Conversion of Instance type  of AWS instances based on the project requirement\n",
        "Maintaining and troubleshooting linux instances and applying patches based on recommendations.\n",
        "Provided AWS admin support for all the AWS resources\n",
        "AWS infrastructure and Application Support activities\n",
        "Analyzing and troubleshooting the production issues\n",
        "Planned and Migrated On-Prem(VMware) Applications to AWS Cloud using Cloud Endure Tool.\n",
        "AWS Design, Implementation and support\n",
        "Conversion of tenency of AWS instances based on the project requirement (dedicated to default)\n",
        "Analysis the existing Cloud Infrastructure inventory and initial assessment of all the services\n",
        "Cost/Security/Performance Optimization Assessment :\n",
        "Performed the assessment Using CloudCheckr tool\n",
        "Load Distribution - Creation of Load balancer\n",
        "Data Protection – Backup\n",
        "Maintaining and troubleshooting security and firewall issue in linux instances\n",
        "Collecting and analysing the AWS volumes and snapshots and recomenduing the cutormer to optimize the resources utilisation.\n",
        "Provided Admin support for the all linux instances\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\thistory\n",
        "\n",
        "\thostname;date\n",
        "\thostname date history\n",
        "\n",
        "hostname;date\n",
        "hostname,date\n",
        "\n",
        "cat /etc/hosts\n",
        "\n",
        "hostname real hostname from /etc/hosts file\n",
        "\n",
        "\tcat /etc/hosts\n",
        "\n",
        "\thostname real hostname from /etc/hosts file\n",
        "\n",
        "\n",
        "\n",
        "\t##############################################33\n",
        "\n",
        "\tdata Restoration from S3\n",
        "\n",
        "\n",
        "\n",
        "https://docs.aws.amazon.com/cli/latest/reference/s3/sync.html\n",
        "\n",
        "aws s3 sync s3://fs-prod-db-backup/file_chunk/885164289/EBSPRDDB/backuppiece/2024-05-01/9n2pinb3_386359_1_1/8ShEIGw5MkYj/ .\n",
        "\n",
        "aws s3 sync s3:// .\n",
        "\n",
        "aws s3 sync s3://fs-prod-db-backup/file_chunk/885164289/EBSPRDDB/backuppiece/2024-04-27/ .\n",
        "\n",
        "\n",
        "aws s3 sync s3://fs-prod-db-backup/ .\n",
        "\n",
        "\n",
        "aws s3 ls s3://buckname/dirname/ --summarize --recursive --human-readable\n",
        "\n",
        "aws s3 ls s3://fs-prod-db-backup/file_chunk/885164289/EBSPRDDB/backuppiece/2024-04-27/ --summarize --recursive --human-readable\n",
        "aws s3 ls s3://fs-prod-db-backup/file_chunk/885164289/EBSPRDDB/backuppiece/2024-04-28/ --summarize --recursive --human-readable\n",
        "\n",
        "01-05  27 GB\n",
        "02-05  39 GB\n",
        "\n",
        "\n",
        "30-04   1.5TB\n",
        "29-4\t1.7 TB\n",
        "28\t\t2.4\n",
        "27      .85 TB\n",
        "\n",
        "6.45 TB Level 0 backup size\n",
        "\n",
        "aws s3 ls s3://fs-prod-db-backup/file_chunk/885164289/EBSPRDDB/backuppiece/ --summarize --recursive --human-readable\n",
        "\n",
        "aws s3 ls s3://fs-prod-db-backup/ --recursive --human-readable --summarize\n",
        "\n",
        "Total Objects: 35122\n",
        "   Total Size: 60.3 TiB\n",
        "[root@milisoatest-rac1 ~]#\n",
        "\n",
        "[root@milisoatest-rac1 s3test]# aws s3 ls s3://fs-prod-db-backup/file_chunk/885164289/EBSPRDDB/backuppiece/2024-05-01/9n2pinb3_386359_1_1/8ShEIGw5MkYj/0000000001 --summarize --recursive --human-readable\n",
        "2024-04-30 19:13:55    6.7 GiB file_chunk/885164289/EBSPRDDB/backuppiece/2024-05-01/9n2pinb3_386359_1_1/8ShEIGw5MkYj/0000000001\n",
        "\n",
        "Total Objects: 1\n",
        "   Total Size: 6.7 GiB\n",
        "[root@milisoatest-rac1 s3test]#\n",
        "\n",
        "\n",
        "Estimated speed weve observed during transfer of folder was 180 mibs second\n",
        "\n",
        "sync is bettre for single file cp is good\n",
        "\n"
      ],
      "metadata": {
        "id": "5VMh81Ju2ZMZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "put /tmp/agent_installer-x86_64.sh\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "aws ec2 describe-volumes --query 'Volumes[*].{ID:VolumeId,InstanceId:Attachments[0].InstanceId,AZ:AvailabilityZone,Size:Size}' --output table\n",
        "describe-volumes &#8212; AWS CLI 1.31.13 Command Reference\n",
        "docs.aws.amazon.com\n",
        "\n",
        "https://docs.aws.amazon.com/cli/latest/reference/ec2/describe-volumes.html\n",
        "\n",
        "\n",
        "EBS-GitLab-PP - ami volume (/dev/sdf)\n",
        "snap-0f114339b41bcff0d\t50 GiB\tCreated by CreateImage(i-062bc4dee45c7956d) for ami-03288332d293ed1b3\tStandard\tCompleted\t2023/10/31 11:31 GMT+5:30\tAvailable (100%)\tNot encrypted\t–\t–\t–\n",
        "EBS-GitLab-PP - ami volume (/dev/sda1)\n",
        "snap-0fbd87612b7ac3202\t50 GiB\tCreated by CreateImage(i-062bc4dee45c7956d) for ami-03288332d293ed1b3\n",
        "\n",
        " ssh -i jumphost-ebs.pem ubuntu@10.18.152.218\n",
        "\n",
        "\n",
        "\n",
        "sg-0b64d95542ef250f1 (sg_ebs-oem)\n",
        "sg-0c90d3b372b01d7a4 (sg_ebs-elb-internal)\n",
        "sg-0d2f85dd38725556a (sg_ebs-jumphost)\n",
        "\n",
        "vol-0015d45f336602d67\t/dev/sdf\t50\t Attached\t2021/12/14 09:01 GMT+5:30\tNo\t–\tNo\n",
        "vol-0d812545696bccbf5\t/dev/sda1\t50\n",
        "\n",
        "\n",
        "EBS-GitLab-Runner\tLinux\t10.18.152.68\n",
        "\n",
        "\n",
        "snap-05b8e9f6f3eb09fa4\t50 GiB\tESM_GitLab_Maintenance_Activity_01262022\tStandard\tCompleted\t2022/01/27 08:39 GMT+5:30\tAvailable (100%)\tNot encrypted\t–\t–\t–\n",
        "EBS-GitLab-PP - ami volume (/dev/sda1)\n",
        "snap-0fbd87612b7ac3202\t50 GiB\tCreated by CreateImage(i-062bc4dee45c7956d) for ami-03288332d293ed1b3\tStandard\tCompleted\t2023/10/31 11:31 GMT+5:30\tAvailable (100%)\tNot encrypted\t–\t–\t–\n",
        "–\n",
        "snap-0846e36cf1179f9f5\t50 GiB\tEBS-GitLab-PP_10.18.152.214_SS_BKP_July_082023"
      ],
      "metadata": {
        "id": "5a4vqjWD23QS"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome to Colab",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}