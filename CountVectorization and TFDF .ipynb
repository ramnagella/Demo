{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramnagella/Demo/blob/master/CountVectorization%20and%20TFDF%20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count Vectorization Steps\n",
        "step-by-step explanation of how vocabulary is created in Count Vectorization\n",
        "Step-by-Step: Vocabulary Creation in Count Vectorization\n",
        "1. Input Collection:\n",
        "a. You start with a collection of documents or sentences, called a corpus.\n",
        "b. Example:\n",
        "i. Document 1: \"I love machine learning\"\n",
        "ii. Document 2: \"Machine learning is fun\"\n",
        "2. Text Normalization (optional but typical):\n",
        "a. Convert all text to lowercase to ensure consistency.\n",
        "b. Result:\n",
        "i. \"i love machine learning\"\n",
        "ii. \"machine learning is fun\"\n",
        "3. Tokenization:\n",
        "a. Break each document into individual words (tokens).\n",
        "b. Document 1: [\"i\", \"love\", \"machine\", \"learning\"]\n",
        "c. Document 2: [\"machine\", \"learning\", \"is\", \"fun\"]\n",
        "4. Unique Word Identification:\n",
        "a. Combine tokens from all documents.\n",
        "b. Identify all unique words (this becomes your vocabulary).\n",
        "c. From the example:\n",
        "i. All tokens combined: [\"i\", \"love\", \"machine\", \"learning\", \"machine\",\n",
        "\"learning\", \"is\", \"fun\"]\n",
        "ii. Unique words (vocabulary): [\"i\", \"love\", \"machine\", \"learning\", \"is\",\n",
        "\"fun\"]\n",
        "5. Assigning Indexes to Words:\n",
        "a. Each unique word in the vocabulary is assigned a fixed index.\n",
        "b. Example:\n",
        "i. \"i\" → 0\n",
        "ii. \"love\" → 1\n",
        "iii. \"machine\" → 2\n",
        "iv. \"learning\" → 3\n",
        "v. \"is\" →\n",
        "This dictionary of word → index is the vocabulary.\n",
        "6. Result:\n",
        "a. The vocabulary is now a mapping of each unique word to an index.\n",
        "b. This vocabulary is later used to transform any input text into a count vector\n",
        "(word frequency vector).\n",
        "\n",
        "\n",
        "#############################################333\n",
        "\n",
        "Count Vectorization Steps\n",
        "step-by-step explanation of how vocabulary is created in Count Vectorization\n",
        "Step-by-Step: Vocabulary Creation in Count Vectorization\n",
        "1. Input Collection:\n",
        "a. You start with a collection of documents or sentences, called a corpus.\n",
        "b. Example:\n",
        "i. Document 1: \"I love machine learning\"\n",
        "ii. Document 2: \"Machine learning is fun\"\n",
        "2. Text Normalization (optional but typical):\n",
        "a. Convert all text to lowercase to ensure consistency.\n",
        "b. Result:\n",
        "i. \"i love machine learning\"\n",
        "ii. \"machine learning is fun\"\n",
        "3. Tokenization:\n",
        "a. Break each document into individual words (tokens).\n",
        "b. Document 1: [\"i\", \"love\", \"machine\", \"learning\"]\n",
        "c. Document 2: [\"machine\", \"learning\", \"is\", \"fun\"]\n",
        "4. Unique Word Identification:\n",
        "a. Combine tokens from all documents.\n",
        "b. Identify all unique words (this becomes your vocabulary).\n",
        "c. From the example:\n",
        "i. All tokens combined: [\"i\", \"love\", \"machine\", \"learning\", \"machine\",\n",
        "\"learning\", \"is\", \"fun\"]\n",
        "ii. Unique words (vocabulary): [\"i\", \"love\", \"machine\", \"learning\", \"is\",\n",
        "\"fun\"]\n",
        "5. Assigning Indexes to Words:\n",
        "a. Each unique word in the vocabulary is assigned a fixed index.\n",
        "b. Example:\n",
        "i. \"i\" → 0\n",
        "ii. \"love\" → 1\n",
        "iii. \"machine\" → 2\n",
        "iv. \"learning\" → 3\n",
        "v. \"is\" →\n",
        "This dictionary of word → index is the vocabulary.\n",
        "6. Result:\n",
        "a. The vocabulary is now a mapping of each unique word to an index.\n",
        "b. This vocabulary is later used to transform any input text into a count vector\n",
        "(word frequency vector).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nrhJpaO7chtN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nylRalfdcilB"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome to Colab",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}