{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramnagella/Demo/blob/master/CountVectorization%20and%20TFDF%20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count Vectorization Steps\n",
        "\n",
        "\n",
        "step-by-step explanation of how vocabulary is created in Count Vectorization\n",
        "Step-by-Step: Vocabulary Creation in Count Vectorization\n",
        "1. Input Collection:\n",
        "a. You start with a collection of documents or sentences, called a corpus.\n",
        "b. Example:\n",
        "i. Document 1: \"I love machine learning\"\n",
        "ii. Document 2: \"Machine learning is fun\"\n",
        "2. Text Normalization (optional but typical):\n",
        "a. Convert all text to lowercase to ensure consistency.\n",
        "b. Result:\n",
        "i. \"i love machine learning\"\n",
        "ii. \"machine learning is fun\"\n",
        "3. Tokenization:\n",
        "a. Break each document into individual words (tokens).\n",
        "b. Document 1: [\"i\", \"love\", \"machine\", \"learning\"]\n",
        "c. Document 2: [\"machine\", \"learning\", \"is\", \"fun\"]\n",
        "4. Unique Word Identification:\n",
        "a. Combine tokens from all documents.\n",
        "b. Identify all unique words (this becomes your vocabulary).\n",
        "c. From the example:\n",
        "i. All tokens combined: [\"i\", \"love\", \"machine\", \"learning\", \"machine\",\n",
        "\"learning\", \"is\", \"fun\"]\n",
        "ii. Unique words (vocabulary): [\"i\", \"love\", \"machine\", \"learning\", \"is\",\n",
        "\"fun\"]\n",
        "5. Assigning Indexes to Words:\n",
        "a. Each unique word in the vocabulary is assigned a fixed index.\n",
        "b. Example:\n",
        "i. \"i\" → 0\n",
        "ii. \"love\" → 1\n",
        "iii. \"machine\" → 2\n",
        "iv. \"learning\" → 3\n",
        "v. \"is\" →\n",
        "This dictionary of word → index is the vocabulary.\n",
        "6. Result:\n",
        "a. The vocabulary is now a mapping of each unique word to an index.\n",
        "b. This vocabulary is later used to transform any input text into a count vector\n",
        "(word frequency vector).\n",
        "\n",
        "\n",
        "#############################################333\n",
        "\n",
        "Count Vectorization Steps\n",
        "step-by-step explanation of how vocabulary is created in Count Vectorization\n",
        "Step-by-Step: Vocabulary Creation in Count Vectorization\n",
        "1. Input Collection:\n",
        "a. You start with a collection of documents or sentences, called a corpus.\n",
        "b. Example:\n",
        "i. Document 1: \"I love machine learning\"\n",
        "ii. Document 2: \"Machine learning is fun\"\n",
        "2. Text Normalization (optional but typical):\n",
        "a. Convert all text to lowercase to ensure consistency.\n",
        "b. Result:\n",
        "i. \"i love machine learning\"\n",
        "ii. \"machine learning is fun\"\n",
        "3. Tokenization:\n",
        "a. Break each document into individual words (tokens).\n",
        "b. Document 1: [\"i\", \"love\", \"machine\", \"learning\"]\n",
        "c. Document 2: [\"machine\", \"learning\", \"is\", \"fun\"]\n",
        "4. Unique Word Identification:\n",
        "a. Combine tokens from all documents.\n",
        "b. Identify all unique words (this becomes your vocabulary).\n",
        "c. From the example:\n",
        "i. All tokens combined: [\"i\", \"love\", \"machine\", \"learning\", \"machine\",\n",
        "\"learning\", \"is\", \"fun\"]\n",
        "ii. Unique words (vocabulary): [\"i\", \"love\", \"machine\", \"learning\", \"is\",\n",
        "\"fun\"]\n",
        "5. Assigning Indexes to Words:\n",
        "a. Each unique word in the vocabulary is assigned a fixed index.\n",
        "b. Example:\n",
        "i. \"i\" → 0\n",
        "ii. \"love\" → 1\n",
        "iii. \"machine\" → 2\n",
        "iv. \"learning\" → 3\n",
        "v. \"is\" →\n",
        "This dictionary of word → index is the vocabulary.\n",
        "6. Result:\n",
        "a. The vocabulary is now a mapping of each unique word to an index.\n",
        "b. This vocabulary is later used to transform any input text into a count vector\n",
        "(word frequency vector).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nrhJpaO7chtN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count Vectorization Steps\n",
        "step-by-step explanation of how vocabulary is created in Count Vectorization\n",
        "Step-by-Step: Vocabulary Creation in Count Vectorization\n",
        "1. Input Collection:\n",
        "a. You start with a collection of documents or sentences, called a corpus.\n",
        "b. Example:\n",
        "i. Document 1: \"I love machine learning\"\n",
        "ii. Document 2: \"Machine learning is fun\"\n",
        "2. Text Normalization (optional but typical):\n",
        "a. Convert all text to lowercase to ensure consistency.\n",
        "b. Result:\n",
        "i. \"i love machine learning\"\n",
        "ii. \"machine learning is fun\"\n",
        "3. Tokenization:\n",
        "a. Break each document into individual words (tokens).\n",
        "b. Document 1: [\"i\", \"love\", \"machine\", \"learning\"]\n",
        "c. Document 2: [\"machine\", \"learning\", \"is\", \"fun\"]\n",
        "4. Unique Word Identification:\n",
        "a. Combine tokens from all documents.\n",
        "b. Identify all unique words (this becomes your vocabulary).\n",
        "c. From the example:\n",
        "i. All tokens combined: [\"i\", \"love\", \"machine\", \"learning\", \"machine\",\n",
        "\"learning\", \"is\", \"fun\"]\n",
        "ii. Unique words (vocabulary): [\"i\", \"love\", \"machine\", \"learning\", \"is\",\n",
        "\"fun\"]\n",
        "5. Assigning Indexes to Words:\n",
        "a. Each unique word in the vocabulary is assigned a fixed index.\n",
        "b. Example:\n",
        "i. \"i\" → 0\n",
        "ii. \"love\" → 1\n",
        "iii. \"machine\" → 2\n",
        "iv. \"learning\" → 3\n",
        "v. \"is\" → 4\n",
        "vi. \"fun\" → 5\n",
        "This dictionary of word → index is the vocabulary.\n",
        "6. Result:\n",
        "a. The vocabulary is now a mapping of each unique word to an index.\n",
        "b. This vocabulary is later used to transform any input text into a count vector\n",
        "(word frequency vector)"
      ],
      "metadata": {
        "id": "nylRalfdcilB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PA\n",
        "\n",
        "#############################################################################\n",
        "\n",
        "Redshift Login\n",
        "\n",
        "dev-ice-redshift-cluster.ce5gi07ha18p.us-east-.redshift.amazonaws.com---Not working\n",
        "\n",
        "dev-ice-redshift-cluster.ce5gi07ha18p.us-east-1.redshift.amazonaws.com\n",
        "\n",
        "Admin user and pass\n",
        "host  dev-ice-redshift-cluster.ce5gi07ha18p.us-east-1.redshift.amazonaws.com\n",
        "\n",
        "admin\n",
        "EChdNNUgnXMnbaCLu5Kn\n",
        "#####################################################################\n",
        "prod-ice-redshift-cluster.cx3g8i1gfddj.us-east-1.redshift.amazonaws.com\n",
        "\n",
        "admin\n",
        "\n",
        "qQTdCcrVSeHEUL5spH\n",
        "######################################################################\n",
        "\n",
        "create user RNagella password 'L4s&9W#yzev'\n",
        "\n",
        "Users to be added  to the below group  so that they can access all the schemas\n",
        "\n",
        "etl_user_group\n",
        "\n",
        "\n",
        "\n",
        "skumarsingh\n",
        "select * from pg_user;\n",
        "\n",
        "drop user if exists skumarsingh\n",
        "\n",
        "SQL Error [55006]: ERROR: user \"skumarsingh\" cannot be dropped because the user has a privilege on some object\n",
        "\n",
        "select * from pg_user;\n",
        "\n",
        "drop user if exists skumarsingh;\n",
        "\n",
        "REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA public FROM skumarsingh;\n",
        "REVOKE ALL PRIVILEGES ON ALL SEQUENCES IN SCHEMA public FROM skumarsingh;\n",
        "REVOKE ALL PRIVILEGES ON SCHEMA public FROM skumarsingh;\n",
        "\n",
        "ALTER USER skumarsingh PASSWORD 'Ironclad#1'\n",
        "\n",
        "https://docs.aws.amazon.com/redshift/latest/dg/r_REVOKE.html\n",
        "\n",
        "\n",
        "SELECT\n",
        "    u.usename AS username,\n",
        "    g.groname AS groupname\n",
        "FROM\n",
        "    pg_user u\n",
        "JOIN\n",
        "    pg_group g ON u.usesysid = ANY(g.grolist)\n",
        "WHERE\n",
        "    u.usename = 'skumarsingh';\n",
        "ALTER GROUP etl_user_group DROP USER skumarsingh;\n",
        "\n",
        "\n",
        "ALTER GROUP etl_user_group ADD USER pyaminipriya,apraveen,rnagella,btilaganji;\n",
        "\n",
        "SELECT\n",
        "    u.usename AS username,\n",
        "    g.groname AS groupname\n",
        "FROM\n",
        "    pg_user u\n",
        "JOIN\n",
        "    pg_group g ON u.usesysid = ANY(g.grolist)\n",
        "WHERE\n",
        "    u.usename  in('skumarsingh', 'pyaminipriya','apraveen','rnagella','btilaganji');\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "rlutz@ironcladenvironmental.com\n",
        "\n",
        "rlutz\n",
        "\n",
        "Rebecca Lutz\n",
        "\n",
        "\n",
        "select * from pg_user;\n",
        "\n",
        "select * from pg_user;\n",
        "\n",
        "For Dev and Prod same queries we can run\n",
        "select * from pg_user;\n",
        "create user rlutz password 'ICE#2024kcv$';\n",
        "select * from pg_user;\n",
        "Select * from  pg_user where usename like '%lutz%';\n",
        "ALTER GROUP etl_user_group ADD USER rlutz;\n",
        "GRANT CREATE ON DATABASE ice_edh TO rlutz;\n",
        "\n",
        "\n",
        "\n",
        "UPushpanjali@IroncladEnvironmental.com\n",
        "hm-uppara.pushpanjali\n",
        "Firstname Uppara,\n",
        "lastname pushpanjali\n",
        "\n",
        "\n",
        "select * from pg_user;\n",
        "create user upushpanjali password 'ICE#2024upAT$';\n",
        "select * from pg_user;\n",
        "Select * from  pg_user where usename like '%pushpanjali%';\n",
        "ALTER GROUP etl_user_group ADD USER upushpanjali;\n",
        "GRANT CREATE ON DATABASE ice_edh TO upushpanjali;\n",
        "\n",
        "Select * from  pg_user where usename like '%pyaminipriya%';\n",
        "\n",
        "\n",
        "READ Only access to Redshift\n",
        "\n",
        "change schema name and user group name\n",
        "\n",
        "GRANT USAGE ON SCHEMA schema_name TO user_or_group;\n",
        "GRANT SELECT ON ALL TABLES IN SCHEMA schema_name TO user_or_group;\n",
        "ALTER DEFAULT PRIVILEGES IN SCHEMA schema_name GRANT SELECT ON TABLES TO user_or_group\n",
        "\n",
        "\n",
        "\n",
        "REVOKE ALL PRIVILEGES ON DATABASE ice_edh FROM pyaminipriya;\n",
        "\n",
        "ALTER GROUP etl_user_group ADD USER pyaminipriya, btilaganji;\n",
        "\n",
        "\n",
        "create user btilaganji password 'ICE#2024Vsr$';\n",
        "\n",
        "create user btilaganji password 'ICE#2024Vsr$';\n",
        "\n",
        "create user btilaganji password 'ICE#2024Vsr$';\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "create user btilaganji password 'ICE#2024Vsr$';\n",
        "\n",
        "create user btilaganji password 'ice_prod_bTila123';\n",
        "\n",
        "drop user if exists btilagani\n",
        "\n",
        "\n",
        "\n",
        "sarumugam@ironcladenvironmental.com\n",
        "\n",
        "select * from pg_user;\n",
        "create user sarumugam password 'ICE#2024upAT$WE';\n",
        "select * from pg_user;\n",
        "Select * from  pg_user where usename like '%sarumugam%';\n",
        "ALTER GROUP etl_user_group ADD USER sarumugam;\n",
        "GRANT CREATE ON DATABASE ice_edh TO sarumugam;\n",
        "\n",
        "aprajapati@ironcladenvironmental.com\n",
        "\n",
        "select * from pg_user;\n",
        "create user aprajapati password 'ICE#2024upAWET$';\n",
        "select * from pg_user;\n",
        "Select * from  pg_user where usename like '%aprajapati%';\n",
        "ALTER GROUP etl_user_group ADD USER aprajapati;\n",
        "GRANT CREATE ON DATABASE ice_edh TO aprajapati;\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Site to site VPN setup to access AWS services like redshift EC2 and Power Bi\n",
        "\n",
        "\n",
        "Ironclad Data center 10.100.0.0/24\n",
        "\n",
        "Public IP 156.146.110.37\n",
        "\n",
        "\n",
        "Host: 10.70.11.10\n",
        "Database.Schema: WSDATAIC\n",
        "Username: icwebsvc\n",
        "password:dfa35akC!9\n",
        "\n",
        "\n",
        ":prod-ice-redshift-cluster.cx3g8i1gfddj.us-east-1.redshift.amazonaws.com\n",
        "   \n",
        "   \n",
        "   DB2 connections jeremoe comments\n",
        "   \n",
        "   What is the PEER address of the current VPN tunnel that is being utilized for the current ODBC DB2 connections over your internal 10.50.1.0/25 addresses?\n",
        "\n",
        "Connectria our Hosting company is trying to find this tunnel so they can add the additional network of 10.50.2.0/24 per your request.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "$ aws ram create-resource-share --name TGW_Prod_Dev_Shared --no-allow-external-principals --principals arn:aws:organizations::877417598177:organization/o-yd0lt28dva\n",
        "\n",
        "$ aws ram associate-resource-share --resource-share arn:aws:ram:us-east-1:877417598177:resource-share/b494a4f6-4b23-477e-b395-b111b965b80a --resource-arns arn:aws:ec2:us-east-1:877417598177:transit-gateway/tgw-055fb173576ac74e0\n",
        "\n",
        "\n",
        "\n",
        "o-yd0lt28dva\n",
        "\n",
        "877417598177\n",
        "\n",
        "\n",
        "aws ram create-resource-share --name TGW_Prod_Dev_Shared --no-allow-external-principals --principals arn:aws:organizations::877417598177:organization/o-yd0lt28dva\n",
        "\n",
        "\n",
        "arn:aws:ec2:us-east-1:877417598177:transit-gateway/tgw-055fb173576ac74e0\n",
        "\n",
        "\n",
        "{\n",
        "    \"resourceShare\": {\n",
        "        \"resourceShareArn\": \"arn:aws:ram:us-east-1:877417598177:resource-share/b494a4f6-4b23-477e-b395-b111b965b80a\",\n",
        "        \"name\": \"TGW_Prod_Dev_Shared\",\n",
        "        \"owningAccountId\": \"877417598177\",\n",
        "        \"allowExternalPrincipals\": false,\n",
        "        \"status\": \"ACTIVE\",\n",
        "        \"tags\": [],\n",
        "        \"creationTime\": \"2024-09-09T07:21:50.965000+00:00\",\n",
        "        \"lastUpdatedTime\": \"2024-09-09T07:21:50.965000+00:00\"\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "aws ram associate-resource-share --resource-share arn:aws:ram:us-east-1:877417598177:resource-share/b494a4f6-4b23-477e-b395-b111b965b80a --resource-arns arn:aws:ec2:us-east-1:877417598177:transit-gateway/tgw-055fb173576ac74e0\n",
        "\n",
        "\n",
        "\n",
        "aws ram associate-resource-share --resource-share arn:aws:ram:us-east-1:877417598177:resource-share/b494a4f6-4b23-477e-b395-b111b965b80a --resource-arns arn:aws:ec2:us-east-1:877417598177:transit-gateway/tgw-055fb173576ac74e0\n",
        "\n",
        "{\n",
        "    \"resourceShareAssociations\": [\n",
        "        {\n",
        "            \"resourceShareArn\": \"arn:aws:ram:us-east-1:877417598177:resource-share/b494a4f6-4b23-477e-b395-b111b965b80a\",\n",
        "            \"associatedEntity\": \"arn:aws:ec2:us-east-1:877417598177:transit-gateway/tgw-055fb173576ac74e0\",\n",
        "            \"associationType\": \"RESOURCE\",\n",
        "            \"status\": \"ASSOCIATING\",\n",
        "            \"external\": false\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "[cloudshell-user@ip-10-134-57-9 ~]$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "select * from pg_user;\n",
        "\n",
        "drop user if exists AKumarPatra;\n",
        "\n",
        "REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA public FROM AKumarPatra;\n",
        "REVOKE ALL PRIVILEGES ON ALL SEQUENCES IN SCHEMA public FROM AKumarPatra;\n",
        "REVOKE ALL PRIVILEGES ON SCHEMA public FROM AKumarPatra;\n",
        "\n",
        "ALTER USER AKumarPatra PASSWORD 'Ironclad#1'\n",
        "\n",
        "\n",
        "pyaminipriya   Anjum---no access in redshift, Deevan, Annanta and Yogesh.\n",
        "\n",
        "AKumarPatra@IroncladEnvironmental.com\n",
        "\n",
        "YThippeswamy@IroncladEnvironmental.com--user doent exist\n",
        "\n",
        "TKumar@IroncladEnvironmental.com--user doesnt exist\n",
        "UPushpanjali@IroncladEnvironmental.com\n",
        "APraveen@IroncladEnvironmental.com\n",
        "PYaminipriya@IroncladEnvironmental.com\n",
        "\n",
        "\n",
        "Select * from  pg_user where usename like '%Deevan%';\n",
        "\n",
        "AWS Access Deleted ---Deevan ,Annata,Anjum,YaminiPriya,Pusjpanjali\n",
        "\n",
        "\n",
        "ALTER GROUP etl_user_group DROP USER AKumarPatra;\n",
        "drop user if exists AKumarPatra;\n",
        "\n",
        "-- Revoke database access\n",
        "REVOKE ALL PRIVILEGES ON DATABASE ice_edh FROM UPushpanjali;\n",
        "\n",
        "-- Revoke schema access\n",
        "REVOKE ALL PRIVILEGES ON SCHEMA ice_edh FROM UPushpanjali;----\n",
        "\n",
        "-- Revoke access on all existing tables\n",
        "REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA ice_edh FROM APraveen;-----\n",
        "\n",
        "-- Revoke access on future tables (default privileges)\n",
        "ALTER DEFAULT PRIVILEGES IN SCHEMA ice_edh REVOKE ALL ON TABLES FROM UPushpanjali;----\n",
        ","
      ],
      "metadata": {
        "id": "aqkwxMQ32GjM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Creating Volumes and attaching it to the servers and optimizing existing EBS volumes of all the instances in AWS  \n",
        "Automating the AWS instance maintenance activities and Conversion of Instance type  of AWS instances based on the project requirement\n",
        "Maintaining and troubleshooting linux instances and applying patches based on recommendations.\n",
        "Provided AWS admin support for all the AWS resources\n",
        "AWS infrastructure and Application Support activities\n",
        "Analyzing and troubleshooting the production issues\n",
        "Planned and Migrated On-Prem(VMware) Applications to AWS Cloud using Cloud Endure Tool.\n",
        "AWS Design, Implementation and support\n",
        "Conversion of tenency of AWS instances based on the project requirement (dedicated to default)\n",
        "Analysis the existing Cloud Infrastructure inventory and initial assessment of all the services\n",
        "Cost/Security/Performance Optimization Assessment :\n",
        "Performed the assessment Using CloudCheckr tool\n",
        "Load Distribution - Creation of Load balancer\n",
        "Data Protection – Backup\n",
        "Maintaining and troubleshooting security and firewall issue in linux instances\n",
        "Collecting and analysing the AWS volumes and snapshots and recomenduing the cutormer to optimize the resources utilisation.\n",
        "Provided Admin support for the all linux instances\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\thistory\n",
        "\n",
        "\thostname;date\n",
        "\thostname date history\n",
        "\n",
        "hostname;date\n",
        "hostname,date\n",
        "\n",
        "cat /etc/hosts\n",
        "\n",
        "hostname real hostname from /etc/hosts file\n",
        "\n",
        "\tcat /etc/hosts\n",
        "\n",
        "\thostname real hostname from /etc/hosts file\n",
        "\n",
        "\n",
        "\n",
        "\t##############################################33\n",
        "\n",
        "\tdata Restoration from S3\n",
        "\n",
        "\n",
        "\n",
        "https://docs.aws.amazon.com/cli/latest/reference/s3/sync.html\n",
        "\n",
        "aws s3 sync s3://fs-prod-db-backup/file_chunk/885164289/EBSPRDDB/backuppiece/2024-05-01/9n2pinb3_386359_1_1/8ShEIGw5MkYj/ .\n",
        "\n",
        "aws s3 sync s3:// .\n",
        "\n",
        "aws s3 sync s3://fs-prod-db-backup/file_chunk/885164289/EBSPRDDB/backuppiece/2024-04-27/ .\n",
        "\n",
        "\n",
        "aws s3 sync s3://fs-prod-db-backup/ .\n",
        "\n",
        "\n",
        "aws s3 ls s3://buckname/dirname/ --summarize --recursive --human-readable\n",
        "\n",
        "aws s3 ls s3://fs-prod-db-backup/file_chunk/885164289/EBSPRDDB/backuppiece/2024-04-27/ --summarize --recursive --human-readable\n",
        "aws s3 ls s3://fs-prod-db-backup/file_chunk/885164289/EBSPRDDB/backuppiece/2024-04-28/ --summarize --recursive --human-readable\n",
        "\n",
        "01-05  27 GB\n",
        "02-05  39 GB\n",
        "\n",
        "\n",
        "30-04   1.5TB\n",
        "29-4\t1.7 TB\n",
        "28\t\t2.4\n",
        "27      .85 TB\n",
        "\n",
        "6.45 TB Level 0 backup size\n",
        "\n",
        "aws s3 ls s3://fs-prod-db-backup/file_chunk/885164289/EBSPRDDB/backuppiece/ --summarize --recursive --human-readable\n",
        "\n",
        "aws s3 ls s3://fs-prod-db-backup/ --recursive --human-readable --summarize\n",
        "\n",
        "Total Objects: 35122\n",
        "   Total Size: 60.3 TiB\n",
        "[root@milisoatest-rac1 ~]#\n",
        "\n",
        "[root@milisoatest-rac1 s3test]# aws s3 ls s3://fs-prod-db-backup/file_chunk/885164289/EBSPRDDB/backuppiece/2024-05-01/9n2pinb3_386359_1_1/8ShEIGw5MkYj/0000000001 --summarize --recursive --human-readable\n",
        "2024-04-30 19:13:55    6.7 GiB file_chunk/885164289/EBSPRDDB/backuppiece/2024-05-01/9n2pinb3_386359_1_1/8ShEIGw5MkYj/0000000001\n",
        "\n",
        "Total Objects: 1\n",
        "   Total Size: 6.7 GiB\n",
        "[root@milisoatest-rac1 s3test]#\n",
        "\n",
        "\n",
        "Estimated speed weve observed during transfer of folder was 180 mibs second\n",
        "\n",
        "sync is bettre for single file cp is good\n",
        "\n"
      ],
      "metadata": {
        "id": "5VMh81Ju2ZMZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "put /tmp/agent_installer-x86_64.sh\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "aws ec2 describe-volumes --query 'Volumes[*].{ID:VolumeId,InstanceId:Attachments[0].InstanceId,AZ:AvailabilityZone,Size:Size}' --output table\n",
        "describe-volumes &#8212; AWS CLI 1.31.13 Command Reference\n",
        "docs.aws.amazon.com\n",
        "\n",
        "https://docs.aws.amazon.com/cli/latest/reference/ec2/describe-volumes.html\n",
        "\n",
        "\n",
        "EBS-GitLab-PP - ami volume (/dev/sdf)\n",
        "snap-0f114339b41bcff0d\t50 GiB\tCreated by CreateImage(i-062bc4dee45c7956d) for ami-03288332d293ed1b3\tStandard\tCompleted\t2023/10/31 11:31 GMT+5:30\tAvailable (100%)\tNot encrypted\t–\t–\t–\n",
        "EBS-GitLab-PP - ami volume (/dev/sda1)\n",
        "snap-0fbd87612b7ac3202\t50 GiB\tCreated by CreateImage(i-062bc4dee45c7956d) for ami-03288332d293ed1b3\n",
        "\n",
        " ssh -i jumphost-ebs.pem ubuntu@10.18.152.218\n",
        "\n",
        "\n",
        "\n",
        "sg-0b64d95542ef250f1 (sg_ebs-oem)\n",
        "sg-0c90d3b372b01d7a4 (sg_ebs-elb-internal)\n",
        "sg-0d2f85dd38725556a (sg_ebs-jumphost)\n",
        "\n",
        "vol-0015d45f336602d67\t/dev/sdf\t50\t Attached\t2021/12/14 09:01 GMT+5:30\tNo\t–\tNo\n",
        "vol-0d812545696bccbf5\t/dev/sda1\t50\n",
        "\n",
        "\n",
        "EBS-GitLab-Runner\tLinux\t10.18.152.68\n",
        "\n",
        "\n",
        "snap-05b8e9f6f3eb09fa4\t50 GiB\tESM_GitLab_Maintenance_Activity_01262022\tStandard\tCompleted\t2022/01/27 08:39 GMT+5:30\tAvailable (100%)\tNot encrypted\t–\t–\t–\n",
        "EBS-GitLab-PP - ami volume (/dev/sda1)\n",
        "snap-0fbd87612b7ac3202\t50 GiB\tCreated by CreateImage(i-062bc4dee45c7956d) for ami-03288332d293ed1b3\tStandard\tCompleted\t2023/10/31 11:31 GMT+5:30\tAvailable (100%)\tNot encrypted\t–\t–\t–\n",
        "–\n",
        "snap-0846e36cf1179f9f5\t50 GiB\tEBS-GitLab-PP_10.18.152.214_SS_BKP_July_082023"
      ],
      "metadata": {
        "id": "5a4vqjWD23QS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[1] How do I troubleshoot InsufficientInstanceCapacity errors when starting or launching an EC2 instance? - https://repost.aws/knowledge-center/ec2-insufficient-capacity-errors\n",
        "\n",
        "[2] Insufficient instance capacity - https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/troubleshooting-launch.html#troubleshooting-launch-capacity\n",
        "\n",
        "[3] Tenancy conversion - https://docs.aws.amazon.com/license-manager/latest/userguide/conversion-tenancy.html\n",
        "\n",
        "[4] describe-images - https://docs.aws.amazon.com/cli/latest/reference/ec2/describe-images.html\n",
        "\n",
        "[5] List EBS snapshots using the AWS CLI - https://repost.aws/knowledge-center/ebs-snapshots-list\n",
        "\n",
        "\n",
        "\n",
        "miliebsnonprd-sftp.millicom.com\t\t10.18.150.164\n",
        "\n",
        "EBS-NONPRD-SFTP  i-076083ec9065a4152  \n",
        "\n",
        "/dev/sda1\n",
        "\n",
        "vol-05ee92200836869ef\t/dev/sda1\n",
        "\n",
        "EBS-NONPRD-SFTP_/dev/sda1_12Sep2023\n",
        "\n",
        "\n",
        "miliebspreprd-app2.millicom.com\t\t10.18.150.232\n",
        "\n",
        "EBS-EBSPREPRD-APP2  i-00420c8d5bbc3bff8\n",
        "\n",
        "/dev/sda1\n",
        "\n",
        "vol-0d249361ca7c0e7a8\t/dev/sda1\n",
        "\n",
        "EBS-EBSPREPRD-APP2_/dev/sda1_12Sep2023\n",
        "\n",
        "\n",
        "aws ec2 modify-instance-placement --instance-id i-0bdcbf1ff195522ec --tenancy default\n",
        "\n",
        "Access key\n",
        "\n",
        "AKIAWP64UY6GIZHA36C2\n",
        "\n",
        "Secret access key\n",
        "\n",
        "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\n",
        "\n",
        "########################################################################################\n",
        "\n",
        "aws ec2 modify-instance-placement --instance-id i-076083ec9065a4152 --tenancy default\n",
        "\n",
        "aws ec2 modify-instance-placement --instance-id i-00420c8d5bbc3bff8 --tenancy default\n",
        "\n",
        "########################################################################################\n",
        "\n",
        "\n",
        "aws ec2 modify-instance-placement --instance-id i-00420c8d5bbc3bff8 --tenancy default\n",
        "\n",
        "C:\\Users\\Ramudu.nagella>\n",
        "C:\\Users\\Ramudu.nagella>aws ec2 modify-instance-placement --instance-id i-076083ec9065a4152 --tenancy default\n",
        "\n",
        "SSL validation failed for https://ec2.us-east-1.amazonaws.com/ [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1002)\n",
        "\n",
        "C:\\Users\\Ramudu.nagella>aws ec2 modify-instance-placement --instance-id i-00420c8d5bbc3bff8 --tenancy default\n",
        "\n",
        "SSL validation failed for https://ec2.us-east-1.amazonaws.com/ [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1002)\n",
        "\n",
        "\n",
        "\n",
        "Tenancy conversion - AWS License Manager\n",
        "docs.aws.amazon.com\n",
        "https://docs.aws.amazon.com/license-manager/latest/userguide/conversion-tenancy.html\n",
        "\n",
        "\n",
        "https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html#getting-started-install-instructions\n",
        "\n",
        "https://docs.aws.amazon.com/license-manager/latest/userguide/conversion-troubleshooting.html\n",
        "\n",
        "https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html#getting-started-install-instructions\n",
        "\n",
        "\n",
        "\n",
        "To resolve this issue , you can try the following steps:\n",
        "\n",
        "\n",
        "\n",
        "Check system time and date: Ensure that the system time and date on the machine running the AWS CLI are accurate. An incorrect system time can cause SSL certificate verification failures.\n",
        "\n",
        "\n",
        "\n",
        "Update the AWS CLI: Make sure you are using the latest version of the AWS CLI. Older versions may have compatibility issues with SSL certificates. You can update the AWS CLI by running the command pip install --upgrade awscli.\n",
        "\n",
        "\n",
        "\n",
        "Verify network connectivity: Ensure that you have a stable internet connection and that there are no network issues preventing the AWS CLI from connecting to the server. You can try accessing the URL \"https://ec2.us-east-1.amazonaws.com/\" using a web browser to check if it is accessible.\n",
        "\n",
        "\n",
        "\n",
        "Check proxy settings: If you are using a proxy server, verify that the proxy settings are correctly configured in the AWS CLI configuration file (~/.aws/config or %USERPROFILE%\\.aws\\config on Windows). Make sure the proxy server's SSL certificate is trusted by the AWS CLI.\n",
        "\n",
        "\n",
        "\n",
        "Verify SSL certificate chain: If you have access to the SSL certificate chain for the server, you can manually verify it using OpenSSL. Run the following command to check the certificate chain:\n",
        "\n",
        "\n",
        "\n",
        "openssl s_client -showcerts -connect ec2.us-east-1.amazonaws.com:443\n",
        "This command will display the SSL certificate chain for the server. Check if the chain is complete and if any intermediate certificates are missing.\n",
        "\n",
        "\n",
        "\n",
        "Disable SSL verification (not recommended): As a last resort, you can disable SSL verification in the AWS CLI configuration file. However, this is not recommended as it compromises the security of the connection. To disable SSL verification, add the following line to the [default] section of the AWS CLI configuration file:\n",
        "\n",
        "\n",
        "\n",
        "verify_ssl = false\n",
        "Again, this is not recommended and should only be used as a temporary solution for testing purposes.\n",
        "\n",
        "\n",
        "\n",
        "If none of the above steps resolve the issue, it may be necessary to contact AWS support for further assistance. They can provide more specific guidance based on your specific setup and configuration.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "[root@globaloem ~]# fdisk -l\n",
        "\n",
        "Disk /dev/nvme2n1: 644.2 GB, 644245094400 bytes, 1258291200 sectors\n",
        "Units = sectors of 1 * 512 = 512 bytes\n",
        "Sector size (logical/physical): 512 bytes / 4096 bytes\n",
        "I/O size (minimum/optimal): 4096 bytes / 4096 bytes\n",
        "Disk label type: dos\n",
        "Disk identifier: 0xe7f1f523\n",
        "\n",
        "        Device Boot      Start         End      Blocks   Id  System\n",
        "/dev/nvme2n1p1            2048  1258291199   629144576   83  Linux\n",
        "\n",
        "Disk /dev/nvme0n1: 137.4 GB, 137438953472 bytes, 268435456 sectors\n",
        "Units = sectors of 1 * 512 = 512 bytes\n",
        "Sector size (logical/physical): 512 bytes / 4096 bytes\n",
        "I/O size (minimum/optimal): 4096 bytes / 4096 bytes\n",
        "Disk label type: dos\n",
        "Disk identifier: 0x30244d31\n",
        "\n",
        "        Device Boot      Start         End      Blocks   Id  System\n",
        "/dev/nvme0n1p1            2048   268435422   134216687+  83  Linux\n",
        "\n",
        "Disk /dev/nvme1n1: 644.2 GB, 644245094400 bytes, 1258291200 sectors\n",
        "Units = sectors of 1 * 512 = 512 bytes\n",
        "Sector size (logical/physical): 512 bytes / 4096 bytes\n",
        "I/O size (minimum/optimal): 4096 bytes / 4096 bytes\n",
        "Disk label type: dos\n",
        "Disk identifier: 0xe7f1f523\n",
        "\n",
        "        Device Boot      Start         End      Blocks   Id  System\n",
        "/dev/nvme1n1p1            2048  1258291199   629144576   83  Linux\n",
        "\n",
        "Disk /dev/nvme3n1: 128.8 GB, 128849018880 bytes, 251658240 sectors\n",
        "Units = sectors of 1 * 512 = 512 bytes\n",
        "Sector size (logical/physical): 512 bytes / 4096 bytes\n",
        "I/O size (minimum/optimal): 4096 bytes / 4096 bytes\n",
        "\n",
        "\n",
        "Disk /dev/nvme4n1: 483.2 GB, 483183820800 bytes, 943718400 sectors\n",
        "Units = sectors of 1 * 512 = 512 bytes\n",
        "Sector size (logical/physical): 512 bytes / 4096 bytes\n",
        "I/O size (minimum/optimal): 4096 bytes / 4096 bytes\n",
        "\n",
        "You have new mail in /var/spool/mail/root\n",
        "[root@globaloem ~]# fdisk /dev/nvme4n1\n",
        "Welcome to fdisk (util-linux 2.23.2).\n",
        "\n",
        "Changes will remain in memory only, until you decide to write them.\n",
        "Be careful before using the write command.\n",
        "\n",
        "Device does not contain a recognized partition table\n",
        "Building a new DOS disklabel with disk identifier 0xd3bd258d.\n",
        "\n",
        "The device presents a logical sector size that is smaller than\n",
        "the physical sector size. Aligning to a physical sector (or optimal\n",
        "I/O) size boundary is recommended, or performance may be impacted.\n",
        "\n",
        "Command (m for help): p\n",
        "\n",
        "Disk /dev/nvme4n1: 483.2 GB, 483183820800 bytes, 943718400 sectors\n",
        "Units = sectors of 1 * 512 = 512 bytes\n",
        "Sector size (logical/physical): 512 bytes / 4096 bytes\n",
        "I/O size (minimum/optimal): 4096 bytes / 4096 bytes\n",
        "Disk label type: dos\n",
        "Disk identifier: 0xd3bd258d\n",
        "\n",
        "        Device Boot      Start         End      Blocks   Id  System\n",
        "\n",
        "Command (m for help): n\n",
        "Partition type:\n",
        "   p   primary (0 primary, 0 extended, 4 free)\n",
        "   e   extended\n",
        "Select (default p): p\n",
        "Partition number (1-4, default 1): 1\n",
        "First sector (2048-943718399, default 2048):\n",
        "Using default value 2048\n",
        "Last sector, +sectors or +size{K,M,G} (2048-943718399, default 943718399):\n",
        "Using default value 943718399\n",
        "Partition 1 of type Linux and of size 450 GiB is set\n",
        "\n",
        "Command (m for help): p\n",
        "\n",
        "Disk /dev/nvme4n1: 483.2 GB, 483183820800 bytes, 943718400 sectors\n",
        "Units = sectors of 1 * 512 = 512 bytes\n",
        "Sector size (logical/physical): 512 bytes / 4096 bytes\n",
        "I/O size (minimum/optimal): 4096 bytes / 4096 bytes\n",
        "Disk label type: dos\n",
        "Disk identifier: 0xd3bd258d\n",
        "\n",
        "        Device Boot      Start         End      Blocks   Id  System\n",
        "/dev/nvme4n1p1            2048   943718399   471858176   83  Linux\n",
        "\n",
        "Command (m for help): w\n",
        "The partition table has been altered!\n",
        "\n",
        "Calling ioctl() to re-read partition table.\n",
        "Syncing disks.\n",
        "You have new mail in /var/spool/mail/root\n",
        "[root@globaloem ~]#\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "[root@globaloem ~]# lsblk\n",
        "NAME        MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT\n",
        "nvme0n1     259:1    0  128G  0 disk\n",
        "└─nvme0n1p1 259:3    0  128G  0 part /\n",
        "nvme3n1     259:6    0  120G  0 disk [SWAP]\n",
        "nvme2n1     259:0    0  600G  0 disk\n",
        "└─nvme2n1p1 259:2    0  600G  0 part /u01\n",
        "nvme1n1     259:4    0  600G  0 disk\n",
        "└─nvme1n1p1 259:5    0  600G  0 part /u02\n",
        "nvme4n1     259:7    0  450G  0 disk\n",
        "└─nvme4n1p1 259:8    0  450G  0 part\n",
        "[root@globaloem ~]#\n",
        "\n",
        "\n",
        "[root@globaloem ~]# lsblk\n",
        "NAME        MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT\n",
        "nvme0n1     259:1    0  128G  0 disk\n",
        "└─nvme0n1p1 259:3    0  128G  0 part /\n",
        "nvme3n1     259:6    0  120G  0 disk [SWAP]\n",
        "nvme2n1     259:0    0  600G  0 disk\n",
        "└─nvme2n1p1 259:2    0  600G  0 part /u01\n",
        "nvme1n1     259:4    0  600G  0 disk\n",
        "└─nvme1n1p1 259:5    0  600G  0 part /u02\n",
        "nvme4n1     259:7    0  450G  0 disk\n",
        "You have new mail in /var/spool/mail/root\n",
        "[root@globaloem ~]# fdisk -l\n",
        "\n",
        "[root@globaloem ~]# mkfs -t ext4 -L dos /dev/nvme4n1\n",
        "mke2fs 1.45.4 (23-Sep-2019)\n",
        "Found a dos partition table in /dev/nvme4n1\n",
        "Proceed anyway? (y,N) y\n",
        "Creating filesystem with 117964800 4k blocks and 29491200 inodes\n",
        "Filesystem UUID: 1b134626-9e83-4556-9f23-62659c1d7953\n",
        "Superblock backups stored on blocks:\n",
        "        32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208,\n",
        "        4096000, 7962624, 11239424, 20480000, 23887872, 71663616, 78675968,\n",
        "        102400000\n",
        "\n",
        "Allocating group tables: done\n",
        "Writing inode tables: done\n",
        "Creating journal (262144 blocks): done\n",
        "Writing superblocks and filesystem accounting information: done\n",
        "\n",
        "You have new mail in /var/spool/mail/root\n",
        "[root@globaloem ~]#\n",
        "\n",
        "[root@globaloem ~]# blkid\n",
        "/dev/nvme0n1p1: LABEL=\"/\" UUID=\"ed005105-a243-4b79-bfc0-a9f4e3d4d9b4\" TYPE=\"ext4\"\n",
        "/dev/nvme3n1: UUID=\"95a0aebd-ffd7-4f4c-b77e-2b7d1bcfb35c\" TYPE=\"swap\"\n",
        "/dev/nvme2n1p1: UUID=\"6515a51f-88a2-4d64-89c7-063d5f1ee5b9\" TYPE=\"ext4\"\n",
        "/dev/nvme1n1p1: UUID=\"8797d0ff-0528-4089-bec4-f7907fe296f9\" TYPE=\"ext4\"\n",
        "/dev/nvme2n1: PTTYPE=\"dos\"\n",
        "/dev/nvme0n1: PTTYPE=\"dos\"\n",
        "/dev/nvme1n1: PTTYPE=\"dos\"\n",
        "/dev/nvme4n1: LABEL=\"dos\" UUID=\"1b134626-9e83-4556-9f23-62659c1d7953\" TYPE=\"ext4\"\n",
        "[root@globaloem ~]#\n",
        "\n",
        "UUID=1b134626-9e83-4556-9f23-62659c1d7953    /u03            ext4   defaults     0 0\n",
        "\n",
        "https://docs.oracle.com/en/learn/file_system_linux_8/#task-7-mount-the-file-systems\n",
        "\n",
        "https://oracle-base.com/articles/linux/linux-disk-partitioning\n",
        "\n",
        "https://oracle-base.com/articles/linux/linux-disk-partitioning\n",
        "\n"
      ],
      "metadata": {
        "id": "x6VjaAGU36Ne"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hi Team,\n",
        "\n",
        "We have applied patches in the given order for all non-PRD environments. Please find the attached log files for the list of OS patches installed.\n",
        "\n",
        "Public Comment:\n",
        "\n",
        "\n",
        "Regards\n",
        "Ram\n",
        "\n",
        "ALB\n",
        "ALB works on Layer 7 of OSI Layer\n",
        "\n",
        "Components of LB\n",
        "\n",
        "\t1) Load BAlancer  Which will serve as Single point of contact for all the requests are coming in and LB will\n",
        "\t  will distribute these in coming  requests or application traffic across multiple target and\n",
        "\t  these target will be EC2 instances or IPS or Lambda functions or containers etc\n",
        "\n",
        "\t2)Listener--Listener will be the process which will check incoming request based on the protocol or port whcih we configured\n",
        "\t  There will be rules defined in the listeners .Every listener default rule defined\n",
        "\t  Based on these rules LB will routhe the traffic\n",
        "\t  \n",
        "\t3) Target Group   \n",
        "\t  \n",
        "\t  We can also health checks on each target group whether these are healthy to recieve the traffic or not\n",
        "\t   \n",
        "\t   LB of E-Copmmerce company\n",
        "\t   \n",
        "\t   Here we need to  create three EC2 instances\n",
        "\t   one for each below\n",
        "\t  /Images  /register /cart\n",
        "\t  \n",
        "\t  \n",
        "\n",
        "Based on port or based on file\n",
        "\n",
        "Orders and payments two listners when to route traffic to orders and payements\n",
        "\n",
        "Routing can happen based on the path\n",
        "\n",
        "When request comes to the ALB and containing orders int the path it is routed to orders microservice or target group\n",
        "\n",
        "in the same the routig decission can be made based on port also i.e when request comes to  the ALB on port 80 route traffic to orders\n",
        "\n",
        "like that we can have another rule for payments also\n",
        "\n",
        "create two target groups with one instance in each target group\n",
        "\n",
        "Create instcnes select VPC ,Subnet and ensure public ip enabled\n",
        "\n",
        "\n",
        "In advacned section we can create a user script to install Apache and start the service\n",
        "\n",
        "AWS console Create Load Balancer\n",
        "\n",
        "1) Configure LB\n",
        "  Name, Internet facing or internal Listner of this LB is port 80\n",
        "  VPC ,Availability Zone The instances of LB should be in one of the availability zones\n",
        "  443 (HTTPS, ACM Certificate: 7c3e51b9-bab7-4059-ac3a-b7269503ee07) forwarding to 8000 (HTTP)\n",
        "  \n",
        "  443 (HTTPS, ACM Certificate: 430b7d6d-4054-4b6f-bd73-79eb94ec553f) forwarding to 4443 (HTTPS)\n",
        "2) Configure Securoty Settings\n",
        "   Any SSL certificates\n",
        "3) Configure Security Groups\n",
        "   Select or create SG ALB listening on 80\n",
        "4) Configure Routing\n",
        "   Target group Select existing target group\n",
        "   Name orders/payments\n",
        "5) Register Target  \n",
        "   Register ,Review and submit  \n",
        "6) Review and submit\n",
        "   \n",
        "   \n",
        "   select the LB and go to listeners it had addd listener on port 80 and see the rules tab Click on view or edit rules\n",
        "   \n",
        "   add two rules one for order and another payments\n",
        "   click on insert rules\n",
        "   Rule ID IF and THEN\n",
        "   Path-----forward to if path contains Order and then request must be forwarded to Orders and then save this rule\n",
        "   \n",
        "   /Orders*   Orders\n",
        "   \n",
        "   Same sttings for Payment also\n",
        "   \n",
        "   and default rule and now the status of targets \twill be healthy\n",
        "   \n",
        "   Go ALB and take DNS name and browse in Browser ALB/Orders or LB DNS /Payments\n",
        "   \n",
        "\n",
        "\n",
        "#!/bin/bash\n",
        "yum install httpd -y\n",
        "systemctl enable httpd\n",
        "mkdir /var/www/html/orders/\n",
        "\n",
        "echo \"<h1>This is Orders App</h1> /var/www/html/oredrs/index.htnl\n",
        "systemctl start httpd\n",
        "\n",
        "Create two instancs one for orders and another for payments\n",
        "\n",
        "\n",
        "Create target groups from Load balancer in the AWS console\n",
        "\n",
        "click on create target group name one should be oredrs and other will be payments\n",
        "\n",
        "target type can be instance or IP\n",
        "\n",
        "After creating target group we have to register targets\n",
        "\n",
        "Click target\n",
        "and edit\n",
        "\n",
        "Now targets status is unused  as targets are ready \tbecause it is not used by any ALB\n",
        "\n",
        "Next step is to create ALB\n",
        "\n",
        "Below are the high level steps to configure ALB\n",
        "\n",
        "1) Configure ALB with ports 80 and 443\n",
        "  \n",
        "2) Configure Securoty Settings of ALB - SSL certificates to be updated as per the client request\n",
        "3) Configure Security Groups\n",
        "   Select or create SG for ALB based ont he requirement\n",
        "4) Configure Routing --ALB to traffic to be routed below host\n",
        "   <host>10.18.152.42</host>\n",
        "   <port>7778</port>\n",
        "\n",
        "\n",
        "Added\n",
        "# REQUIRED (for Insight Agent): watch for execve syscalls, change to arch=b32 for 32 bit systems\n",
        "-a always,exit -F arch=b64 -S execve -F key=execve\n",
        "\n",
        "We have taken the backup of the configuration files as suggeted and followed the document, upon restarting the services getting below exception.\n",
        "\n",
        "Error == Job for auditd.service failed because the control process exited with error code. See \"systemctl status auditd.service\" and \"journalctl -xe\" for details.\n",
        "\n",
        "\n",
        "Below are the details\n",
        "\n",
        "[root@miliebsdev-app1 plugins.d]# service auditd start\n",
        "Redirecting to /bin/systemctl start auditd.service\n",
        "Job for auditd.service failed because the control process exited with error code. See \"systemctl status auditd.service\" and \"journalctl -xe\" for details.\n",
        "[root@miliebsdev-app1 plugins.d]# systemctl statusb auditd.service\"\n",
        "> ^C\n",
        "[root@miliebsdev-app1 plugins.d]# systemctl status auditd.service\n",
        "● auditd.service - Security Auditing Service\n",
        "   Loaded: loaded (/usr/lib/systemd/system/auditd.service; enabled; vendor preset: enabled)\n",
        "   Active: failed (Result: exit-code) since Mon 2023-09-04 10:01:45 CST; 50s ago\n",
        "     Docs: man:auditd(8)\n",
        "           https://github.com/linux-audit/audit-documentation\n",
        "  Process: 621 ExecStart=/sbin/auditd (code=exited, status=1/FAILURE)\n",
        " Main PID: 679 (code=exited, status=0/SUCCESS)\n",
        "\n",
        "Sep 04 10:01:45 miliebsdev-app1.millicom.com systemd[1]: Starting Security Auditing Service...\n",
        "Sep 04 10:01:45 miliebsdev-app1.millicom.com auditd[622]: Started dispatcher: /sbin/audispd pid: 624\n",
        "Sep 04 10:01:45 miliebsdev-app1.millicom.com auditd[622]: Error setting audit daemon pid (File exists)\n",
        "Sep 04 10:01:45 miliebsdev-app1.millicom.com auditd[622]: Unable to set audit pid, exiting\n",
        "Sep 04 10:01:45 miliebsdev-app1.millicom.com systemd[1]: auditd.service: control process exited, code=exited status=1\n",
        "Sep 04 10:01:45 miliebsdev-app1.millicom.com audispd[624]: Missing equal sign for line 15 in /etc/audisp/plugins.d/syslog.conf\n",
        "Sep 04 10:01:45 miliebsdev-app1.millicom.com systemd[1]: Failed to start Security Auditing Service.\n",
        "Sep 04 10:01:45 miliebsdev-app1.millicom.com systemd[1]: Unit auditd.service entered failed state.\n",
        "Sep 04 10:01:45 miliebsdev-app1.millicom.com systemd[1]: auditd.service failed.\n",
        "\n",
        "\n",
        "[root@miliebsdev-app1 plugins.d]# cat syslog.conf\n",
        "# This file controls the configuration of the syslog plugin.\n",
        "# It simply takes events and writes them to syslog. The\n",
        "# arguments provided can be the default priority that you\n",
        "# want the events written with. And optionally, you can give\n",
        "# a second argument indicating the facility that you want events\n",
        "# logged to. Valid options are LOG_LOCAL0 through 7, LOG_AUTH,\n",
        "# LOG_AUTHPRIV, LOG_DAEMON, LOG_SYSLOG, and LOG_USER.\n",
        "\n",
        "active = no\n",
        "direction = out\n",
        "path = builtin_syslog\n",
        "type = builtin\n",
        "args = LOG_LOCAL6\n",
        "format = string\n",
        "local6.* @@10.18.8.41\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "List of\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "1)\tsnapshot of instances and shutting down the instances .\n",
        "2)\tOptimizing existing EBS volumes of all the instances in AWS\n",
        "3)\tSetup Load balancers in AWS and move the traffic from OTD to ELB\n",
        "4)\tOracle Clone activities to done through AWS using AWS backup /AMI’s .\n",
        "5)  Creatinmg Volumes and attatching it to the servers\n",
        "6)  Conversion of Instance type  of AWS instances from old to new and new to old\n",
        "7)  Uploading new S3 keys to users in all the instances\n",
        "8)  Raising support requests with AWS for amy issues .\n",
        "9)  Automating the AWS instcnes start/stop activities\n",
        "10) Linux admin support activities\n",
        "11) Linux Quarterly patching analysis and implementation( More than 50 Linux servers)\n",
        "12) Troubleshooting Linux File system Issues\n",
        "13) Linux Security and firewall configuratuon\n",
        "14) Installing and configuring third party application tools\n",
        "15) Linux Mailx server issues\n",
        "16) Normal daily support activities from client if any\n",
        "17) Attendng All Client calls (24*7)\n",
        "18) Analysing and optimizing the AWS resources\n",
        "19) Preparing and uploading SOP in share point for all the activities\n",
        "20) Sharing the knowledge with team members for all the activites\n",
        "21) Supporting the client round the clock (24*7) including weekends and public holidays also .\n",
        "22)\n",
        "\n",
        "sendmail\n",
        "sendmail-cf\n",
        "procmail\n",
        "mailx\n",
        "yum install procmail mailx sendmail sendmail-cf -y\n",
        "\n",
        "or   check using rpm -qa | grep mail\n",
        "config file for sendmail are in /etc/mail\n",
        "sensmail.mc and sendmail.cf\n",
        "authinfo file\n",
        "AuthInfo:localhost.localdomain \"U:root\" \"I:myuser@att.net\" \"P:password\" \"M:LOGIN PLAIN\"\n",
        "\n",
        "changes in sendmail.mc\n",
        "\n",
        "\n",
        "dnl#\n",
        "define \t('SMART_HOST',`smtp.gmail.com`)\n",
        "FEATURE('authinfo')\n",
        "dnl#\n",
        "\n",
        "#m4 sendmail.mc >sendmail.cf\n",
        "#makemap hash authinfo <authinfo\n",
        "#systemctl restart/start sendmail\n",
        "#\n",
        "\n",
        "Change the tenancy of an instance using the AWS CLI\n",
        "An instance must be in the stopped state in order to change its tenancy.\n",
        "\n",
        "1) Already the insatcne is in stop state .\n",
        "2) Taking Snapshot backup of the instance\n",
        "3) using the below command we can change the instance type\n",
        "\n",
        "aws ec2 modify-instance-placement --instance-id i-0bdcbf1ff195522ec --tenancy default\n",
        "\n",
        "4) After successfull conversion of tenancy confirmation in EC2 console , we can start the instance .\n",
        "5) if the instance is not started we can revert back to dediacted  and we do have backup as well to restore it .\n",
        "\n",
        "EBS-OPC-OBI-PRD-App1\n",
        "i-0bdcbf1ff195522ec\n",
        "\n",
        "aws ec2 describe-images --region us-east-1\n",
        "\n",
        "https://repost.aws/knowledge-center/ebs-snapshots-list\n",
        "https://docs.aws.amazon.com/license-manager/latest/userguide/conversion-tenancy.html\n",
        "https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/dedicated-instance.html#dedicatedreservedinstances\n",
        "\n",
        "EBS-OPC-OBI-PRD-App1_/dev/sda1_06Sep2023\n",
        "\n",
        "\n",
        "vol-0f7ec96691f4419e4\t/dev/sda1\n",
        "\n",
        "aws ec2 describe-images --output text >> images.csv\n",
        "\n",
        "Instance:\n",
        "\n",
        "aws ec2 describe-instances \\\n",
        "    --filters Name=instance-state-name,Values=running \\\n",
        "    --query 'Reservations[*].Instances[*].{Name:Tags[?Key==`Name`]|[0].Value,Instance:InstanceId,Type:InstanceType}' \\\n",
        "    --output text >> instances.csv\n",
        "\n",
        "\n",
        "\n",
        "Dedicated Instances - Amazon Elastic Compute Cloud\n",
        "docs.aws.amazon.com\n",
        "https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/dedicated-instance.html#dedicatedreservedinstances\n",
        "Tenancy conversion - AWS License Manager\n",
        "docs.aws.amazon.com\n",
        "https://docs.aws.amazon.com/license-manager/latest/userguide/conversion-tenancy.html\n",
        "describe-images &#8212; AWS CLI 1.29.41 Command Reference\n",
        "docs.aws.amazon.com\n",
        "https://docs.aws.amazon.com/cli/latest/reference/ec2/describe-images.html\n",
        "EBS Snapshot:\n",
        "\n",
        "https://repost.aws/knowledge-center/ebs-snapshots-list\n",
        "‹Ram›\n",
        "10:43 PM\n",
        "ami-064803e95528795f9\n",
        "Sakpal, Abhishek\n",
        "10:46 PM\n",
        "aws ec2 describe-images --region us-east-1\n",
        "aws ec2 describe-images \\   \n",
        "    --output text >> images.csv\n",
        "\n",
        "\taws ec2 describe-images --output text >> images.csv\n",
        "\n",
        "Instance:\n",
        "\n",
        "aws ec2 describe-instances \\\n",
        "    --filters Name=instance-state-name,Values=running \\\n",
        "    --query 'Reservations[*].Instances[*].{Name:Tags[?Key==`Name`]|[0].Value,Instance:InstanceId,Type:InstanceType}' \\\n",
        "    --output text >> instances.csv\n",
        "\n",
        "\thttps://docs.aws.amazon.com/AmazonECS/latest/developerguide/create-application-load-balancer.html#alb-configure-routing\n",
        "\n",
        "\thttps://docs.aws.amazon.com/elasticloadbalancing/latest/application/create-application-load-balancer.html\n",
        "\n",
        "\n",
        "Sendmail ----\n",
        "\n",
        "Hi All,\n",
        "\n",
        "We have installed and configured  the sendmail \tsuccessfully. We verified by sending test mail. Please refer attached.\n",
        "\n",
        "\n",
        "Installed:\n",
        "\n",
        "  sendmail.x86_64 0:8.14.7-6.0.1.el7\n",
        "\n",
        "Dependency Installed:\n",
        "  hesiod.x86_64 0:3.2.1-3.el7                                                     procmail.x86_64 0:3.22-36.el7_4.1\n",
        "\n",
        "Complete!\n",
        "[root@globaloem ~]# sendmail -d0.4 -bv root | grep Version\n",
        "Version 8.14.7\n",
        "\n",
        "● sendmail.service - Sendmail Mail Transport Agent\n",
        "   Loaded: loaded (/usr/lib/systemd/system/sendmail.service; enabled; vendor preset: disabled)\n",
        "   Active: inactive (dead)\n",
        "[root@globaloem ~]# systemctl start sendmail\n",
        "[root@globaloem ~]# systemctl status sendmail\n",
        "● sendmail.service - Sendmail Mail Transport Agent\n",
        "   Loaded: loaded (/usr/lib/systemd/system/sendmail.service; enabled; vendor preset: disabled)\n",
        "   Active: active (running) since Thu 2023-09-07 04:34:43 EDT; 4s ago\n",
        "  Process: 20573 ExecStart=/usr/sbin/sendmail -bd $SENDMAIL_OPTS $SENDMAIL_OPTARG (code=exited, status=0/SUCCESS)\n",
        "  Process: 20567 ExecStartPre=/etc/mail/make aliases (code=exited, status=0/SUCCESS)\n",
        "  Process: 20562 ExecStartPre=/etc/mail/make (code=exited, status=0/SUCCESS)\n",
        "\n",
        "[root@globaloem ~]# mail -s \"Test Email\" rnagella@spinnakersupport.com\n",
        "hi\n",
        "EOT\n",
        "[root@globaloem ~]#\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Linux\n",
        "\n",
        "aws ec2 describe-snapshots --owner-ids self --query \"Snapshots[*].{SnapshotId:SnapshotId,Description:Description,OwnerId:OwnerId,StartTime:StartTime,State:State,StorageTier:StorageTier,VolumeId:VolumeId,VolumeSize:VolumeSize,Name:Tags[?Key=='Name']|[0].Value}\" --output text | ForEach-Object { $_ -replace \"`t\", \",\" } | Out-File -Encoding UTF8 -FilePath snapshot.csv\n",
        "\n",
        "aws ec2 describe-snapshots --owner-ids self  --query \"Snapshots[*].{SnapshotId:SnapshotId,Description:Description,OwnerId:OwnerId,StartTime:StartTime,State:State,StorageTier:StorageTier,VolumeId:VolumeId,VolumeSize:VolumeSize,Name:Tags[?Key=='Name']|[0].Value}\" --output text | sed 's/\\t/,/g' >  snapshot.csv\n",
        "aws ec2 describe-snapshots --owner-ids self --query \"Snapshots[*].{SnapshotId:SnapshotId,Description:Description,OwnerId:OwnerId,StartTime:StartTime,State:State,StorageTier:StorageTier,VolumeId:VolumeId,VolumeSize:VolumeSize,Name:Tags[?Key=='Name']|[0].Value}\" --output text | ForEach-Object { $_ -replace \"`t\", \",\" } | Out-File -Encoding UTF8 -FilePath snapshot.csv\n",
        "###################################################\n",
        "\n",
        "aws ec2 describe-snapshots --owner-ids self  --query \"Snapshots[*].{SnapshotId:SnapshotId,Description:Description,OwnerId:OwnerId,StartTime:StartTime,State:State,StorageTier:StorageTier,VolumeId:VolumeId,VolumeSize:VolumeSize,Name:Tags[?Key=='Name']|[0].Value}\" --output text | sed 's/\\t/,/g' >  snapshot.csv\n",
        "\n",
        "aws ec2 describe-snapshots --owner-ids self --query \"Snapshots[*].{SnapshotId:SnapshotId,Description:Description,OwnerId:OwnerId,StartTime:StartTime,State:State,StorageTier:StorageTier,VolumeId:VolumeId,VolumeSize:VolumeSize,Name:Tags[?Key=='Name']|[0].Value}\" --output text | ForEach-Object { $_ -replace \"`t\", \",\" } | Out-File -Encoding UTF8 -FilePath snapshot.csv\n",
        "\n",
        "\n",
        "aws ec2 describe-snapshots --owner-ids self --query \"Snapshots[*].{SnapshotId:SnapshotId,Description:Description,OwnerId:OwnerId,StartTime:StartTime,State:State,StorageTier:StorageTier,VolumeId:VolumeId,VolumeSize:VolumeSize,Name:Tags[?Key=='Name']|[0].Value}\" --output text | ForEach-Object { $_ -replace \"`t\", \",\" } | Out-File -Encoding UTF8 -FilePath snapshot.csv\n",
        "\n",
        "\n",
        "aws ec2 describe-images --owners self  --query \"Images[*].{ImageId:ImageId,OwnerId:OwnerId,CreationDate:CreationDate,PlatformDetails:PlatformDetails,Name:Tags[?Key=='Name']|[0].Value}\" --output text | ForEach-Object { $_ -replace \"`t\", \",\" } | Out-File -Encoding UTF8 -FilePath ami.csv\n",
        "\n",
        "Snapshot delete command sequence\n",
        "\n",
        "Will report the details of snapshot id created from 2020-01-01 to 2020-01-04\n",
        "These will delete only EBS Snapshot but not AMI Snapshot\n",
        "aws ec2 describe-snapshots --query 'Snapshots[?(StartTime >= `2020-01-01`) && (StartTime < `2020-01-05`)].{ID:SnapshotId}' --owner-ids self --region ap-south-1 --output text > older_snapshot.txt\n",
        "\n",
        "Then Delete\n",
        "for snapshots in `cat older_snapshot.txt` ;do aws ec2 delete-snapshot --region ap-south-1 --snapshot-id $snapshot ; sleep 1 ;done\n",
        "\n",
        "\n",
        "region we should be very very careful\n",
        "\n",
        "\n",
        "https://docs.aws.amazon.com/cli/latest/reference\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "aws ec2 modify-instance-placement --instance-id i-0bdcbf1ff195522ec --tenancy default\n",
        "\n",
        "aws ec2 modify-instance-placement --instance-id i-0bdcbf1ff195522ec --tenancy default\n",
        "\n",
        "\n",
        "aws ec2 modify-instance-placement --instance-id i-0bdcbf1ff195522ec --tenancy default\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "- Verify ENA drivers are installed\n",
        "modinfo ena\n",
        "- Verify NVMe drivers are installed\n",
        "$ modinfo nvme\n",
        "$ grep 'nvme' /boot/System.map-$(uname -r)\n",
        "\n",
        "\n",
        "\n",
        "AW01EBSM01DEVELOPMENT_SS_BKP_Aug_162023\n",
        "\n",
        "ebsdevelopment_SS_BKP_Aug_162023\n",
        "Data is huge 23 volumes (size is 26 TB) and there were no old snapsots for the instance ..\n",
        "\n",
        "Most of the volumes blocks may be dirty and took long time to complete\n",
        "Dirty data that Amazon EBS copies to Amazon S3 is the most common cause for slow AMI or snapshot creation.\n",
        "Dirty data is measured by the number of blocks\n",
        "EBS-backed AMI or snapshot creation might be slow because you're copying large amounts of data to Amazon Simple Storage Service (Amazon S3).\n",
        " Many factors, such as write activity on the EBS volume, impact creation time. Therefore, creation times for snapshots vary\n",
        "\n",
        "AW01OBIEED01PP_SS_BKP_Aug_162023\n",
        "\n",
        "https://repost.aws/knowledge-center/ebs-snapshot-ec2-ami-creation-slow  \n",
        "\n",
        "aws ec2 describe-instances --instance-id <i-0d1d47cd43260f76e> --query \"Reservations[].Instances[].EnaSupport\" --region <us-east-1>\n",
        "\n",
        "aws ec2 describe-instances --instance-id i-0527c9c46020b818f --query \"Reservations[].Instances[].EnaSupport\" --region us-east-1\n",
        "aws ec2 describe-instances --instance-id i-08978013136f41ffb --query \"Reservations[].Instances[].EnaSupport\" --region us-east-1\n",
        "aws ec2 describe-instances --instance-id i-016f963c343bd784a --query \"Reservations[].Instances[].EnaSupport\" --region us-east-1\n",
        "aws ec2 describe-instances --instance-id i-0e35ea1419974af56 --query \"Reservations[].Instances[].EnaSupport\" --region us-east-1\n",
        "$ aws ec2 describe-instances --instance-id <your-instance-id> --query \"Reservations[].Instances[].EnaSupport\" --region <your-region>\n",
        "\n",
        "aws ec2 describe-instances --instance-id i-062ebad3cf37b9dfe --query \"Reservations[].Instances[].EnaSupport\" --region us-east-1\n",
        "\n",
        "# if it is enabled, then you will get the following output\n",
        "[\n",
        "    true\n",
        "]\n",
        "\n",
        "#if it is not enabled, you will get an empty array\n",
        "[]\n",
        "\n",
        "4. If ENA is not enabled, then run following command to enable it\n",
        "\n",
        "# Note: following command won't return any response\n",
        "$ aws ec2 modify-instance-attribute --instance-id <your-instance-id> --ena-support --region <your-region>\n",
        "\n",
        " aws ec2 modify-instance-attribute --instance-id i-0d1d47cd43260f76e --ena-support --region us-east-1\n",
        "\n",
        " aws ec2 modify-instance-attribute --instance-id i-062ebad3cf37b9dfe --ena-support --region us-east-1\n",
        "\n",
        "\n",
        "\n",
        "# Verify if above command was a success\n",
        "$ aws ec2 describe-instances --instance-id <your-instance-id> --query \"Reservations[].Instances[].EnaSupport\" --region <your-region>  \n",
        "[\n",
        "    true\n",
        "]\n",
        "\n",
        "$ aws ec2 describe-instances --instance-id i-0d1d47cd43260f76e --query \"Reservations[].Instances[].EnaSupport\" --region us-east-1\n",
        "\n",
        "aws ec2 describe-instances --instance-id i-062ebad3cf37b9dfe --query \"Reservations[].Instances[].EnaSupport\" --region us-east-1\n",
        "\n",
        "5. Voila! Now change your instance type if not already changed from aws console, and start the instance\n",
        "\n",
        "$ aws ec2 start-instances --instance-ids <your-instance-id> --region <your-region>\n",
        "\n",
        "Instance type available in the AWS console are different from the one mentioned in the ticket. Yuri will check and confirm .\n",
        "\n",
        "\n",
        "\n",
        "1) First we need to conenct Global protect VPN\n",
        "2) from putty connect to Bastion host (10.111.249.14)bastion.millicom.com\n",
        "3) From bastion host to connect  as Orcle Linux user use below SSH command and  Press 0 (ZERO) for oracle linux user\n",
        "4)To connect a database server you below command and replace the IP\n",
        "   ssh -i .ssh/AWS_oracle.openssh oracle@iaddress of the server(For Example ssh -i .ssh/AWS_oracle.openssh oracle@10.18.152.171)\n",
        "5) If you want to connect as root linux user Press \"1\" and  We need to get approval from Feli/Yuri\n",
        "6) To get approval connect on whatapp group or in the JIRA ticket  \n",
        "\n",
        "\n",
        "\n",
        "My name is Nithin, and I'm from the AWS Premium Support team for EC2 Linux Service. We spoke earlier today regarding your query on consolidating Snapshot details into a CSV report. Thank you for your time over the call, It was a pleasure having words with you today. As informed I'm sharing a short summary to recap our discussion over an email.  \n",
        "\n",
        "It's my understanding that multiple Snapshot's and AMI's exist within your AWS Environment and you required a report with the necessary data present. As per your use-case I had provided the appropriate AWS CLI command that successfully generated the report:\n",
        "\n",
        "     [+] Get details of EBS Snapshots\n",
        "     aws ec2 describe-snapshots --owner-ids self --query \"Snapshots[*].{SnapshotId:SnapshotId,Description:Description,OwnerId:OwnerId,StartTime:StartTime,State:State,StorageTier:StorageTier,VolumeId:VolumeId,VolumeSize:VolumeSize,Name:Tags[?Key=='Name']|[0].Value}\" --output text | ForEach-Object { $_ -replace \"`t\", \",\" } | Out-File -Encoding UTF8 -FilePath snapshot.csv\n",
        "\n",
        "     [+] Get details of AMIs\n",
        "     aws ec2 describe-images --owners self  --query \"Images[*].{ImageId:ImageId,OwnerId:OwnerId,CreationDate:CreationDate,PlatformDetails:PlatformDetails,Name:Tags[?Key=='Name']|[0].Value}\" --output text | ForEach-Object { $_ -replace \"`t\", \",\" } | Out-File -Encoding UTF8 -FilePath amidetail.csv\n",
        "\n",
        "     [+] Delete EBS snapshot's created for individual EBS volumes (Linux Based Commands)\n",
        "  \n",
        "     - The below command would retrieve snapshot IDs between the provided StartTime\n",
        "\n",
        "     aws ec2 describe-snapshots --query 'Snapshots[?(StartTime >= `2020-01-01`) && (StartTime < `2021-01-01`)].{ID:SnapshotId}' --owner-ids self --region ap-south-1 --output text > older_snapshot.txt\n",
        "\n",
        "     - Note: The below command would delete the Snapshots retrieved from the above command. Kindly proceed with caution.\n",
        "     # for snapshots in `cat older_snapshot.txt` ;do aws ec2 delete-snapshot --region ap-south-1 --snapshot-id $snapshot ; sleep 1 ;done\n",
        "\n",
        "\n",
        "     [+] Get EBS Volume details\n",
        "     aws ec2 describe-volumes --query \"Volumes[*].{ID:VolumeId,InstanceId:Attachments[0].InstanceId,VolumeType:VolumeType,VolumeSize:Size,State:State,Name:Tags[?Key=='Name']|[0].Value}\" --output text | ForEach-Object { $_ -replace \"`t\", \",\" } | Out-File -Encoding UTF8 -FilePath volumes.csv\n",
        "\n",
        "     [+] Get Instance details\n",
        "     aws ec2 describe-instances --output text --query 'Reservations[*].Instances[*].[InstanceId, InstanceType, ImageId, State.Name, LaunchTime, Placement.AvailabilityZone, Placement.Tenancy, PrivateIpAddress, PrivateDnsName, PublicDnsName, [Tags[?Key==`Name`].Value] [0][0] ]'  --output text | ForEach-Object { $_ -replace \"`t\", \",\" } | Out-File -Encoding UTF8 -FilePath instances.csv\n",
        "\n",
        "################################\n",
        "\n",
        "aws ec2 describe-volumes --query \"Volumes[*].{ID:VolumeId,InstanceId:Attachments[0].InstanceId,VolumeType:VolumeType,VolumeSize:Size,State:State,Name:Tags[?Key=='Name']|[0].Value}\" --output text > outputfilename.csv\n",
        "\n",
        "\n",
        "/home/cloudshell-user/outputfilename.csv\n",
        "\n",
        "####################################################\n",
        "     [+] Get a list of snapshot ID's associated with a particular AMI. (Replace <ami-id> with the corresponding one)\n",
        "     aws ec2 describe-images --image-ids <ami-id> --query 'Images[*].[BlockDeviceMappings[*].Ebs.SnapshotId]' --output text | ForEach-Object { $_ -replace \"`t\", \",\" } | Out-File -Encoding UTF8 -FilePath amidetail.csv\n",
        "\n",
        "I'm proceeding to resolve this case as no further action is required from our end. If you are facing any issues or having any additional queries please feel free to reach out to me by selecting the \"Web\" option and I'll be happy to work ahead with you until everything is successfully addressed.\n",
        "\n",
        "Thank you and have a great day ahead!\n",
        "\n",
        "We value your feedback. Please share your experience by rating this and other correspondences in the AWS Support Center. You can rate a correspondence by selecting the stars in the top right corner of the correspondence.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "aws ec2 describe-security-groups --query 'SecurityGroups[*].GroupId' --output text | | ForEach-Object { $_ -replace \"`t\", \",\" } | Out-File -Encoding UTF8 -FilePath SGDetails.csv\n",
        "\n",
        "\n",
        "\n",
        "aws ec2 describe-subnets --filter Name=vpc-id,Values=vpc-3ff83946 | jq -r '.Subnets[]|.SubnetId+\" \"+.CidrBlock+\" \"+(.Tags[]|select(.Key==\"Name\").Value'\n",
        "\n",
        "\n",
        "\n",
        "aws ec2 describe-instances --output text --query 'Reservations[*].Instances[*].[InstanceId, InstanceType, ImageId, State.Name, LaunchTime, Placement.AvailabilityZone, Placement.Tenancy, PrivateIpAddress, PrivateDnsName, PublicDnsName, [Tags[?Key==`Name`].Value] [0][0] ]'  --output text | ForEach-Object { $_ -replace \"`t\", \",\" } | Out-File -Encoding UTF8 -FilePath instances.csv\n",
        "\n",
        "\n",
        "\n",
        "aws ec2 describe-snapshots --query 'Snapshots[?(StartTime >= `2020-01-01`) && (StartTime < `2021-01-01`)].{ID:SnapshotId}' --owner-ids self --region ap-south-1 --output text > 2020_snapshot.csv\n",
        "\n",
        "\n",
        "aws ec2 describe-snapshots --owner-ids self --query \"Snapshots[?(StartTime >= `2020-01-01`) && (StartTime < `2021-12-31`)].{SnapshotId:SnapshotId,Description:Description,OwnerId:OwnerId,StartTime:StartTime,State:State,StorageTier:StorageTier,VolumeId:VolumeId,VolumeSize:VolumeSize,Name:Tags[?Key=='Name']|[0].Value}\" --output text | ForEach-Object { $_ -replace \"`t\", \",\" } | Out-File -Encoding UTF8 -FilePath snapshotNew2020.csv\n",
        "\n",
        "\n",
        "aws ec2 describe-snapshots --owner-ids self --query \"Snapshots[*].{SnapshotId:SnapshotId,Description:Description,OwnerId:OwnerId,StartTime:StartTime,State:State,StorageTier:StorageTier,VolumeId:VolumeId,VolumeSize:VolumeSize,Name:Tags[?Key=='Name']|[0].Value}\" --output text | ForEach-Object { $_ -replace \"`t\", \",\" } | Out-File -Encoding UTF8 -FilePath snapshot2020.csv\n",
        "\n",
        "\n",
        "aws ec2 describe-snapshots --owner-ids self --query \"Snapshots[*].{SnapshotId:SnapshotId,Description:Description,OwnerId:OwnerId,StartTime:StartTime,State:State,StorageTier:StorageTier,VolumeId:VolumeId,VolumeSize:VolumeSize,Name:Tags[?Key=='Name']|[0].Value}\" --output text |sed 's/\\t/,/g' > snapshot.csv\n",
        "\n",
        "\n",
        "sed 's/\\t/,/g' > output.csv\n",
        "\n",
        "\n",
        "\n",
        "aws ec2 describe-snapshots --query 'Snapshots[?StartTime >= `2017-06-01`].{id:SnapshotId}' --owner-ids nnnnnnnnnnn---issue is there\n",
        "\n",
        "\n",
        "aws ec2 describe-security-groups --filters Name=ip-permission.from-port,Values=22 Name=ip-permission.to-port,Values=22 Name=ip-permission.cidr,Values='0.0.0.0/0' --query \"SecurityGroups[*].[GroupName]\" --output text  | ForEach-Object { $_ -replace \"`t\", \",\" } | Out-File -Encoding UTF8 -FilePath SecurityGroups.csv\n",
        "\n",
        "\n",
        "aws ec2 describe-security-groups --filters Name=ip-permission.from-port,Values=22 Name=ip-permission.to-port,Values=22 Name=ip-permission.cidr,Values='0.0.0.0/0' --query \"SecurityGroups[*].[GroupName]\" --output text\n",
        "\n",
        "\n",
        "i-0b4179f1c7d0c5448\n",
        "\n",
        "\n",
        "\n",
        "i-0b4179f1c7d0c5448\n",
        "\n",
        "\n",
        "\n",
        "https://docs.aws.amazon.com/opensearch-service/latest/developerguide/managedomains-snapshots.html\n",
        "\n",
        "https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/snapshot-ami-policy.html\n",
        "\n",
        "\n",
        "aws ec2 describe-subnets --filters \"Name=vpc-id,Values=vpc-3ff83946\"\n",
        "\n",
        "\n",
        "aws ec2 describe-subnets --filter Name=vpcid,Values=\"vpc-3ff83946\" --query \"SubnetSummaries.sort_by(@,&Visibility.Name)[].[Visibility.Name,SubnetId,Name]\" --output table\n",
        "\n",
        "aws ec2 describe-subnets --filter Name=vpc-id,Values=vpc-3ff83946 --query 'Subnets[?MapPublicIpOnLaunch==`false`].SubnetId'\n",
        "\n",
        "aws s3api list-buckets | grep Name\n",
        "\n",
        "\n",
        "\n",
        "IAM\n",
        "S3\n",
        "Lamda\n",
        "backup\n",
        "lifecycle manager\n",
        "trusted advisor\n",
        "billing access\n",
        "cloud shell\n",
        "CloudWatch\n",
        "\n",
        "\n",
        "\n",
        "Excel reports\n",
        "\n",
        "\n",
        "\n",
        "aws s3api get-bucket-encryption --bucket awsroot\n",
        "\n",
        "\n",
        "aws s3api get-bucket-policy-status --bucket awsroot\n",
        "\n",
        "\n",
        "\n",
        "Complete inventory list\n",
        "Firewall disbaled servers\n",
        "Security groups\n",
        "Subnets\n",
        "VPC\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "10.18.152.5--EBSDB   ebsprd-db   i-0c6eed772dd187386\n",
        "\n",
        "10.18.153.232---OBIn  EBS-OBI-PRD-DB1   i-0b595f730489f649c\n",
        "10.18.152.164--SOAPRD  soaprd02  i-098078bb79fd6d84d\n",
        "\n",
        "10.18.152.155---EBSOPCPRD   EBS-OPC-EBSPRD-DB1  i-018aa84f7f55a12a0\n",
        "\n",
        "10.18.152.171---OBIOPCPRD   OPC-OBI-PRD-DB  i-0f747459d229a939b\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " The AWS CLI commands for Powershell with the requested service catalogue. I've attemtped to include as many fields as possible to construct to a CSV sheet.\n",
        "\n",
        "- VPC Details\n",
        "# aws ec2 describe-vpcs --query \"Vpcs[*].{VpcId:VpcId,DhcpOptionsId:DhcpOptionsId,OwnerId:OwnerId,InstanceTenancy:InstanceTenancy,CidrBlock:CidrBlock,State:State}\" --output text  | ForEach-Object { $_ -replace \"`t\", \",\" } | Out-File -Encoding UTF8 -FilePath vpc.csv\n",
        "\n",
        "- Subnet Details\n",
        "# aws ec2 describe-subnets --query \"Subnets[*].{SubnetId:SubnetId,CidrBlock:CidrBlock,State:State,SubnetArn:SubnetArn}\" --output text  | ForEach-Object { $_ -replace \"`t\", \",\" } | Out-File -Encoding UTF8 -FilePath subnets.csv\n",
        "\n",
        "- RouteTable Details\n",
        "# aws ec2 describe-route-tables --query \"RouteTables[*].{RouteTableId:RouteTableId,VpcId:VpcId}\" --output text  | ForEach-Object { $_ -replace \"`t\", \",\" } | Out-File -Encoding UTF8 -FilePath RouteTable.csv\n",
        "\n",
        "- Lambda Details\n",
        "# aws lambda list-functions --query \"Functions[*].{FunctionName:FunctionName,CodeSha256:CodeSha256,CodeSize:CodeSize,FunctionArn:FunctionArn,Handler:Handler,MemorySize:MemorySize,Role:Role,LastModified:LastModified,Description:Description}\" --output text  | ForEach-Object { $_ -replace \"`t\", \",\" } | Out-File -Encoding UTF8 -FilePath lambda.csv\n",
        "\n",
        "- RDS Details\n",
        "# aws rds describe-db-instances --query \"DBInstances[*].{DBInstanceIdentifier:DBInstanceIdentifier,DBInstanceClass:DBInstanceClass,Engine:Engine,DBInstanceStatus:DBInstanceStatus,MasterUsername:MasterUsername,AllocatedStorage:AllocatedStorage,InstanceCreateTime:InstanceCreateTime,PreferredBackupWindow:PreferredBackupWindow}\"  --output text  | ForEach-Object { $_ -replace \"`t\", \",\" } | Out-File -Encoding UTF8 -FilePath rds.csv\n",
        "\n",
        "- ElasticCache Details\n",
        "# aws elasticache describe-cache-clusters  --query \"CacheClusters[*].{CacheClusterId:CacheClusterId,CacheNodeType:CacheNodeType,Engine:Engine,EngineVersion:EngineVersion,CacheClusterStatus:CacheClusterStatus,NumCacheNodes:NumCacheNodes}\"  --output text  | ForEach-Object { $_ -replace \"`t\", \",\" } | Out-File -Encoding UTF8 -FilePath elasticache.csv\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "From the kernel boot log I could see that it is failing at the initramfs stage. The purpose of the initramfs is to bootstrap the system to the point where it can access the root file system.\n",
        "\n",
        "We changes the instance back to r4.4xlarge and first made a backup of the current kernel, initramfs and listed it by running the below command:\n",
        "\n",
        "cp /boot/vmlinuz-$(uname -r) /boot/vmlinuz-$(uname -r).$(date +%m-%d-%H%M%S); cp /boot/initramfs-$(uname -r).img /boot/initramfs-$(uname -r).bak.$(date +%m-%d-%H%M%S).img; ls -l /boot/ | grep 'vmlinuz*\\|initramfs*'\n",
        "\n",
        "We inspected the content of grub and initramfs to ensure that you have all the drivers. We used the ./nitro_check_script.sh to check that the NVME and ENA modules are present as well as triple checking the files in usr/lib/modules/5.4.17-2136.315.5.el7uek.x86_64/kernel/drivers and running lsmod.\n",
        "\n",
        "After suspecting that the latest ena driver was not being added to initramfs after the kernel upgrade we used the below to rebuild the initramfs that correspond to the grub config file.\n",
        "\n",
        "dracut --kver 5.4.17-2136.315.5.el7uek.x86_64 -f -v\n"
      ],
      "metadata": {
        "id": "f80BupG_4Sec"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "lsblk -o +SERIAL\n",
        "\n",
        "Restoring the instance from snapshot or AMI…\n",
        "\n",
        "1)\tCollect all the configuaration details of the instance\n",
        "EBS-GitLab-PP\ti-062bc4dee45c7956d\n",
        "\n",
        "2)\tt3.large\n",
        "3)\t446602463116 ---Zone--us-east-1a\n",
        "4)\tjumphost-ebs  SG details vpc-3ff83946   subnet-0ad76740   ami-0bedf1591d374ac30 size\n",
        "5)\tsg-0b64d95542ef250f1 (sg_ebs-oem)\n",
        "6)\tsg-0c90d3b372b01d7a4 (sg_ebs-elb-internal)\n",
        "7)\tsg-0d2f85dd38725556a (sg_ebs-jumphost)\n",
        "vol-0015d45f336602d67\n",
        "/dev/sdf\t50\t Attached\t2021/12/14 09:01 GMT+5:30\tNo\t–\tNo\n",
        "vol-0d8f7d1d396cbf3e0\n",
        "/dev/sda1\t50\t Attached\n",
        "\n",
        "\n",
        "2) Go to Snapshot and select snapshot and go to actions and  click create image from snapshot\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Fil the fields like image name ,description ,default architecture  or select what evr we want,root device name,Volume type\n",
        "\n",
        "\n",
        "\n",
        " \tEBS-GitLab-PP - ami volume (/dev/sdf)\tsnap-0f114339b41bcff0d\n",
        "50 GiB\tCreated by CreateImage(i-062bc4dee45c7956d) for ami-03288332d293ed1b3\tStandard\tCompleted\t2023/10/31 11:31 GMT+5:30\tAvailable (100%)\tNot encrypted\t–\t–\t–\n",
        " \tEBS-GitLab-PP - ami volume (/dev/sda1)\tsnap-0fbd87612b7ac3202\n",
        "50 GiB\tCreated by CreateImage(i-062bc4dee45c7956d) for ami-03288332d293ed1b3\n",
        "\n",
        "\n",
        "\n",
        "snap-05b8e9f6f3eb09fa4\t50 GiB\tESM_GitLab_Maintenance_Activity_01262022\tStandard\tCompleted\t2022/01/27 08:39 GMT+5:30\tAvailable (100%)\tNot encrypted\t–\t–\t–\n",
        "EBS-GitLab-PP - ami volume (/dev/sda1)\n",
        "snap-0fbd87612b7ac3202\t50 GiB\tCreated by CreateImage(i-062bc4dee45c7956d) for ami-03288332d293ed1b3\tStandard\tCompleted\t2023/10/31 11:31 GMT+5:30\tAvailable (100%)\tNot encrypted\t–\t–\t–\n",
        "\n",
        "Copy the image id from which we want to create instance like i-062bc4dee45c7956d\n",
        "\n",
        "Go to AMI ‘s and search for i-062bc4dee45c7956d AND select AMI and click launch instance from AMI ..\n",
        "\n",
        "\n",
        "Fill the details and Click launch instance\n",
        "\n",
        "How to replace root volume into existing instance …\n",
        "\n",
        "Select the instance\n",
        "\n",
        "\n",
        "\n",
        "Fill the details like of snapshot id of volumes . and click create replacement task.\n"
      ],
      "metadata": {
        "id": "UYsgaOGb42qO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JbwH6I8m6Jm7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Creating New VPN to access AWS applications  and resources in multiple AWS accounts through TRANSITGATE WAY.\n",
        "\n",
        "In AWS console there are six AWS accounts are there (Audit,Dev, LogArichive , MasterPayer, Production and shared) .\n",
        "But only in Prod, Shared and Dev accounts VPC ‘s created and shared among these three accounts and in other accounts there is no VPC except default\n",
        "Subnets are shared between three using Resource access manager .In the similar way we can create one TRANSITGATE WAY and share between all the AWS accounts .\n",
        "STEP1:Launch EC2 instance in on-premises VPC Created two instances one for Open and other for server\n",
        "        1)Disable source and destination checks (in open instance select the instance and go to actions -networking -change source /destination checks select stop and save )\n",
        "        2)public subnet\n",
        "        3)Security group SSH port 22 and  ICMP all port N/A\n",
        "        4)Make a note of the public IP\n",
        "STEP2::AWS VPC configuration\n",
        "         1)Launch EC2 instance\n",
        "       \n",
        "        2) Public or Private Subnet\n",
        "1)\t         3) 22 ICMP All\n",
        "OR Collect Public IP on Premises Firewall from on-Prem Network Team .\n",
        "Here in IranClad environment in the on-prem data center  they are now using FORTNET FW to access AWS and they are going to replace FORTNET FW with MEARKI FW and  access AWS application .\n",
        "\n",
        "As there are already instances are created in on-premises and AWS so no need tom create any instance and VPC .\n",
        "\n",
        "So STEP 1 and 2 not required\n",
        "\n",
        "STEP3::    ###Create a customer gateway\n",
        "Name:::AWS-VPC-CGW---\n",
        "Routing :Static\n",
        "\tIP:::Public IP of on-Premises EC2 OR MERAKI FW Public IP …156.146.110.37\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "1)\tLogin to the AWS console and search for VPC and click customer gateway in left hand side in the screen.\n",
        "\n",
        "\n",
        "\n",
        "2)\tClick on create Customer gateway on right hand side top  corner  and fill the details.\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Name ::;AWS_VPN_CGW and IP address is public IP of MERAKI FW   Public IP  and click create customer gateway.\n",
        "\n",
        "\n",
        "STEP4::: Click on TRANSIT GATEWAY….and click on create TRANSIT GATEWAY..\n",
        "\n",
        "\n",
        "\n",
        "Fill the details like name and description and remaining field will be default  and click on create transit gateway.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "STEP5:::\n",
        "1)\tClick on site-to-site\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "EC2 ==== EC2 subnet RT ==== TGW attachment RT for source VPC ==== TGW ==== TGW attachment RT for DestinationVPN ==== VPN ===== On-premise\n",
        "\n",
        "1)\tShare the transit gate way\n",
        "2)\tVPC RT 10.100.0.0/24\n",
        "3)\tTransit gateway RT 10.100.0.0/24\n"
      ],
      "metadata": {
        "id": "iTzjJOyO6QI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "Creating New VPN to access AWS applications  and resources in multiple AWS accounts through TRANSITGATE WAY.\n",
        "\n",
        "In AWS console there are six AWS accounts are there (Audit,Dev, LogArichive , MasterPayer, Production and shared) .\n",
        "But only in Prod, Shared and Dev accounts VPC ‘s created and shared among these three accounts and in other accounts there is no VPC except default\n",
        "Subnets are shared between three using Resource access manager .In the similar way we can create one TRANSITGATE WAY and share between all the AWS accounts .\n",
        "STEP1:Launch EC2 instance in on-premises VPC Created two instances one for Open and other for server\n",
        "        1)Disable source and destination checks (in open instance select the instance and go to actions -networking -change source /destination checks select stop and save )\n",
        "        2)public subnet\n",
        "        3)Security group SSH port 22 and  ICMP all port N/A\n",
        "        4)Make a note of the public IP\n",
        "STEP2::AWS VPC configuration\n",
        "         1)Launch EC2 instance\n",
        "\n",
        "        2) Public or Private Subnet\n",
        "1)\t         3) 22 ICMP All\n",
        "OR Collect Public IP on Premises Firewall from on-Prem Network Team .\n",
        "Here in IranClad environment in the on-prem data center  they are now using FORTNET FW to access AWS and they are going to replace FORTNET FW with MEARKI FW and  access AWS application .\n",
        "\n",
        "As there are already instances are created in on-premises and AWS so no need tom create any instance and VPC .\n",
        "\n",
        "So STEP 1 and 2 not required\n",
        "\n",
        "STEP3::    ###Create a customer gateway\n",
        "Name:::AWS-VPC-CGW---\n",
        "Routing :Static\n",
        "\tIP:::Public IP of on-Premises EC2 OR MERAKI FW Public IP …156.146.110.37\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "1)\tLogin to the AWS console and search for VPC and click customer gateway in left hand side in the screen.\n",
        "\n",
        "\n",
        "\n",
        "2)\tClick on create Customer gateway on right hand side top  corner  and fill the details.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Name ::;AWS_VPN_CGW and IP address is public IP of MERAKI FW   Public IP  and click create customer gateway.\n",
        "\n",
        "\n",
        "STEP4::: Click on TRANSIT GATEWAY….and click on create TRANSIT GATEWAY..\n",
        "\n",
        "\n",
        "\n",
        "Fill the details like name and description and remaining field will be default  and click on create transit gateway.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "STEP5:::\n",
        "1)\tClick on site-to-site\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "EC2 ==== EC2 subnet RT ==== TGW attachment RT for source VPC ==== TGW ==== TGW attachment RT for DestinationVPN ==== VPN ===== On-premise\n",
        "\n",
        "1)\tShare the transit gate way\n",
        "2)\tVPC RT 10.100.0.0/24\n",
        "3)\tTransit gateway RT 10.100.0.0/24\n"
      ],
      "metadata": {
        "id": "wEz_AUub6Lz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Creating New VPN to access AWS applications  and resources in multiple AWS accounts through TRANSITGATE WAY.\n",
        "\n",
        "In AWS console there are six AWS accounts are there (Audit,Dev, LogArichive , MasterPayer, Production and shared) .\n",
        "But only in Prod, Shared and Dev accounts VPC ‘s created and shared among these three accounts and in other accounts there is no VPC except default\n",
        "Subnets are shared between three using Resource access manager .In the similar way we can create one TRANSITGATE WAY and share between all the AWS accounts .\n",
        "STEP1:Launch EC2 instance in on-premises VPC Created two instances one for Open and other for server\n",
        "        1)Disable source and destination checks (in open instance select the instance and go to actions -networking -change source /destination checks select stop and save )\n",
        "        2)public subnet\n",
        "        3)Security group SSH port 22 and  ICMP all port N/A\n",
        "        4)Make a note of the public IP\n",
        "STEP2::AWS VPC configuration\n",
        "         1)Launch EC2 instance\n",
        "       \n",
        "        2) Public or Private Subnet\n",
        "1)\t         3) 22 ICMP All\n",
        "OR Collect Public IP on Premises Firewall from on-Prem Network Team .\n",
        "Here in IranClad environment in the on-prem data center  they are now using FORTNET FW to access AWS and they are going to replace FORTNET FW with MEARKI FW and  access AWS application .\n",
        "\n",
        "As there are already instances are created in on-premises and AWS so no need tom create any instance and VPC .\n",
        "\n",
        "So STEP 1 and 2 not required\n",
        "\n",
        "STEP3::    ###Create a customer gateway\n",
        "Name:::AWS-VPC-CGW---\n",
        "Routing :Static\n",
        "\tIP:::Public IP of on-Premises EC2 OR MERAKI FW Public IP …156.146.110.37\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "1)\tLogin to the AWS console and search for VPC and click customer gateway in left hand side in the screen.\n",
        "\n",
        "\n",
        "\n",
        "2)\tClick on create Customer gateway on right hand side top  corner  and fill the details.\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Name ::;AWS_VPN_CGW and IP address is public IP of MERAKI FW   Public IP  and click create customer gateway.\n",
        "\n",
        "\n",
        "STEP4::: Click on TRANSIT GATEWAY….and click on create TRANSIT GATEWAY..\n",
        "\n",
        "\n",
        "\n",
        "Fill the details like name and description and remaining field will be default  and click on create transit gateway.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "STEP5:::\n",
        "1)\tClick on site-to-site\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "EC2 ==== EC2 subnet RT ==== TGW attachment RT for source VPC ==== TGW ==== TGW attachment RT for DestinationVPN ==== VPN ===== On-premise\n",
        "\n",
        "1)\tShare the transit gate way\n",
        "2)\tVPC RT 10.100.0.0/24\n",
        "3)\tTransit gateway RT 10.100.0.0/24\n"
      ],
      "metadata": {
        "id": "am0n-OkM6X63"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        " aws ec2 describe-volumes --query \"Volumes[*].{ID:VolumeId,InstanceId:Attachments[0].InstanceId,VolumeType:VolumeType,VolumeSize:Size,State:State,Name:Tags[?Key=='Name']|[0].Value}\" --output text | sed 's/\\t/,/g' > output.csv\n",
        "\n",
        "\n",
        " aws ec2 describe-instances --output text --query 'Reservations[*].Instances[*].[InstanceId, InstanceType, ImageId, State.Name, LaunchTime, Placement.AvailabilityZone, Placement.Tenancy, PrivateIpAddress, PrivateDnsName, PublicDnsName, [Tags[?Key==`Name`].Value] [0][0] ]'  --output text | sed 's/\\t/,/g' > output2.csv\n",
        "\n",
        "\n",
        " /home/cloudshell-user/output2.csv\n",
        "\n",
        "\n",
        " Volumes\n",
        "aws ec2 describe-volumes --query \"Volumes[*].{ID:VolumeId,InstanceId:Attachments[0].InstanceId,VolumeType:VolumeType,VolumeSize:Size,State:State,Name:Tags[?Key=='Name']|[0].Value}\" --output text | sed 's/\\t/,/g' > output.csv\n",
        "\n",
        "/home/cloudshell-user/AuditVolumes.csv\n",
        "\n",
        "ProdVolumes\n",
        "DevVolumes.csv\n",
        "Instances\n",
        "aws ec2 describe-instances --output text --query 'Reservations[*].Instances[*].[InstanceId, InstanceType, ImageId, State.Name, LaunchTime, Placement.AvailabilityZone, Placement.Tenancy, PrivateIpAddress, PrivateDnsName, PublicDnsName, [Tags[?Key==`Name`].Value] [0][0] ]'  --output text | sed 's/\\t/,/g' > output2.csv\n",
        "\n",
        "Snapshots\n",
        "aws ec2 describe-snapshots --query \"Snapshots[*].{Description:Description,Tags:Tags[?Key=='Name'].Value | [0],AccountId:OwnerId,SnapshotId:SnapshotId,StartTime:StartTime,Status:State,Type:VolumeType,VolumeId:VolumeId,Size:VolumeSize}\" --output text | sed 's/\\t/,/g' > snapshot3.csv\n",
        "\n",
        "\n",
        "/home/cloudshell-user/AuditSnapshot.csv\n",
        "\n",
        "\n",
        "Security group\n",
        "aws ec2 describe-security-groups \\\n",
        "--query \"SecurityGroups[*].{GroupId:GroupId,GroupName:GroupName,VpcId:VpcId,Description:Description,OwnerId:OwnerId,InboundRuleCount:length(IpPermissions),OutboundRuleCount:length(IpPermissionsEgress),Tags:Tags[?Key=='Name']|[0].Value}\" \\\n",
        "--output json | jq -r '[\"GroupId\", \"GroupName\", \"VpcId\", \"Description\", \"OwnerId\", \"InboundRuleCount\", \"OutboundRuleCount\", \"Tags\"], (.[] | [.GroupId, .GroupName, .VpcId, .Description, .OwnerId, .InboundRuleCount, .OutboundRuleCount, .Tags]) | @csv' > security_groups.csv\n",
        "\n",
        "Security group rules\n",
        "aws ec2 describe-security-groups \\\n",
        "--query \"SecurityGroups[*].{GroupId:GroupId,GroupName:GroupName,Rules:IpPermissions[*].{Type:'inbound',IpProtocol:IpProtocol,FromPort:FromPort,ToPort:ToPort,IpRanges:IpRanges[*].CidrIp,Ipv6Ranges:Ipv6Ranges[*].CidrIpv6,PrefixListIds:PrefixListIds[*].PrefixListId,UserIdGroupPairs:UserIdGroupPairs[*].GroupId}}\" \\\n",
        "--output json | \\\n",
        "jq -r '.[] | .GroupId as $groupid | .GroupName as $groupname | .Rules[] | [$groupid, $groupname, .Type, .IpProtocol, (.FromPort // \"N/A\"), (.ToPort // \"N/A\"), (.IpRanges | join(\";\")), (.Ipv6Ranges | join(\";\")), (.PrefixListIds | join(\";\")), (.UserIdGroupPairs | join(\";\"))] | @csv' > security_group_rules.csv\n",
        "\n",
        "MPayerSGRules\n",
        "/home/cloudshell-user/AuditSGRules.csv\n",
        "\n",
        "\n",
        "Elastic IPs\n",
        "aws ec2 describe-addresses \\\n",
        "--query \"Addresses[*].{PublicIp:PublicIp,Type:Domain,AllocationId:AllocationId,ReverseDNS:PublicDns,InstanceId:InstanceId,PrivateIpAddress:PrivateIpAddress,AssociationId:AssociationId,NetworkInterfaceOwnerId:NetworkInterfaceOwnerId,Region:Region}\" \\\n",
        "--output json | \\\n",
        "jq -r '[\"PublicIp\", \"Type\", \"AllocationId\", \"ReverseDNS\", \"InstanceId\", \"PrivateIpAddress\", \"AssociationId\", \"NetworkInterfaceOwnerId\", \"Region\"], (.[] | [.PublicIp, .Type, .AllocationId, (.ReverseDNS // \"N/A\"), (.InstanceId // \"N/A\"), (.PrivateIpAddress // \"N/A\"), (.AssociationId // \"N/A\"), (.NetworkInterfaceOwnerId // \"N/A\"), .Region]) | @csv' > elastic_ips.csv\n",
        "\n",
        "/home/cloudshell-user/AuditEIP.csv\n",
        "\n",
        "Load balancer\n",
        "aws elbv2 describe-load-balancers \\\n",
        "--query \"LoadBalancers[*].{LoadBalancerName:LoadBalancerName,DNSName:DNSName,Type:Type,VpcId:VpcId,Subnets:SubnetMappings[*].SubnetId,Tags:Tags[?Key=='Name'].Value | [0]}\" \\\n",
        "--output json | \\\n",
        "jq -r '.[] | .LoadBalancerName as $lbName | .DNSName as $dns | .Type as $type | .VpcId as $vpcId | .Tags as $tag | .Subnets as $subnets | [ $lbName, $dns, $type, $vpcId, $subnets | join(\";\"), $tag ] | @csv' > load_balancers.csv\n",
        "\n",
        "\n",
        "/home/cloudshell-user/AuditLB.csv\n",
        "\n",
        "AMIs\n",
        "aws ec2 describe-images --owners self --query \"Images[*].{ImageId:ImageId,CreationDate:CreationDate,Tags:Tags[?Key=='Name'].Value | [0],AccountId:OwnerId,OS:Platform || 'Linux/Unix'}\" --output text | sed 's/\\t/,/g' > amis.csv\n",
        "\n",
        "/home/cloudshell-user/AuditAmi.csv\n",
        "\n",
        " Installing AWS CLI\n",
        "\n",
        " https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html#getting-started-install-instructions:~:text=Install%20or%20update%20the%20AWS%20CLI\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " aws ec2 describe-instances --output text --query 'Reservations[*].Instances[*].[InstanceId, InstanceType, ImageId, State.Name, LaunchTime, Placement.AvailabilityZone, Placement.Tenancy, PrivateIpAddress, PrivateDnsName, PublicDnsName, [Tags[?Key==`Name`].Value] [0][0] ]'  --output text | sed 's/\\t/,/g' > instances.csv\n",
        "\n",
        "\n",
        "aws ec2 describe-security-groups --query 'SecurityGroups[*].GroupId' --output text | sed 's/\\t/,/g' > SGDetails.csv\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "AWS CLI command for LB:\n",
        "--------------------------------\n",
        "aws elb describe-load-balancers --region <Your Region> --query ‘LoadBalancerDescriptions[*].[LoadBalancerName,DNSName,State.Code,VPCId,AvailabilityZones[].ZoneName,join(`,`, Subnets[].SubnetId),CreatedTime]’ --output text | awk ‘BEGIN {print “Name,DNS name,State,VPC ID,Availability Zones,Subnets,Date created”} {print $0}’ > LB_info.csv\n",
        "\n",
        "AWS CLI Command for AMI:\n",
        "----------------------------------\n",
        "aws ec2 describe-images --owners self --region <Your Region> --output json | jq -r ‘([“Name”, “ImageId”, “ImageType”, “OwnerId”, “Public”, “State”, “CreationDate”, “Platform”, “ImageLocation”] |\n",
        "@csv\n",
        "), (.Images[] | [.Name, .ImageId, .ImageType, .OwnerId, .Public, .State, .CreationDate, .Platform, .ImageLocation] |\n",
        "@csv\n",
        ")' > AMI_info.csv\n",
        "\n",
        "AWS CLI command for S3:\n",
        "--------------------------------\n",
        "aws s3api list-buckets --query ‘Buckets[*].[Name,Region,CreationDate,HasAccessAnalyzer]’ --output text | awk ‘BEGIN {print “Name,Region,CreationTime,AccessAnalyzer”} {OFS=“,”} NR>1 {print $1,$2,$3,$4}’ > S3_info.csv\n",
        "\n",
        "AWS CLI command for Internet gateway:\n",
        "------------------------------------------------\n",
        "aws ec2 describe-internet-gateways --query ‘InternetGateways[].{Name:Tags[?Key==`Name`]|[0].Value,InternetGatewayId:InternetGatewayId,State:Attachments[0].State,VpcId:Attachments[0].VpcId,Owner:OwnerId}’ --output=text | sed ‘s/\\t/,/g’ >> Internetgateway_info.csv\n",
        "\n",
        "################################################################################################################\n",
        "\n",
        "And for remaining below services details with CloudShell desired output is not coming, so tested powershell script and it is working, so in-order to use Powershell script on your windows test instance to achieve the desired output for remaining below services.\n",
        "\n",
        "Before executing the commands:\n",
        "a)Create a instance profile role with Administrator permissions.\n",
        "\n",
        "To Create instance profile role:\n",
        "********************************\n",
        "1] go to AWS management console\n",
        "2] search for IAM in the top search bar > click on it\n",
        "3] in the left navigation panel > click on roles under access management\n",
        "4] select create role under trusted entity type select AWS service > under use case choose EC2 and proceed with next\n",
        "5] under permission policies search for administrator access and select it and proceed with next\n",
        "6] Add a name to your role and can click on create role\n",
        "\n",
        "To Attach instance profile role:\n",
        "********************************\n",
        "1] Go to EC2 dashboard and select your test windows instance(where we installed the AWS CLI earlier over the call [1]).\n",
        "2] go to actions > under security click on modify IAM role\n",
        "3] choose the role you created previously and click on update IAM role\n",
        "\n",
        "a) open powershell with admin\n",
        "b) configured the IAM role in powershell by running following command:\n",
        "\n",
        "aws configure set role “arn”:“arn:aws:sts::{YOUR ACCOUNT ID}:assumed-role/{YOUR ROLE NAME}\n",
        "\n",
        "After configuring your role, execute the below commands in powershell to get your desired output.\n",
        "\n",
        "Elastic IP information:\n",
        "——————————--\n",
        "$allRegions = Get-EC2Region | Select-Object -ExpandProperty RegionName $elasticIPInfo = foreach ($region in $allRegions) { $addresses = Get-EC2Address -Region $region foreach ($address in $addresses) { [PSCustomObject]@{ ‘Allocated IPv4 Address’ = $address.PublicIp ‘Type’ = $address.AddressType ‘Allocation ID’ = $address.AllocationId ‘Reverse DNS Record’ = $address.PublicHostName ‘Associated Instance ID’ = $address.InstanceId ‘Private IP Address’ = $address.PrivateIpAddress ‘Association ID’ = $address.AssociationId ‘Network Interface Owner Account ID’ = $address.NetworkInterfaceOwnerId ‘Network Border Group’ = $address.NetworkBorderGroup ‘Region’ = $region } } } $elasticIPInfo | Export-Csv -Path ‘elastic_IP_info.csv’ -NoTypeInformation\n",
        "\n",
        "Subnet information:\n",
        "—————————--\n",
        "$subnets = Get-EC2Subnet | Select-Object @{Name=‘SubnetId’;Expression={$.SubnetId}}, @{Name=‘State’;Expression={$.State}}, @{Name=‘VpcId’;Expression={$.VpcId}}, @{Name=‘CidrBlock’;Expression={$.CidrBlock}}, @{Name=‘AvailableIpAddressCount’;Expression={$.AvailableIpAddressCount}}, @{Name=‘AvailabilityZone’;Expression={$.AvailabilityZone}}, @{Name=‘AvailabilityZoneId’;Expression={$.AvailabilityZoneId}}, @{Name=‘RouteTableId’;Expression={$.RouteTableId}}, @{Name=‘NetworkAclId’;Expression={$.NetworkAclId}}, @{Name=‘OwnerId’;Expression={$.OwnerId}} $subnets | Export-Csv -Path “subnet.csv” -NoTypeInformation\n",
        "\n",
        "Volumes information:\n",
        "——————————\n",
        "$allRegions = Get-EC2Region | Select-Object -ExpandProperty RegionName $volumeInfo = foreach ($region in $allRegions) { $volumes = Get-EC2Volume -Region $region | Select-Object VolumeId, @{Name=“InstanceId”;Expression={($.Attachments.InstanceId)}}, @{Name=“InstanceName”;Expression={($.Attachments.InstanceId | ForEach-Object {Get-EC2Instance -InstanceId $_ -Region $region | Select-Object -ExpandProperty Instances | Select-Object -ExpandProperty PrivateDnsName})}}, State, Size, @{Name=“VolumeType”;Expression={$_.VolumeType}}, AvailabilityZone $volumes } $volumeInfo | Export-Csv -Path “volume_info.csv” -NoTypeInformation\n",
        "\n",
        "Security group information:\n",
        "—————————————\n",
        "$sgInfo = Get-EC2SecurityGroup | Select-Object @{Name=“Name”;Expression={$.GroupName}}, @{Name=“SecurityGroupID”;Expression={$.GroupId}}, @{Name=“SecurityGroupName”;Expression={$.GroupName}}, @{Name=“VpcId”;Expression={$.VpcId}}, @{Name=“Description”;Expression={$.Description}}, @{Name=“Owner”;Expression={$.OwnerId}}, @{Name=“InboundRulesCount”;Expression={($.IpPermissions.IpRanges.Count + $.IpPermissions.UserIdGroupPairs.Count)}}, @{Name=“OutboundRulesCount”;Expression={($.IpPermissionsEgress.IpRanges.Count + $.IpPermissionsEgress.UserIdGroupPairs.Count)}} $sgInfo | Export-Csv -Path “sg.csv” -NoTypeInformation\n",
        "\n",
        "Security group inbound and outbound:\n",
        "——————————————————\n",
        "Get-EC2SecurityGroup | Select-Object -Property @{Name=“GroupId”; Expression={$.GroupId}}, @{Name=“GroupName”; Expression={$.GroupName}}, @{Name=“Type”; Expression={$.IpPermissions.IpProtocol}}, @{Name=“IpProtocol”; Expression={$.IpPermissions.IpProtocol}}, @{Name=“FromPort”; Expression={$.IpPermissions.FromPort}}, @{Name=“ToPort”; Expression={$.IpPermissions.ToPort}}, @{Name=“IpRanges”; Expression={$_.IpPermissions.IpRanges.CidrIp}} | Export-Csv -Path “sg_rules_IN_Out.csv” -NoTypeInformation\n",
        "\n",
        "Note: Output files will be saved on the directory location where you will executed the script on the powershell.\n",
        "Please verify the above commands in your test environment and please let me know how it goes.\n",
        "\n",
        "Additionally, If you would like to discuss on this case over the screen share session.Please confirm me your available time, As my shift timings are 8AM to 4PM IST Monday to Friday, accordingly I will schedule a call for further assistance on this case.\n",
        "\n",
        "I hope above information servers you well. Meanwhile, if you have any further queries or concerns, please feel free to add correspondence to this case and I’ll be more than happy to assist.\n",
        "\n",
        "Thank you and have a great day ahead.\n",
        "\n",
        "References:\n",
        "===========\n",
        "[1] https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html#getting-started-install-instructions\n",
        "\n",
        "\n",
        "\n",
        "MarriPalle Krishna ---9959410993---\n",
        "\n",
        "\n",
        "\n",
        "I don't have the permissions for checking the billing,cost and payment preferences.\n",
        "Ironclad team only have privilegess for this billing and cost services.\n",
        "\n",
        "https://console.aws.amazon.com/billing/home?#/paymentpreferences/paymentmethods.\n",
        "\n",
        "Only root user can see the card details over the above link.\n",
        "Root user  can edit the details or click over verify button to make card valid\n",
        "Once card becomes valid AWS team will retry the transaction and inform the status\n",
        "\n",
        "Also if root user can create support case for more details on this issue ."
      ],
      "metadata": {
        "id": "pn9ZAoPa6joe"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome to Colab",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}