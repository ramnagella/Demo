{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramnagella/Demo/blob/master/CountVectorization%20and%20TFDF%20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count Vectorization Steps\n",
        "\n",
        "\n",
        "step-by-step explanation of how vocabulary is created in Count Vectorization\n",
        "Step-by-Step: Vocabulary Creation in Count Vectorization\n",
        "1. Input Collection:\n",
        "a. You start with a collection of documents or sentences, called a corpus.\n",
        "b. Example:\n",
        "i. Document 1: \"I love machine learning\"\n",
        "ii. Document 2: \"Machine learning is fun\"\n",
        "2. Text Normalization (optional but typical):\n",
        "a. Convert all text to lowercase to ensure consistency.\n",
        "b. Result:\n",
        "i. \"i love machine learning\"\n",
        "ii. \"machine learning is fun\"\n",
        "3. Tokenization:\n",
        "a. Break each document into individual words (tokens).\n",
        "b. Document 1: [\"i\", \"love\", \"machine\", \"learning\"]\n",
        "c. Document 2: [\"machine\", \"learning\", \"is\", \"fun\"]\n",
        "4. Unique Word Identification:\n",
        "a. Combine tokens from all documents.\n",
        "b. Identify all unique words (this becomes your vocabulary).\n",
        "c. From the example:\n",
        "i. All tokens combined: [\"i\", \"love\", \"machine\", \"learning\", \"machine\",\n",
        "\"learning\", \"is\", \"fun\"]\n",
        "ii. Unique words (vocabulary): [\"i\", \"love\", \"machine\", \"learning\", \"is\",\n",
        "\"fun\"]\n",
        "5. Assigning Indexes to Words:\n",
        "a. Each unique word in the vocabulary is assigned a fixed index.\n",
        "b. Example:\n",
        "i. \"i\" → 0\n",
        "ii. \"love\" → 1\n",
        "iii. \"machine\" → 2\n",
        "iv. \"learning\" → 3\n",
        "v. \"is\" →\n",
        "This dictionary of word → index is the vocabulary.\n",
        "6. Result:\n",
        "a. The vocabulary is now a mapping of each unique word to an index.\n",
        "b. This vocabulary is later used to transform any input text into a count vector\n",
        "(word frequency vector).\n",
        "\n",
        "\n",
        "#############################################333\n",
        "\n",
        "Count Vectorization Steps\n",
        "step-by-step explanation of how vocabulary is created in Count Vectorization\n",
        "Step-by-Step: Vocabulary Creation in Count Vectorization\n",
        "1. Input Collection:\n",
        "a. You start with a collection of documents or sentences, called a corpus.\n",
        "b. Example:\n",
        "i. Document 1: \"I love machine learning\"\n",
        "ii. Document 2: \"Machine learning is fun\"\n",
        "2. Text Normalization (optional but typical):\n",
        "a. Convert all text to lowercase to ensure consistency.\n",
        "b. Result:\n",
        "i. \"i love machine learning\"\n",
        "ii. \"machine learning is fun\"\n",
        "3. Tokenization:\n",
        "a. Break each document into individual words (tokens).\n",
        "b. Document 1: [\"i\", \"love\", \"machine\", \"learning\"]\n",
        "c. Document 2: [\"machine\", \"learning\", \"is\", \"fun\"]\n",
        "4. Unique Word Identification:\n",
        "a. Combine tokens from all documents.\n",
        "b. Identify all unique words (this becomes your vocabulary).\n",
        "c. From the example:\n",
        "i. All tokens combined: [\"i\", \"love\", \"machine\", \"learning\", \"machine\",\n",
        "\"learning\", \"is\", \"fun\"]\n",
        "ii. Unique words (vocabulary): [\"i\", \"love\", \"machine\", \"learning\", \"is\",\n",
        "\"fun\"]\n",
        "5. Assigning Indexes to Words:\n",
        "a. Each unique word in the vocabulary is assigned a fixed index.\n",
        "b. Example:\n",
        "i. \"i\" → 0\n",
        "ii. \"love\" → 1\n",
        "iii. \"machine\" → 2\n",
        "iv. \"learning\" → 3\n",
        "v. \"is\" →\n",
        "This dictionary of word → index is the vocabulary.\n",
        "6. Result:\n",
        "a. The vocabulary is now a mapping of each unique word to an index.\n",
        "b. This vocabulary is later used to transform any input text into a count vector\n",
        "(word frequency vector).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nrhJpaO7chtN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count Vectorization Steps\n",
        "step-by-step explanation of how vocabulary is created in Count Vectorization\n",
        "Step-by-Step: Vocabulary Creation in Count Vectorization\n",
        "1. Input Collection:\n",
        "a. You start with a collection of documents or sentences, called a corpus.\n",
        "b. Example:\n",
        "i. Document 1: \"I love machine learning\"\n",
        "ii. Document 2: \"Machine learning is fun\"\n",
        "2. Text Normalization (optional but typical):\n",
        "a. Convert all text to lowercase to ensure consistency.\n",
        "b. Result:\n",
        "i. \"i love machine learning\"\n",
        "ii. \"machine learning is fun\"\n",
        "3. Tokenization:\n",
        "a. Break each document into individual words (tokens).\n",
        "b. Document 1: [\"i\", \"love\", \"machine\", \"learning\"]\n",
        "c. Document 2: [\"machine\", \"learning\", \"is\", \"fun\"]\n",
        "4. Unique Word Identification:\n",
        "a. Combine tokens from all documents.\n",
        "b. Identify all unique words (this becomes your vocabulary).\n",
        "c. From the example:\n",
        "i. All tokens combined: [\"i\", \"love\", \"machine\", \"learning\", \"machine\",\n",
        "\"learning\", \"is\", \"fun\"]\n",
        "ii. Unique words (vocabulary): [\"i\", \"love\", \"machine\", \"learning\", \"is\",\n",
        "\"fun\"]\n",
        "5. Assigning Indexes to Words:\n",
        "a. Each unique word in the vocabulary is assigned a fixed index.\n",
        "b. Example:\n",
        "i. \"i\" → 0\n",
        "ii. \"love\" → 1\n",
        "iii. \"machine\" → 2\n",
        "iv. \"learning\" → 3\n",
        "v. \"is\" → 4\n",
        "vi. \"fun\" → 5\n",
        "This dictionary of word → index is the vocabulary.\n",
        "6. Result:\n",
        "a. The vocabulary is now a mapping of each unique word to an index.\n",
        "b. This vocabulary is later used to transform any input text into a count vector\n",
        "(word frequency vector)"
      ],
      "metadata": {
        "id": "nylRalfdcilB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PA\n",
        "\n",
        "#############################################################################\n",
        "\n",
        "Redshift Login\n",
        "\n",
        "dev-ice-redshift-cluster.ce5gi07ha18p.us-east-.redshift.amazonaws.com---Not working\n",
        "\n",
        "dev-ice-redshift-cluster.ce5gi07ha18p.us-east-1.redshift.amazonaws.com\n",
        "\n",
        "Admin user and pass\n",
        "host  dev-ice-redshift-cluster.ce5gi07ha18p.us-east-1.redshift.amazonaws.com\n",
        "\n",
        "admin\n",
        "EChdNNUgnXMnbaCLu5Kn\n",
        "#####################################################################\n",
        "prod-ice-redshift-cluster.cx3g8i1gfddj.us-east-1.redshift.amazonaws.com\n",
        "\n",
        "admin\n",
        "\n",
        "qQTdCcrVSeHEUL5spH\n",
        "######################################################################\n",
        "\n",
        "create user RNagella password 'L4s&9W#yzev'\n",
        "\n",
        "Users to be added  to the below group  so that they can access all the schemas\n",
        "\n",
        "etl_user_group\n",
        "\n",
        "\n",
        "\n",
        "skumarsingh\n",
        "select * from pg_user;\n",
        "\n",
        "drop user if exists skumarsingh\n",
        "\n",
        "SQL Error [55006]: ERROR: user \"skumarsingh\" cannot be dropped because the user has a privilege on some object\n",
        "\n",
        "select * from pg_user;\n",
        "\n",
        "drop user if exists skumarsingh;\n",
        "\n",
        "REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA public FROM skumarsingh;\n",
        "REVOKE ALL PRIVILEGES ON ALL SEQUENCES IN SCHEMA public FROM skumarsingh;\n",
        "REVOKE ALL PRIVILEGES ON SCHEMA public FROM skumarsingh;\n",
        "\n",
        "ALTER USER skumarsingh PASSWORD 'Ironclad#1'\n",
        "\n",
        "https://docs.aws.amazon.com/redshift/latest/dg/r_REVOKE.html\n",
        "\n",
        "\n",
        "SELECT\n",
        "    u.usename AS username,\n",
        "    g.groname AS groupname\n",
        "FROM\n",
        "    pg_user u\n",
        "JOIN\n",
        "    pg_group g ON u.usesysid = ANY(g.grolist)\n",
        "WHERE\n",
        "    u.usename = 'skumarsingh';\n",
        "ALTER GROUP etl_user_group DROP USER skumarsingh;\n",
        "\n",
        "\n",
        "ALTER GROUP etl_user_group ADD USER pyaminipriya,apraveen,rnagella,btilaganji;\n",
        "\n",
        "SELECT\n",
        "    u.usename AS username,\n",
        "    g.groname AS groupname\n",
        "FROM\n",
        "    pg_user u\n",
        "JOIN\n",
        "    pg_group g ON u.usesysid = ANY(g.grolist)\n",
        "WHERE\n",
        "    u.usename  in('skumarsingh', 'pyaminipriya','apraveen','rnagella','btilaganji');\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "rlutz@ironcladenvironmental.com\n",
        "\n",
        "rlutz\n",
        "\n",
        "Rebecca Lutz\n",
        "\n",
        "\n",
        "select * from pg_user;\n",
        "\n",
        "select * from pg_user;\n",
        "\n",
        "For Dev and Prod same queries we can run\n",
        "select * from pg_user;\n",
        "create user rlutz password 'ICE#2024kcv$';\n",
        "select * from pg_user;\n",
        "Select * from  pg_user where usename like '%lutz%';\n",
        "ALTER GROUP etl_user_group ADD USER rlutz;\n",
        "GRANT CREATE ON DATABASE ice_edh TO rlutz;\n",
        "\n",
        "\n",
        "\n",
        "UPushpanjali@IroncladEnvironmental.com\n",
        "hm-uppara.pushpanjali\n",
        "Firstname Uppara,\n",
        "lastname pushpanjali\n",
        "\n",
        "\n",
        "select * from pg_user;\n",
        "create user upushpanjali password 'ICE#2024upAT$';\n",
        "select * from pg_user;\n",
        "Select * from  pg_user where usename like '%pushpanjali%';\n",
        "ALTER GROUP etl_user_group ADD USER upushpanjali;\n",
        "GRANT CREATE ON DATABASE ice_edh TO upushpanjali;\n",
        "\n",
        "Select * from  pg_user where usename like '%pyaminipriya%';\n",
        "\n",
        "\n",
        "READ Only access to Redshift\n",
        "\n",
        "change schema name and user group name\n",
        "\n",
        "GRANT USAGE ON SCHEMA schema_name TO user_or_group;\n",
        "GRANT SELECT ON ALL TABLES IN SCHEMA schema_name TO user_or_group;\n",
        "ALTER DEFAULT PRIVILEGES IN SCHEMA schema_name GRANT SELECT ON TABLES TO user_or_group\n",
        "\n",
        "\n",
        "\n",
        "REVOKE ALL PRIVILEGES ON DATABASE ice_edh FROM pyaminipriya;\n",
        "\n",
        "ALTER GROUP etl_user_group ADD USER pyaminipriya, btilaganji;\n",
        "\n",
        "\n",
        "create user btilaganji password 'ICE#2024Vsr$';\n",
        "\n",
        "create user btilaganji password 'ICE#2024Vsr$';\n",
        "\n",
        "create user btilaganji password 'ICE#2024Vsr$';\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "create user btilaganji password 'ICE#2024Vsr$';\n",
        "\n",
        "create user btilaganji password 'ice_prod_bTila123';\n",
        "\n",
        "drop user if exists btilagani\n",
        "\n",
        "\n",
        "\n",
        "sarumugam@ironcladenvironmental.com\n",
        "\n",
        "select * from pg_user;\n",
        "create user sarumugam password 'ICE#2024upAT$WE';\n",
        "select * from pg_user;\n",
        "Select * from  pg_user where usename like '%sarumugam%';\n",
        "ALTER GROUP etl_user_group ADD USER sarumugam;\n",
        "GRANT CREATE ON DATABASE ice_edh TO sarumugam;\n",
        "\n",
        "aprajapati@ironcladenvironmental.com\n",
        "\n",
        "select * from pg_user;\n",
        "create user aprajapati password 'ICE#2024upAWET$';\n",
        "select * from pg_user;\n",
        "Select * from  pg_user where usename like '%aprajapati%';\n",
        "ALTER GROUP etl_user_group ADD USER aprajapati;\n",
        "GRANT CREATE ON DATABASE ice_edh TO aprajapati;\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Site to site VPN setup to access AWS services like redshift EC2 and Power Bi\n",
        "\n",
        "\n",
        "Ironclad Data center 10.100.0.0/24\n",
        "\n",
        "Public IP 156.146.110.37\n",
        "\n",
        "\n",
        "Host: 10.70.11.10\n",
        "Database.Schema: WSDATAIC\n",
        "Username: icwebsvc\n",
        "password:dfa35akC!9\n",
        "\n",
        "\n",
        ":prod-ice-redshift-cluster.cx3g8i1gfddj.us-east-1.redshift.amazonaws.com\n",
        "   \n",
        "   \n",
        "   DB2 connections jeremoe comments\n",
        "   \n",
        "   What is the PEER address of the current VPN tunnel that is being utilized for the current ODBC DB2 connections over your internal 10.50.1.0/25 addresses?\n",
        "\n",
        "Connectria our Hosting company is trying to find this tunnel so they can add the additional network of 10.50.2.0/24 per your request.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "$ aws ram create-resource-share --name TGW_Prod_Dev_Shared --no-allow-external-principals --principals arn:aws:organizations::877417598177:organization/o-yd0lt28dva\n",
        "\n",
        "$ aws ram associate-resource-share --resource-share arn:aws:ram:us-east-1:877417598177:resource-share/b494a4f6-4b23-477e-b395-b111b965b80a --resource-arns arn:aws:ec2:us-east-1:877417598177:transit-gateway/tgw-055fb173576ac74e0\n",
        "\n",
        "\n",
        "\n",
        "o-yd0lt28dva\n",
        "\n",
        "877417598177\n",
        "\n",
        "\n",
        "aws ram create-resource-share --name TGW_Prod_Dev_Shared --no-allow-external-principals --principals arn:aws:organizations::877417598177:organization/o-yd0lt28dva\n",
        "\n",
        "\n",
        "arn:aws:ec2:us-east-1:877417598177:transit-gateway/tgw-055fb173576ac74e0\n",
        "\n",
        "\n",
        "{\n",
        "    \"resourceShare\": {\n",
        "        \"resourceShareArn\": \"arn:aws:ram:us-east-1:877417598177:resource-share/b494a4f6-4b23-477e-b395-b111b965b80a\",\n",
        "        \"name\": \"TGW_Prod_Dev_Shared\",\n",
        "        \"owningAccountId\": \"877417598177\",\n",
        "        \"allowExternalPrincipals\": false,\n",
        "        \"status\": \"ACTIVE\",\n",
        "        \"tags\": [],\n",
        "        \"creationTime\": \"2024-09-09T07:21:50.965000+00:00\",\n",
        "        \"lastUpdatedTime\": \"2024-09-09T07:21:50.965000+00:00\"\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "aws ram associate-resource-share --resource-share arn:aws:ram:us-east-1:877417598177:resource-share/b494a4f6-4b23-477e-b395-b111b965b80a --resource-arns arn:aws:ec2:us-east-1:877417598177:transit-gateway/tgw-055fb173576ac74e0\n",
        "\n",
        "\n",
        "\n",
        "aws ram associate-resource-share --resource-share arn:aws:ram:us-east-1:877417598177:resource-share/b494a4f6-4b23-477e-b395-b111b965b80a --resource-arns arn:aws:ec2:us-east-1:877417598177:transit-gateway/tgw-055fb173576ac74e0\n",
        "\n",
        "{\n",
        "    \"resourceShareAssociations\": [\n",
        "        {\n",
        "            \"resourceShareArn\": \"arn:aws:ram:us-east-1:877417598177:resource-share/b494a4f6-4b23-477e-b395-b111b965b80a\",\n",
        "            \"associatedEntity\": \"arn:aws:ec2:us-east-1:877417598177:transit-gateway/tgw-055fb173576ac74e0\",\n",
        "            \"associationType\": \"RESOURCE\",\n",
        "            \"status\": \"ASSOCIATING\",\n",
        "            \"external\": false\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "[cloudshell-user@ip-10-134-57-9 ~]$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "select * from pg_user;\n",
        "\n",
        "drop user if exists AKumarPatra;\n",
        "\n",
        "REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA public FROM AKumarPatra;\n",
        "REVOKE ALL PRIVILEGES ON ALL SEQUENCES IN SCHEMA public FROM AKumarPatra;\n",
        "REVOKE ALL PRIVILEGES ON SCHEMA public FROM AKumarPatra;\n",
        "\n",
        "ALTER USER AKumarPatra PASSWORD 'Ironclad#1'\n",
        "\n",
        "\n",
        "pyaminipriya   Anjum---no access in redshift, Deevan, Annanta and Yogesh.\n",
        "\n",
        "AKumarPatra@IroncladEnvironmental.com\n",
        "\n",
        "YThippeswamy@IroncladEnvironmental.com--user doent exist\n",
        "\n",
        "TKumar@IroncladEnvironmental.com--user doesnt exist\n",
        "UPushpanjali@IroncladEnvironmental.com\n",
        "APraveen@IroncladEnvironmental.com\n",
        "PYaminipriya@IroncladEnvironmental.com\n",
        "\n",
        "\n",
        "Select * from  pg_user where usename like '%Deevan%';\n",
        "\n",
        "AWS Access Deleted ---Deevan ,Annata,Anjum,YaminiPriya,Pusjpanjali\n",
        "\n",
        "\n",
        "ALTER GROUP etl_user_group DROP USER AKumarPatra;\n",
        "drop user if exists AKumarPatra;\n",
        "\n",
        "-- Revoke database access\n",
        "REVOKE ALL PRIVILEGES ON DATABASE ice_edh FROM UPushpanjali;\n",
        "\n",
        "-- Revoke schema access\n",
        "REVOKE ALL PRIVILEGES ON SCHEMA ice_edh FROM UPushpanjali;----\n",
        "\n",
        "-- Revoke access on all existing tables\n",
        "REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA ice_edh FROM APraveen;-----\n",
        "\n",
        "-- Revoke access on future tables (default privileges)\n",
        "ALTER DEFAULT PRIVILEGES IN SCHEMA ice_edh REVOKE ALL ON TABLES FROM UPushpanjali;----\n",
        ","
      ],
      "metadata": {
        "id": "aqkwxMQ32GjM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Creating Volumes and attaching it to the servers and optimizing existing EBS volumes of all the instances in AWS  \n",
        "Automating the AWS instance maintenance activities and Conversion of Instance type  of AWS instances based on the project requirement\n",
        "Maintaining and troubleshooting linux instances and applying patches based on recommendations.\n",
        "Provided AWS admin support for all the AWS resources\n",
        "AWS infrastructure and Application Support activities\n",
        "Analyzing and troubleshooting the production issues\n",
        "Planned and Migrated On-Prem(VMware) Applications to AWS Cloud using Cloud Endure Tool.\n",
        "AWS Design, Implementation and support\n",
        "Conversion of tenency of AWS instances based on the project requirement (dedicated to default)\n",
        "Analysis the existing Cloud Infrastructure inventory and initial assessment of all the services\n",
        "Cost/Security/Performance Optimization Assessment :\n",
        "Performed the assessment Using CloudCheckr tool\n",
        "Load Distribution - Creation of Load balancer\n",
        "Data Protection – Backup\n",
        "Maintaining and troubleshooting security and firewall issue in linux instances\n",
        "Collecting and analysing the AWS volumes and snapshots and recomenduing the cutormer to optimize the resources utilisation.\n",
        "Provided Admin support for the all linux instances\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\thistory\n",
        "\n",
        "\thostname;date\n",
        "\thostname date history\n",
        "\n",
        "hostname;date\n",
        "hostname,date\n",
        "\n",
        "cat /etc/hosts\n",
        "\n",
        "hostname real hostname from /etc/hosts file\n",
        "\n",
        "\tcat /etc/hosts\n",
        "\n",
        "\thostname real hostname from /etc/hosts file\n",
        "\n",
        "\n",
        "\n",
        "\t##############################################33\n",
        "\n",
        "\tdata Restoration from S3\n",
        "\n",
        "\n",
        "\n",
        "https://docs.aws.amazon.com/cli/latest/reference/s3/sync.html\n",
        "\n",
        "aws s3 sync s3://fs-prod-db-backup/file_chunk/885164289/EBSPRDDB/backuppiece/2024-05-01/9n2pinb3_386359_1_1/8ShEIGw5MkYj/ .\n",
        "\n",
        "aws s3 sync s3:// .\n",
        "\n",
        "aws s3 sync s3://fs-prod-db-backup/file_chunk/885164289/EBSPRDDB/backuppiece/2024-04-27/ .\n",
        "\n",
        "\n",
        "aws s3 sync s3://fs-prod-db-backup/ .\n",
        "\n",
        "\n",
        "aws s3 ls s3://buckname/dirname/ --summarize --recursive --human-readable\n",
        "\n",
        "aws s3 ls s3://fs-prod-db-backup/file_chunk/885164289/EBSPRDDB/backuppiece/2024-04-27/ --summarize --recursive --human-readable\n",
        "aws s3 ls s3://fs-prod-db-backup/file_chunk/885164289/EBSPRDDB/backuppiece/2024-04-28/ --summarize --recursive --human-readable\n",
        "\n",
        "01-05  27 GB\n",
        "02-05  39 GB\n",
        "\n",
        "\n",
        "30-04   1.5TB\n",
        "29-4\t1.7 TB\n",
        "28\t\t2.4\n",
        "27      .85 TB\n",
        "\n",
        "6.45 TB Level 0 backup size\n",
        "\n",
        "aws s3 ls s3://fs-prod-db-backup/file_chunk/885164289/EBSPRDDB/backuppiece/ --summarize --recursive --human-readable\n",
        "\n",
        "aws s3 ls s3://fs-prod-db-backup/ --recursive --human-readable --summarize\n",
        "\n",
        "Total Objects: 35122\n",
        "   Total Size: 60.3 TiB\n",
        "[root@milisoatest-rac1 ~]#\n",
        "\n",
        "[root@milisoatest-rac1 s3test]# aws s3 ls s3://fs-prod-db-backup/file_chunk/885164289/EBSPRDDB/backuppiece/2024-05-01/9n2pinb3_386359_1_1/8ShEIGw5MkYj/0000000001 --summarize --recursive --human-readable\n",
        "2024-04-30 19:13:55    6.7 GiB file_chunk/885164289/EBSPRDDB/backuppiece/2024-05-01/9n2pinb3_386359_1_1/8ShEIGw5MkYj/0000000001\n",
        "\n",
        "Total Objects: 1\n",
        "   Total Size: 6.7 GiB\n",
        "[root@milisoatest-rac1 s3test]#\n",
        "\n",
        "\n",
        "Estimated speed weve observed during transfer of folder was 180 mibs second\n",
        "\n",
        "sync is bettre for single file cp is good\n",
        "\n"
      ],
      "metadata": {
        "id": "5VMh81Ju2ZMZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "put /tmp/agent_installer-x86_64.sh\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "aws ec2 describe-volumes --query 'Volumes[*].{ID:VolumeId,InstanceId:Attachments[0].InstanceId,AZ:AvailabilityZone,Size:Size}' --output table\n",
        "describe-volumes &#8212; AWS CLI 1.31.13 Command Reference\n",
        "docs.aws.amazon.com\n",
        "\n",
        "https://docs.aws.amazon.com/cli/latest/reference/ec2/describe-volumes.html\n",
        "\n",
        "\n",
        "EBS-GitLab-PP - ami volume (/dev/sdf)\n",
        "snap-0f114339b41bcff0d\t50 GiB\tCreated by CreateImage(i-062bc4dee45c7956d) for ami-03288332d293ed1b3\tStandard\tCompleted\t2023/10/31 11:31 GMT+5:30\tAvailable (100%)\tNot encrypted\t–\t–\t–\n",
        "EBS-GitLab-PP - ami volume (/dev/sda1)\n",
        "snap-0fbd87612b7ac3202\t50 GiB\tCreated by CreateImage(i-062bc4dee45c7956d) for ami-03288332d293ed1b3\n",
        "\n",
        " ssh -i jumphost-ebs.pem ubuntu@10.18.152.218\n",
        "\n",
        "\n",
        "\n",
        "sg-0b64d95542ef250f1 (sg_ebs-oem)\n",
        "sg-0c90d3b372b01d7a4 (sg_ebs-elb-internal)\n",
        "sg-0d2f85dd38725556a (sg_ebs-jumphost)\n",
        "\n",
        "vol-0015d45f336602d67\t/dev/sdf\t50\t Attached\t2021/12/14 09:01 GMT+5:30\tNo\t–\tNo\n",
        "vol-0d812545696bccbf5\t/dev/sda1\t50\n",
        "\n",
        "\n",
        "EBS-GitLab-Runner\tLinux\t10.18.152.68\n",
        "\n",
        "\n",
        "snap-05b8e9f6f3eb09fa4\t50 GiB\tESM_GitLab_Maintenance_Activity_01262022\tStandard\tCompleted\t2022/01/27 08:39 GMT+5:30\tAvailable (100%)\tNot encrypted\t–\t–\t–\n",
        "EBS-GitLab-PP - ami volume (/dev/sda1)\n",
        "snap-0fbd87612b7ac3202\t50 GiB\tCreated by CreateImage(i-062bc4dee45c7956d) for ami-03288332d293ed1b3\tStandard\tCompleted\t2023/10/31 11:31 GMT+5:30\tAvailable (100%)\tNot encrypted\t–\t–\t–\n",
        "–\n",
        "snap-0846e36cf1179f9f5\t50 GiB\tEBS-GitLab-PP_10.18.152.214_SS_BKP_July_082023"
      ],
      "metadata": {
        "id": "5a4vqjWD23QS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[1] How do I troubleshoot InsufficientInstanceCapacity errors when starting or launching an EC2 instance? - https://repost.aws/knowledge-center/ec2-insufficient-capacity-errors\n",
        "\n",
        "[2] Insufficient instance capacity - https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/troubleshooting-launch.html#troubleshooting-launch-capacity\n",
        "\n",
        "[3] Tenancy conversion - https://docs.aws.amazon.com/license-manager/latest/userguide/conversion-tenancy.html\n",
        "\n",
        "[4] describe-images - https://docs.aws.amazon.com/cli/latest/reference/ec2/describe-images.html\n",
        "\n",
        "[5] List EBS snapshots using the AWS CLI - https://repost.aws/knowledge-center/ebs-snapshots-list\n",
        "\n",
        "\n",
        "\n",
        "miliebsnonprd-sftp.millicom.com\t\t10.18.150.164\n",
        "\n",
        "EBS-NONPRD-SFTP  i-076083ec9065a4152  \n",
        "\n",
        "/dev/sda1\n",
        "\n",
        "vol-05ee92200836869ef\t/dev/sda1\n",
        "\n",
        "EBS-NONPRD-SFTP_/dev/sda1_12Sep2023\n",
        "\n",
        "\n",
        "miliebspreprd-app2.millicom.com\t\t10.18.150.232\n",
        "\n",
        "EBS-EBSPREPRD-APP2  i-00420c8d5bbc3bff8\n",
        "\n",
        "/dev/sda1\n",
        "\n",
        "vol-0d249361ca7c0e7a8\t/dev/sda1\n",
        "\n",
        "EBS-EBSPREPRD-APP2_/dev/sda1_12Sep2023\n",
        "\n",
        "\n",
        "aws ec2 modify-instance-placement --instance-id i-0bdcbf1ff195522ec --tenancy default\n",
        "\n",
        "Access key\n",
        "\n",
        "AKIAWP64UY6GIZHA36C2\n",
        "\n",
        "Secret access key\n",
        "\n",
        "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\n",
        "\n",
        "########################################################################################\n",
        "\n",
        "aws ec2 modify-instance-placement --instance-id i-076083ec9065a4152 --tenancy default\n",
        "\n",
        "aws ec2 modify-instance-placement --instance-id i-00420c8d5bbc3bff8 --tenancy default\n",
        "\n",
        "########################################################################################\n",
        "\n",
        "\n",
        "aws ec2 modify-instance-placement --instance-id i-00420c8d5bbc3bff8 --tenancy default\n",
        "\n",
        "C:\\Users\\Ramudu.nagella>\n",
        "C:\\Users\\Ramudu.nagella>aws ec2 modify-instance-placement --instance-id i-076083ec9065a4152 --tenancy default\n",
        "\n",
        "SSL validation failed for https://ec2.us-east-1.amazonaws.com/ [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1002)\n",
        "\n",
        "C:\\Users\\Ramudu.nagella>aws ec2 modify-instance-placement --instance-id i-00420c8d5bbc3bff8 --tenancy default\n",
        "\n",
        "SSL validation failed for https://ec2.us-east-1.amazonaws.com/ [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1002)\n",
        "\n",
        "\n",
        "\n",
        "Tenancy conversion - AWS License Manager\n",
        "docs.aws.amazon.com\n",
        "https://docs.aws.amazon.com/license-manager/latest/userguide/conversion-tenancy.html\n",
        "\n",
        "\n",
        "https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html#getting-started-install-instructions\n",
        "\n",
        "https://docs.aws.amazon.com/license-manager/latest/userguide/conversion-troubleshooting.html\n",
        "\n",
        "https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html#getting-started-install-instructions\n",
        "\n",
        "\n",
        "\n",
        "To resolve this issue , you can try the following steps:\n",
        "\n",
        "\n",
        "\n",
        "Check system time and date: Ensure that the system time and date on the machine running the AWS CLI are accurate. An incorrect system time can cause SSL certificate verification failures.\n",
        "\n",
        "\n",
        "\n",
        "Update the AWS CLI: Make sure you are using the latest version of the AWS CLI. Older versions may have compatibility issues with SSL certificates. You can update the AWS CLI by running the command pip install --upgrade awscli.\n",
        "\n",
        "\n",
        "\n",
        "Verify network connectivity: Ensure that you have a stable internet connection and that there are no network issues preventing the AWS CLI from connecting to the server. You can try accessing the URL \"https://ec2.us-east-1.amazonaws.com/\" using a web browser to check if it is accessible.\n",
        "\n",
        "\n",
        "\n",
        "Check proxy settings: If you are using a proxy server, verify that the proxy settings are correctly configured in the AWS CLI configuration file (~/.aws/config or %USERPROFILE%\\.aws\\config on Windows). Make sure the proxy server's SSL certificate is trusted by the AWS CLI.\n",
        "\n",
        "\n",
        "\n",
        "Verify SSL certificate chain: If you have access to the SSL certificate chain for the server, you can manually verify it using OpenSSL. Run the following command to check the certificate chain:\n",
        "\n",
        "\n",
        "\n",
        "openssl s_client -showcerts -connect ec2.us-east-1.amazonaws.com:443\n",
        "This command will display the SSL certificate chain for the server. Check if the chain is complete and if any intermediate certificates are missing.\n",
        "\n",
        "\n",
        "\n",
        "Disable SSL verification (not recommended): As a last resort, you can disable SSL verification in the AWS CLI configuration file. However, this is not recommended as it compromises the security of the connection. To disable SSL verification, add the following line to the [default] section of the AWS CLI configuration file:\n",
        "\n",
        "\n",
        "\n",
        "verify_ssl = false\n",
        "Again, this is not recommended and should only be used as a temporary solution for testing purposes.\n",
        "\n",
        "\n",
        "\n",
        "If none of the above steps resolve the issue, it may be necessary to contact AWS support for further assistance. They can provide more specific guidance based on your specific setup and configuration.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "[root@globaloem ~]# fdisk -l\n",
        "\n",
        "Disk /dev/nvme2n1: 644.2 GB, 644245094400 bytes, 1258291200 sectors\n",
        "Units = sectors of 1 * 512 = 512 bytes\n",
        "Sector size (logical/physical): 512 bytes / 4096 bytes\n",
        "I/O size (minimum/optimal): 4096 bytes / 4096 bytes\n",
        "Disk label type: dos\n",
        "Disk identifier: 0xe7f1f523\n",
        "\n",
        "        Device Boot      Start         End      Blocks   Id  System\n",
        "/dev/nvme2n1p1            2048  1258291199   629144576   83  Linux\n",
        "\n",
        "Disk /dev/nvme0n1: 137.4 GB, 137438953472 bytes, 268435456 sectors\n",
        "Units = sectors of 1 * 512 = 512 bytes\n",
        "Sector size (logical/physical): 512 bytes / 4096 bytes\n",
        "I/O size (minimum/optimal): 4096 bytes / 4096 bytes\n",
        "Disk label type: dos\n",
        "Disk identifier: 0x30244d31\n",
        "\n",
        "        Device Boot      Start         End      Blocks   Id  System\n",
        "/dev/nvme0n1p1            2048   268435422   134216687+  83  Linux\n",
        "\n",
        "Disk /dev/nvme1n1: 644.2 GB, 644245094400 bytes, 1258291200 sectors\n",
        "Units = sectors of 1 * 512 = 512 bytes\n",
        "Sector size (logical/physical): 512 bytes / 4096 bytes\n",
        "I/O size (minimum/optimal): 4096 bytes / 4096 bytes\n",
        "Disk label type: dos\n",
        "Disk identifier: 0xe7f1f523\n",
        "\n",
        "        Device Boot      Start         End      Blocks   Id  System\n",
        "/dev/nvme1n1p1            2048  1258291199   629144576   83  Linux\n",
        "\n",
        "Disk /dev/nvme3n1: 128.8 GB, 128849018880 bytes, 251658240 sectors\n",
        "Units = sectors of 1 * 512 = 512 bytes\n",
        "Sector size (logical/physical): 512 bytes / 4096 bytes\n",
        "I/O size (minimum/optimal): 4096 bytes / 4096 bytes\n",
        "\n",
        "\n",
        "Disk /dev/nvme4n1: 483.2 GB, 483183820800 bytes, 943718400 sectors\n",
        "Units = sectors of 1 * 512 = 512 bytes\n",
        "Sector size (logical/physical): 512 bytes / 4096 bytes\n",
        "I/O size (minimum/optimal): 4096 bytes / 4096 bytes\n",
        "\n",
        "You have new mail in /var/spool/mail/root\n",
        "[root@globaloem ~]# fdisk /dev/nvme4n1\n",
        "Welcome to fdisk (util-linux 2.23.2).\n",
        "\n",
        "Changes will remain in memory only, until you decide to write them.\n",
        "Be careful before using the write command.\n",
        "\n",
        "Device does not contain a recognized partition table\n",
        "Building a new DOS disklabel with disk identifier 0xd3bd258d.\n",
        "\n",
        "The device presents a logical sector size that is smaller than\n",
        "the physical sector size. Aligning to a physical sector (or optimal\n",
        "I/O) size boundary is recommended, or performance may be impacted.\n",
        "\n",
        "Command (m for help): p\n",
        "\n",
        "Disk /dev/nvme4n1: 483.2 GB, 483183820800 bytes, 943718400 sectors\n",
        "Units = sectors of 1 * 512 = 512 bytes\n",
        "Sector size (logical/physical): 512 bytes / 4096 bytes\n",
        "I/O size (minimum/optimal): 4096 bytes / 4096 bytes\n",
        "Disk label type: dos\n",
        "Disk identifier: 0xd3bd258d\n",
        "\n",
        "        Device Boot      Start         End      Blocks   Id  System\n",
        "\n",
        "Command (m for help): n\n",
        "Partition type:\n",
        "   p   primary (0 primary, 0 extended, 4 free)\n",
        "   e   extended\n",
        "Select (default p): p\n",
        "Partition number (1-4, default 1): 1\n",
        "First sector (2048-943718399, default 2048):\n",
        "Using default value 2048\n",
        "Last sector, +sectors or +size{K,M,G} (2048-943718399, default 943718399):\n",
        "Using default value 943718399\n",
        "Partition 1 of type Linux and of size 450 GiB is set\n",
        "\n",
        "Command (m for help): p\n",
        "\n",
        "Disk /dev/nvme4n1: 483.2 GB, 483183820800 bytes, 943718400 sectors\n",
        "Units = sectors of 1 * 512 = 512 bytes\n",
        "Sector size (logical/physical): 512 bytes / 4096 bytes\n",
        "I/O size (minimum/optimal): 4096 bytes / 4096 bytes\n",
        "Disk label type: dos\n",
        "Disk identifier: 0xd3bd258d\n",
        "\n",
        "        Device Boot      Start         End      Blocks   Id  System\n",
        "/dev/nvme4n1p1            2048   943718399   471858176   83  Linux\n",
        "\n",
        "Command (m for help): w\n",
        "The partition table has been altered!\n",
        "\n",
        "Calling ioctl() to re-read partition table.\n",
        "Syncing disks.\n",
        "You have new mail in /var/spool/mail/root\n",
        "[root@globaloem ~]#\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "[root@globaloem ~]# lsblk\n",
        "NAME        MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT\n",
        "nvme0n1     259:1    0  128G  0 disk\n",
        "└─nvme0n1p1 259:3    0  128G  0 part /\n",
        "nvme3n1     259:6    0  120G  0 disk [SWAP]\n",
        "nvme2n1     259:0    0  600G  0 disk\n",
        "└─nvme2n1p1 259:2    0  600G  0 part /u01\n",
        "nvme1n1     259:4    0  600G  0 disk\n",
        "└─nvme1n1p1 259:5    0  600G  0 part /u02\n",
        "nvme4n1     259:7    0  450G  0 disk\n",
        "└─nvme4n1p1 259:8    0  450G  0 part\n",
        "[root@globaloem ~]#\n",
        "\n",
        "\n",
        "[root@globaloem ~]# lsblk\n",
        "NAME        MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT\n",
        "nvme0n1     259:1    0  128G  0 disk\n",
        "└─nvme0n1p1 259:3    0  128G  0 part /\n",
        "nvme3n1     259:6    0  120G  0 disk [SWAP]\n",
        "nvme2n1     259:0    0  600G  0 disk\n",
        "└─nvme2n1p1 259:2    0  600G  0 part /u01\n",
        "nvme1n1     259:4    0  600G  0 disk\n",
        "└─nvme1n1p1 259:5    0  600G  0 part /u02\n",
        "nvme4n1     259:7    0  450G  0 disk\n",
        "You have new mail in /var/spool/mail/root\n",
        "[root@globaloem ~]# fdisk -l\n",
        "\n",
        "[root@globaloem ~]# mkfs -t ext4 -L dos /dev/nvme4n1\n",
        "mke2fs 1.45.4 (23-Sep-2019)\n",
        "Found a dos partition table in /dev/nvme4n1\n",
        "Proceed anyway? (y,N) y\n",
        "Creating filesystem with 117964800 4k blocks and 29491200 inodes\n",
        "Filesystem UUID: 1b134626-9e83-4556-9f23-62659c1d7953\n",
        "Superblock backups stored on blocks:\n",
        "        32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208,\n",
        "        4096000, 7962624, 11239424, 20480000, 23887872, 71663616, 78675968,\n",
        "        102400000\n",
        "\n",
        "Allocating group tables: done\n",
        "Writing inode tables: done\n",
        "Creating journal (262144 blocks): done\n",
        "Writing superblocks and filesystem accounting information: done\n",
        "\n",
        "You have new mail in /var/spool/mail/root\n",
        "[root@globaloem ~]#\n",
        "\n",
        "[root@globaloem ~]# blkid\n",
        "/dev/nvme0n1p1: LABEL=\"/\" UUID=\"ed005105-a243-4b79-bfc0-a9f4e3d4d9b4\" TYPE=\"ext4\"\n",
        "/dev/nvme3n1: UUID=\"95a0aebd-ffd7-4f4c-b77e-2b7d1bcfb35c\" TYPE=\"swap\"\n",
        "/dev/nvme2n1p1: UUID=\"6515a51f-88a2-4d64-89c7-063d5f1ee5b9\" TYPE=\"ext4\"\n",
        "/dev/nvme1n1p1: UUID=\"8797d0ff-0528-4089-bec4-f7907fe296f9\" TYPE=\"ext4\"\n",
        "/dev/nvme2n1: PTTYPE=\"dos\"\n",
        "/dev/nvme0n1: PTTYPE=\"dos\"\n",
        "/dev/nvme1n1: PTTYPE=\"dos\"\n",
        "/dev/nvme4n1: LABEL=\"dos\" UUID=\"1b134626-9e83-4556-9f23-62659c1d7953\" TYPE=\"ext4\"\n",
        "[root@globaloem ~]#\n",
        "\n",
        "UUID=1b134626-9e83-4556-9f23-62659c1d7953    /u03            ext4   defaults     0 0\n",
        "\n",
        "https://docs.oracle.com/en/learn/file_system_linux_8/#task-7-mount-the-file-systems\n",
        "\n",
        "https://oracle-base.com/articles/linux/linux-disk-partitioning\n",
        "\n",
        "https://oracle-base.com/articles/linux/linux-disk-partitioning\n",
        "\n"
      ],
      "metadata": {
        "id": "x6VjaAGU36Ne"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome to Colab",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}