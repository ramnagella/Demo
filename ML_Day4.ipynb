{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramnagella/Demo/blob/master/ML_Day4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#25-10-2024 Session ----Logistic Regression you can see in gitgub\n",
        "#80% data will be selected for training and 20% for testing\n",
        "#total data is devided into training and test data based on 80% of the data with the help of ML Algs ML model is developed and\n",
        "#then will give test data ,ML model will predict the o/p or label that is Y_Predict values\n",
        "#and Will validate Y_predict with y_test values after the validation will get accuracy"
      ],
      "metadata": {
        "id": "CjlyN2y5m4QR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' ML work Flow---1. Problem Statements 2.Data Collection 3.Data Cleaning or Preparation\n",
        "4.Choosing the algorithm 5.Train or build the data 6. Test 7.Evaluation if accuracy is less then choose another algorithm\n",
        "8. After biulding the model ,Deploy the model\n",
        "\n",
        "Here in our example we can add another column/feature like age group for the people aging between 20 t- 30 and 30 to 40\n",
        "Data preparation involves ---1 cleaning 2. transformatio  process and 3 EDA\n",
        "Best example for logistic regresion is email spam or not\n",
        "\n",
        "1. binomial logistic regression(true or false or 0 or 1) 2.multinomial logistic regression  more than two (fruits types animal types\n",
        "and ordinal means three or more types of dependent variables low medium high like that\n",
        "Same data we can use it another algs\n",
        "dataset.duplicated()\n",
        "dataset.drop_duplicates()\n",
        "dataset['Age'].duplicated\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "q1bDyZTum4MY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#28-10-2024--After splitting the dat into train and test rest of the code coninued in the next session on  28-octt\n",
        "'''\n",
        "Feature scaling machine sould give equal priority for all the features because ML algs will give priority for\n",
        "bydeafult for heigher values like age 20 salary 80000 ML algs will give priority for 80000 salary forst then age\n",
        "to avoid this will do feature scaling which will avoid bias\n",
        "Will use standardisation feature scaling and normalisation feature scaling\n",
        "by using all these feature scling techiniques machine will give equal priority for all the features\n",
        "\n",
        "Normalisation actually method is useful when working with the distance based algorithms or neural networks where values need to be in a specific range\n",
        "some of the distance calculations you can using the this one support vector machine\n",
        "'''"
      ],
      "metadata": {
        "id": "sYjbkI54m4Ez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Linear Regression is under the regression algorithm concept --\n",
        "#Here we are taking house price prediction\n",
        "'''\n",
        "In this example only two features are there that is the reason we no need to go for feature scaling\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "ooXulbxhm4BX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "04-11-2024------Session ---Linear Regression ---\n",
        "\n",
        "if we are using classificatiuon algs better to use accuracy score for validation\n",
        "\n",
        "supervised approach  Classification algs like logistic regression will Accuracy for measuring accuracy\n",
        "in supervised approach Regression algs like linear regression and other algs will use R square ,MAE(Mean absolute error),MSE(Mean square error)\n",
        "\n",
        "If your algs are not giving right results for training and test we can generate data for sample testing purpose using\n",
        "Faker module in Python suppose you have only records of data like 10 rowss and 4 columns we can generate 1000 rows and 15 columns of data\n",
        "using Faker module/library based on our 10 rows and 4 columns data\n",
        "\n",
        "We are using linear equation for linear regression there are lot of equations to use but we are using linear\n",
        "in linear regression draw best fit line for all the data points (cover all the daat points ) then we can find\n",
        "slope and intercept\n",
        "\n",
        "if one feature is there we can use Y=mx +c\n",
        "if mutiple features arre there we can use Y=m1x1+m2x2+c\n",
        "There are different ways like single i/p and single o/p---Single linear regressio\n",
        "multiple i/p and single o/p---multiple linear regression\n",
        "multiple i/p and multiple o/p---is not there in linear regression\n",
        "Slope =DY/DX\n",
        "\n",
        "House price data is already cleaned one we took and no missing values\n",
        "we are visualsing the data for Linear regression\n",
        "\n",
        "Plotting teh values in X-Y plane\n",
        "\n",
        "Segregation code\n",
        "X=dataset.iloc[:,:-1].values\n",
        "y=dataset.iloc[:,-1].values\n",
        "\n",
        "Here no need to split the data into training and test if qwe want we can do it but not required\n",
        ".fit() ---method by passing  i/p and o/p fit or biuld a model\n",
        "\n",
        "While validating if we are giving x value if there is lot of variation is there means need more data tp train\n",
        "Same example will try with other algorithm since there is lot variance in the prediction values of house prices\n",
        "with Linear regression alg\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "model=DecisionTreeRegressor()\n",
        "model.fit(X_train,y_train)#or model.fit(X,y)\n",
        "Then use the prediction code in the program\n",
        "Here we are getting approx correct value\n",
        "y_predict=model.predict(X_test)\n",
        "y_predict=model.predict(X_test)\n",
        "So DecisionTreeRegressor alg is good for this problem\n",
        "DecisionTreeClassifier alg also is there but it is used classification problems not for this example .\n",
        "Since the data is continuos so we are choosing regression algs not classificaton algs\n",
        "\n",
        "In  2nd case some of the values are missing ofr hours columan it would be better to fill with avg value instead of nulll or zero value\n",
        "\n",
        "dataset['hours'].isna().sum()  ---to check the null values in hours column alone\n",
        "Predict exam marsks for any values\n",
        "data=[[8.67,19,1]]\n",
        "model.predict(data)\n",
        "run the above code and verify the result with actuals .0.1 difference it is good alg for this problem\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GRfqq5jam3-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#06-11-2024-----Session ---"
      ],
      "metadata": {
        "id": "mrKrD-sXm37b"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome to Colab",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}