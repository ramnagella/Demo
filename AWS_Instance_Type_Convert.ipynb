{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramnagella/Demo/blob/master/AWS_Instance_Type_Convert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "Creating Volumes and attaching it to the servers and optimizing existing EBS volumes of all the instances in AWS  \n",
        "Automating the AWS instance maintenance activities and Conversion of Instance type  of AWS instances based on the project requirement\n",
        "Maintaining and troubleshooting linux instances and applying patches based on recommendations.\n",
        "Provided AWS admin support for all the AWS resources\n",
        "AWS infrastructure and Application Support activities\n",
        "Analyzing and troubleshooting the production issues\n",
        "Planned and Migrated On-Prem(VMware) Applications to AWS Cloud using Cloud Endure Tool.\n",
        "AWS Design, Implementation and support\n",
        "Conversion of tenency of AWS instances based on the project requirement (dedicated to default)\n",
        "Analysis the existing Cloud Infrastructure inventory and initial assessment of all the services\n",
        "Cost/Security/Performance Optimization Assessment :\n",
        "Performed the assessment Using CloudCheckr tool\n",
        "Load Distribution - Creation of Load balancer\n",
        "Data Protection – Backup\n",
        "Maintaining and troubleshooting security and firewall issue in linux instances\n",
        "Collecting and analysing the AWS volumes and snapshots and recomenduing the cutormer to optimize the resources utilisation.\n",
        "Provided Admin support for the all linux instances\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\thistory\n",
        "\n",
        "\thostname;date\n",
        "\thostname date history\n",
        "\n",
        "hostname;date\n",
        "hostname,date\n",
        "\n",
        "cat /etc/hosts\n",
        "\n",
        "hostname real hostname from /etc/hosts file\n",
        "\n",
        "\tcat /etc/hosts\n",
        "\n",
        "\thostname real hostname from /etc/hosts file\n",
        "\n",
        "\n",
        "\n",
        "\t##############################################33\n",
        "\n",
        "\tdata Restoration from S3\n",
        "\n",
        "\n",
        "\n",
        "https://docs.aws.amazon.com/cli/latest/reference/s3/sync.html\n",
        "\n",
        "aws s3 sync s3://fs-prod-db-backup/file_chunk/885164289/EBSPRDDB/backuppiece/2024-05-01/9n2pinb3_386359_1_1/8ShEIGw5MkYj/ .\n",
        "\n",
        "aws s3 sync s3:// .\n",
        "\n",
        "aws s3 sync s3://fs-prod-db-backup/file_chunk/885164289/EBSPRDDB/backuppiece/2024-04-27/ .\n",
        "\n",
        "\n",
        "aws s3 sync s3://fs-prod-db-backup/ .\n",
        "\n",
        "\n",
        "aws s3 ls s3://buckname/dirname/ --summarize --recursive --human-readable\n",
        "\n",
        "aws s3 ls s3://fs-prod-db-backup/file_chunk/885164289/EBSPRDDB/backuppiece/2024-04-27/ --summarize --recursive --human-readable\n",
        "aws s3 ls s3://fs-prod-db-backup/file_chunk/885164289/EBSPRDDB/backuppiece/2024-04-28/ --summarize --recursive --human-readable\n",
        "\n",
        "01-05  27 GB\n",
        "02-05  39 GB\n",
        "\n",
        "\n",
        "30-04   1.5TB\n",
        "29-4\t1.7 TB\n",
        "28\t\t2.4\n",
        "27      .85 TB\n",
        "\n",
        "6.45 TB Level 0 backup size\n",
        "\n",
        "aws s3 ls s3://fs-prod-db-backup/file_chunk/885164289/EBSPRDDB/backuppiece/ --summarize --recursive --human-readable\n",
        "\n",
        "aws s3 ls s3://fs-prod-db-backup/ --recursive --human-readable --summarize\n",
        "\n",
        "Total Objects: 35122\n",
        "   Total Size: 60.3 TiB\n",
        "[root@milisoatest-rac1 ~]#\n",
        "\n",
        "[root@milisoatest-rac1 s3test]# aws s3 ls s3://fs-prod-db-backup/file_chunk/885164289/EBSPRDDB/backuppiece/2024-05-01/9n2pinb3_386359_1_1/8ShEIGw5MkYj/0000000001 --summarize --recursive --human-readable\n",
        "2024-04-30 19:13:55    6.7 GiB file_chunk/885164289/EBSPRDDB/backuppiece/2024-05-01/9n2pinb3_386359_1_1/8ShEIGw5MkYj/0000000001\n",
        "\n",
        "Total Objects: 1\n",
        "   Total Size: 6.7 GiB\n",
        "[root@milisoatest-rac1 s3test]#\n",
        "\n",
        "\n",
        "Estimated speed weve observed during transfer of folder was 180 mibs second\n",
        "\n",
        "sync is bettre for single file cp is good\n",
        "\n",
        "\n",
        "[root@milisoatest-rac1 s3test]# time aws s3 sync s3://fs-prod-db-backup/file_chunk/885164289/EBSPRDDB/backuppiece/2024-05-01/9n2pinb3_386359_1_1/8ShEIGw5MkYj/ .\n",
        "download: s3://fs-prod-db-backup/file_chunk/885164289/EBSPRDDB/backuppiece/2024-05-01/9n2pinb3_386359_1_1/8ShEIGw5MkYj/metadata.xml to ./metadata.xml\n",
        "download: s3://fs-prod-db-backup/file_chunk/885164289/EBSPRDDB/backuppiece/2024-05-01/9n2pinb3_386359_1_1/8ShEIGw5MkYj/0000000001 to ./0000000001\n",
        "\n",
        "real    0m40.094s\n",
        "user    0m22.739s\n",
        "sys     0m30.980s\n",
        "You have new mail in /var/spool/mail/root\n",
        "[root@milisoatest-rac1 s3test]#\n",
        "\n",
        "##############################################3\n",
        "\n",
        "Volume Extension Commands:;\n",
        "lsblk\n",
        " df -h\n",
        " cat /etc/fstab\n",
        "\n",
        " sudo growpart /dev/nvme0n1 1\n",
        "\n",
        " sudo resize2fs /dev/nvme0n1p1\n",
        "\n",
        " verification\n",
        "\n",
        "\n",
        " lsblk\n",
        " df -h\n",
        "\n",
        " #####################################################\n",
        "\n",
        " Removing P{ublic IP\n",
        "\n",
        "\n",
        "https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-instance-addressing.html#concepts-public-addresses\n",
        "\n",
        "From this third-party video(https://www.youtube.com/watch?v=EL-_ipaE4W4 ), we gather this steps:\n",
        "\n",
        "0. Backup of the instance.\n",
        "1. Take note of which AZ/subnet the EC2 instance was launched.\n",
        "2. Create new Network Interface is same AZ/subnet.\n",
        "3. Allocate Elastic IP and associate Elastic IP to Primary Interface from where you wanted to remove public IP.\n",
        "4. Attach Network Interface created in step 2 to the instance in question.\n",
        "5. From EC2 console you should see that instance having as public ip the EIP address and 2 private IP addresses.\n",
        "6. Disassociate Elastic IP from the primary interface of the instance.\n",
        "7. Finally, detach the secondary network interface that we created earlier.\n",
        "8. From EC2 console you should see that the instance does not have public ip address anymore.\n",
        "\n",
        "Create Network Interface: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-eni.html#create_eni\n",
        "Allocate an Elastic IP: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/elastic-ip-addresses-eip.html#using-instance-addressing-eips-allocating\n",
        "Associate EIP to instance --> https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/using-eni.html#associate_eip\n",
        "#############################################################333\n",
        "\n",
        "\n",
        "Instance family type conversion\n",
        "\n",
        "To perform above prechecks you can refer to below AWS article with more details about this pre-checks and script that perform this checks.\n",
        "- Linux instance not booting after I changed its type to a Nitro-based instance type\n",
        "https://repost.aws/[knowledge-center][boot-error-linux-nitro-instance] [repost.aws]\n",
        "Below you can find the commands we have used during our troubleshooting session for this prechecks.\n",
        "-----------------------------------------------------\n",
        "- Verify NVMe drivers are installed\n",
        "$ modinfo nvme\n",
        "$ grep 'nvme' /boot/System.map-$(uname -r)\n",
        "If no output received from above command, need to install NVME modules following below guide.\n",
        "https://docs.aws.amazon.com/[AWSEC2][latest][UserGuide][nvme-ebs-volumes.html] [docs.aws.amazon.com]\n",
        "- Verify ENA drivers are installed\n",
        "$ modinfo ena\n",
        "If no output received from above command, need to install ENA modules following below guide\n",
        "https://docs.aws.amazon.com/[AWSEC2][latest][UserGuide][enhanced-networking-ena.html]#enhanced-networking-ena-linux [docs.aws.amazon.com]\n",
        "- Verify '/etc/fstab' file use UUID instead dive name (/dev/xvda), please refer to below document for guidance on this configuration. Depending on the amount of filesystems configured in 'fstab' file, you will need to update all the configured local filesystems to use UUID.\n",
        "- Automatically mount an attached volume after reboot\n",
        "https://docs.aws.amazon.com/[AWSEC2][latest][UserGuide][ebs-using-volumes.html]#ebs-mount-after-reboot [docs.aws.amazon.com]\n",
        "-----------------------------------------------------\n",
        "After performing these pre-checks, you can change instance type to Nitro based instance type (r5, r6i, m5, m6i).\n",
        "In case that after changing to Nitro instance type, instance OS is not booting and see 'dracut time out' errors from ec2 instance system log or screenshoot. You will need to add NVMe driver to initramfs image, please refer to below steps for this procedure.\n",
        "-----------------------------------------------------\n",
        "1. Stop instance and revert instance type to previous instance type (Non Nitro instance type)\n",
        "Note: We recommend to create ec2 instance backup (AMI or EBS snapshot) before making any change.\n",
        "2. Connect to the instance via SSH\n",
        "3. As root run the following commands:\n",
        "- Add NVMe drivers to initramfs\n",
        "# echo 'add_drivers+=\" nvme \"' > /etc/dracut.conf.d/nvme.conf\n",
        "- Re-create kernel image\n",
        "# mkinitrd /boot/initramfs-$(uname -r).img $(uname -r) --force\n",
        "- Rebuild GRUB to use newly created initramfs image\n",
        "# grub2-mkconfig -o /boot/grub2/grub.cfg\n",
        "4. Perform sanity reboot of the OS to verify new kernel image load after reboot\n",
        "5. Stop the instance, change instance type to Nitro based instance type and start the instance\n",
        "-----------------------------------------------------\n",
        "I Hope you find the above information helpful. However, feel free to reach back to us for any question or concern regarding this case. We are always to help you.\n",
        "We value your feedback. Please share your experience by rating this and other correspondences in the AWS Support Center. You can rate a correspondence by selecting the stars in the top right corner of the correspondence.\n",
        "Best regards,\n",
        "Fernando I.\n",
        "Amazon Web Services\n",
        "\n",
        "[oracle@miliebsprd-dr-app1 ~]$ modinfo nvme\n",
        "[oracle@miliebsprd-dr-app2 ~]$ modinfo nvme\n",
        "[oracle@miliebsprd-dr-app2 ~]$ grep 'nvme' /boot/System.map-$(uname -r)\n",
        "\n",
        "[oracle@miliebsprd-dr-app2 ~]$ modinfo ena\n",
        "\n",
        "\n",
        "[oracle@miliebsprd-dr-app2 ~]$ cat /etc/fstab\n",
        "\n",
        "#\n",
        "# /etc/fstab\n",
        "# Created by anaconda on Wed Nov  9 11:02:20 2016\n",
        "#\n",
        "# Accessible filesystems, by reference, are maintained under '/dev/disk'\n",
        "# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info\n",
        "#\n",
        "LABEL=/ /                       ext4   defaults     0 0\n",
        "/dev/xvdb       /data   ext4    defaults        0       0\n",
        "#us-east-1a.fs-d0ae1d98.efs.us-east-1.amazonaws.com:/    /interface nfs4    nfsvers=4.1     0       0\n",
        "#10.18.151.77:/nfs    /u01    nfs    defaults    0 0\n",
        "/dev/xvdb       swap    swap defaults    0 0\n",
        "10.18.151.164:/u01/install/APPS /u01/install/APPS nfs4    nfsvers=4.1     0       0\n",
        "10.18.150.92:/ /interface      nfs4    nfsvers=4.1     0       0\n",
        "[oracle@miliebsprd-dr-app2 ~]$\n",
        "\n",
        "\n",
        "[oracle@miliebsprd-dr-app1 ~]$ cat /etc/fstab\n",
        "\n",
        "#\n",
        "# /etc/fstab\n",
        "# Created by anaconda on Wed Nov  9 11:02:20 2016\n",
        "#\n",
        "# Accessible filesystems, by reference, are maintained under '/dev/disk'\n",
        "# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info\n",
        "#\n",
        "LABEL=/ /                       ext4   defaults     0 0\n",
        "UUID=d90e2d67-135f-4da8-8587-9b36a4f89bd8       /data   ext4    defaults        0       0\n",
        "#10.18.151.77:/nfs /u01 nfs  rw,nointr,bg,hard,timeo=600,wsize=65536,rsize=65536 0 0\n",
        "#/dev/xvdb      swap    swap defaults    0 0\n",
        "#us-east-1a.fs-d0ae1d98.efs.us-east-1.amazonaws.com:/    /interface nfs4    nfsvers=4.1     0       0\n",
        "UUID=a9a7067c-79c9-4fc6-8092-2b461d026e90       /u01   ext4    defaults        0       0\n",
        "UUID=e168c2c0-09e7-4a43-a4e2-cfe16f61ece9       /stage   ext4    defaults        0       0\n",
        "#10.18.150.92:/ /interface      nfs4    nfsvers=4.1     0       0\n",
        "#us-east-1a.fs-d0ae1d98.efs.us-east-1.amazonaws.com:/    /interface nfs4    nfsvers=4.1     0       0\n",
        "\n",
        "You have new mail in /var/spool/mail/oracle\n",
        "[oracle@miliebsprd-dr-app1 ~]$\n",
        "\n",
        "\n",
        "aws ec2 describe-instances --instance-id <i-0d1d47cd43260f76e> --query \"Reservations[].Instances[].EnaSupport\" --region <us-east-1>\n",
        "\n",
        "aws ec2 describe-instances --instance-id i-0d1d47cd43260f76e --query \"Reservations[].Instances[].EnaSupport\" --region us-east-1\n",
        "\n",
        "$ aws ec2 describe-instances --instance-id <your-instance-id> --query \"Reservations[].Instances[].EnaSupport\" --region <your-region>\n",
        "\n",
        "aws ec2 describe-instances --instance-id i-062ebad3cf37b9dfe --query \"Reservations[].Instances[].EnaSupport\" --region us-east-1\n",
        "\n",
        "# if it is enabled, then you will get the following output\n",
        "[\n",
        "    true\n",
        "]\n",
        "\n",
        "#if it is not enabled, you will get an empty array\n",
        "[]\n",
        "\n",
        "4. If ENA is not enabled, then run following command to enable it\n",
        "\n",
        "# Note: following command won't return any response\n",
        "$ aws ec2 modify-instance-attribute --instance-id <your-instance-id> --ena-support --region <your-region>\n",
        "\n",
        " aws ec2 modify-instance-attribute --instance-id i-0d1d47cd43260f76e --ena-support --region us-east-1\n",
        "\n",
        " aws ec2 modify-instance-attribute --instance-id i-062ebad3cf37b9dfe --ena-support --region us-east-1\n",
        "\n",
        "\n",
        "\n",
        "# Verify if above command was a success\n",
        "$ aws ec2 describe-instances --instance-id <your-instance-id> --query \"Reservations[].Instances[].EnaSupport\" --region <your-region>  \n",
        "[\n",
        "    true\n",
        "]\n",
        "\n",
        "$ aws ec2 describe-instances --instance-id i-0d1d47cd43260f76e --query \"Reservations[].Instances[].EnaSupport\" --region us-east-1\n",
        "\n",
        "aws ec2 describe-instances --instance-id i-062ebad3cf37b9dfe --query \"Reservations[].Instances[].EnaSupport\" --region us-east-1\n",
        "\n",
        "5. Voila! Now change your instance type if not already changed from aws console, and start the instance\n",
        "\n",
        "$ aws ec2 start-instances --instance-ids <your-instance-id> --region <your-region>\n",
        "#################################################################################\n",
        "To chnage the tenancy type of instance\n",
        "\n",
        "aws ec2 modify-instance-placement --instance-id <instance_id> --tenancy default\n",
        "\n"
      ],
      "metadata": {
        "id": "xWW2x5Owf-mK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Infratrack\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Revision History\n",
        "Date\tVersion\tDescription\tAuthor\n",
        "03-Oct-2024\t1.0\tInitial version\tRamudu Nagella\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "1. Introduction:\t2\n",
        "2. \t3\n",
        "2.1: \t3\n",
        "2.2: AWS IAM Benifits\t3\n",
        "3. Steps to provide access to Redshift\t3\n",
        "\n",
        "\n",
        "\n",
        "1.\tIntroduction:\n",
        "              Amazon Redshift is a fully managed cloud-based data warehouse service provided by Amazon Web Services (AWS). It is designed to help users analyze and query large amounts of data using standard SQL and existing Business Intelligence (BI) tools.\n",
        "    2. Redshift access Requirements:\n",
        "    To create the connection asset, you need these connection details:\n",
        "•\tDatabase name\n",
        "•\tHostname or IP address\n",
        "•\tPort number\n",
        "•\tUsername and password\n",
        "•\tSSL certificate (if required by the database server)\n",
        "2.2:\n",
        "it is a fully managed,relational database management service based on the PostgreSQL engine. It can handle petabyte-scale data while offering lightning-fast querying performance. The query handling efficiency is achieved through the combination of:\n",
        "\n",
        "· highly parallel processing (shared-nothing system): the service uses a number of processors to perform coordinated computations in parallel,\n",
        "· a columnar database design: it delivers column-orientated technology on an as-a-service basis, making it affordable, easy, and fast to get up and running with,\n",
        "· data compression of columns: owing to columnar data storage, Redshift automatically can use adaptive compression encoding, depending on the column data type,\n",
        "· a query optimizer: it uses analyzed information about tables to generate efficient query plans for execution,\n",
        "· compiled query code: the query execution engine compiles the query into machine code and distributes it to the cluster nodes. The compiled code executes faster because it eliminates the overhead of using an interpreter\n",
        "\n",
        "2.\tSteps to provide access to Redshift\n",
        "  STEP1: Login to AWS workspace\n",
        "\n",
        "\n",
        "\n",
        "STEP2:Click on DBeaver tool or search for DBeaver in search bar . if it doesn’t exist .\n",
        "Download DBeaver and install .\n",
        "\n",
        "STEP3:In the Dbeaver window click on database and select new database connection.\n",
        "\n",
        "\n",
        "In the search bar search for Redshift and select it .\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "To connect to the DEV database fill the details as below\n",
        "Hostname : dev-ice-redshift-cluster.ce5gi07ha18p.us-east-1.redshift.amazonaws.com\n",
        "Database :ice_edh\n",
        "User name :\n",
        "Password:\n",
        "All other details are default.\n",
        "\n",
        "To connect to the Prod database fill the details as below\n",
        "\n",
        "Hostname : prod-ice-redshift-cluster.cx3g8i1gfddj.us-east-1.redshift.amazonaws.com\n",
        "Database: ice_edh\n",
        "User name :\n",
        "Password:\n",
        "All other details are default.\n",
        "\n",
        "Fill the details and click on test connection and download the drivers if prompted to download.\n",
        "\n",
        "\n",
        "Finally click finish.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "   \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Redshift configuration:::Two Bode cluster\n",
        "\n",
        "dc2.large\n",
        "\n",
        "no  multi AZ\n",
        "320 GB storage\n",
        "Virtual private cloud (VPC)\n",
        "vpc-0296330403c7fe5f0\n",
        "Availability Zone\n",
        "us-east-1c\n",
        "VPC security group\n",
        "Specify which instances and devices can connect to the cluster.\n",
        "sg-0b13aa69c0980c316\n",
        "\n",
        "\n",
        "Current cluster version\n",
        "1.0.73348\n",
        "Snapshot retention period\n",
        "Automated: 1 day\n",
        "Maintenance window\n",
        "Every Sunday from 12:00 PM to 12:30 PM IST\n",
        "Date created\n",
        "May 30, 2023, 16:24 (UTC+05:30)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jmM03ELr7ZhA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Infratrack\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Revision History\n",
        "Date\tVersion\tDescription\tAuthor\n",
        "22-Sep-2024\t1.0\tInitial version\tRamudu Nagella\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "1. Introduction:\t3\n",
        "2. Analysis of AWS Accounts\t2\n",
        "2.1: Advanatges transit gateway\t3\n",
        "2.2: Analysis of \t5\n",
        "    2.3: Steps to create new VPN tunnel-----------------------------------------------------------------6\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "1.Introduction:\n",
        "In IronClad AWS environment  six AWS accounts are there (Audit,Dev, LogArichive , MasterPayer, Production and shared) . But only in Prod, Shared and Dev accounts VPC ‘s are created and shared among these three accounts and in other accounts there is no VPC except default in masterpayer account.\n",
        "Customer/Users from on-premises want to access all the applications  and services in AWS .\n",
        "Network gateway allows customers to connect Virtual Private Clouds (VPCs) across different accounts through site to site VPN or AWS client VPN.\n",
        "2. Analysis of AWS Accounts:\n",
        "     AWS  Network gateway (Virtual gateway/Transit gateway)allows customers to connect Virtual Private Clouds (VPCs) across different accounts .\n",
        "Since  there are six accounts are  there in our environment, we need to create six VGW’s to access all the services in all accounts . Communication will be become complex.\n",
        "      After analyzing the existing AWS accounts and client requirements we can access the AWS services in all accounts through virtual gateway or transit gateway .\n",
        "Network gateway allows customers to connect Virtual Private Clouds (VPCs) across different accounts\n",
        "\n",
        "2.1: Advantages of Transit gateway:\n",
        "•\tTransit Gateway provides enhanced routing services when compared with other     \n",
        "gateway services.\n",
        "•\tWe can use single Transit Gateway to access services across multiple AWS accounts\n",
        "•\tTGW supports Inter-Region peering. CIDR overlap is also permitted with the addition of multiple route tables\n",
        "•\tTGW simplifies  in managing network connectivity between VPCs by consolidating all connections through a single gateway.\n",
        ".\n",
        "\n",
        "2.2: Steps  to create VPN tunnel (site to site VPN):\n",
        "•\tAWS Site-to-Site VPN help us  to securely connect  on-premises network with Virtual Private Cloud .\n",
        "Login to AWS console and search for VPC ..\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "In VPN click on site to site VPN\n",
        "\n",
        "\n",
        "\n",
        "Click on create VPN connection ..\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Fill the details like name of the VPN  and select target gateway type and choose respective gateway from the list .\n",
        "\n",
        "\n",
        "Select routing options based on requirement .\n",
        "\n",
        "\n",
        "\n",
        "Click on create VPN connection\n",
        "\n",
        " .\n",
        "New site to site VPN tunnel is created.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ayNpG7oN7kcV"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome to Colab",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}