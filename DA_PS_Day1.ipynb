{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramnagella/Demo/blob/master/DA_PS_Day1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#DA with PySpark 30-08-2024--\n",
        "#Installing PySpark ---https://medium.com/@uzzaman.ahmed/setup-pyspark-on-local-machine-and-link-it-with-jupyter-notebook-windows-e08349e792db\n",
        "#Check the concepts of hadoop,bigdata and Spark\n",
        "#Structured  data --RDBMS--SQL,oracle ,mysql---Client/Server arch\n",
        "#Semi Structured----XML,JSON,email,text\n",
        "#un-strcurued -----audio,video,pdf's ,images,animated pictures--hadoop is master/slave arch--multiple Master(controller) nodes and slave nodes\n",
        "#no-sql---mangodb,cassandra,hbase\n",
        "#Any data(SD/SSD/USD) which is beyond the storage and processing capabilities of RDBMS\n",
        "#only 20% data is SD rest 80 % data is SSD and USD\n",
        "#GB means better to use RDBMS ---PB and TB means Bid data -Twitter 30 TB /Month\n",
        "#Velocity means the rate at which data is genrated ---is data mb/sec means RDBMS--GB or TB/Sec means big data\n",
        "#Verocity how far data is reliable ---RDBMS --only SD ---Big data --accepts any type of data\n",
        "#haddop is framework developed by apache opensource\n",
        "#Hadoop horizontal scaling --supports parallel processing and distributed storage --map/reduce programming\n",
        "#Drawback of hadoop is ---hadoop supports batch processing  and HDFS---storage and processing happens in Hard disk\n",
        "#In real time it is difficult--hadoop doesnt support realtime processing of data\n",
        "#Real time data processing --in memory data processing and data processing applications ---master/slave -SPARK better choice -- RDD ---\n",
        "#in SPARK initial read and write happens in hard disk --further reads and writes in memory of the data nodes\n",
        "#intermediate R/W happens from ---RAM --and final writes happens into Hard disk\n",
        "#in real we can cal spark is advanced one of hadoop\n",
        "#Spark supports Resilient distribution dataset---RDD"
      ],
      "metadata": {
        "id": "E33s6I6zRB1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Need to install java Version ---to install pyspark we need install JDK 1.8---then check pyspark version\n",
        "#conda install -c conda-forge openjdk\n",
        "#conda install conda-forge::pyspark\n",
        "#conda activate pyspark_new\n",
        "#pip show pyspark\n",
        "#conda install -c conda-forge findspark---to initiate the spark image"
      ],
      "metadata": {
        "id": "uzEwYjb8RBxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2-09-2024----Spark and PySpark---\n",
        "#Spark Architecture is as below ---Client server executes the Driver program (jar file program),in master node--worker node--cluster manager\n",
        "#1 GB allocated to worker nodes ---Resource allocation taken care by cluster manager(hadoop framework)--it is component of haddop (clsternamanger and driver program) --like splitting the data\n",
        "# and allocating all the worker nodes --W1,W2,W3.....after the allocation all these worker nodes register into master nodes\n",
        "#Master nodes communicates with worker nodes using heart beat ---worker nodes are executor---\n",
        "#Only resource allocation purpose will go for cluster manager\n",
        "#Master nodes worker nodes aee not virtual machones resources are allocated by cluster manager for the hadoop components.\n",
        "#one worker node act as active master node and another worker acta s passive master node if primary master node failes\n",
        "#secondary master node will take over the tasks.----zookeeper ---ZooKeeper work on the election process to elect one worker node as to act as master node\n",
        "#"
      ],
      "metadata": {
        "id": "opreKqO0RBvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' PySpark Architecture----Client go with ----> Driver Program initiated called master node will create automatically initially SparkContext object\n",
        "----SparkContext is entry point for spark functionality---one SC is created for JVM ---\n",
        "----We cant create multiple SC objects first we need to stop or kill active SC object and create new SC object\n",
        "----SparkContext---here we can give app name --or\n",
        "----how much memlory or disk space is used we can write in SC object\n",
        "----SC --->picked file --->py4j virtual machone engine\n",
        "----in PySpark, \"picked file\" primarily refers to files that have been serialized using Python's pickle module and then saved to a distributed file system by Spark.\n",
        "----This process allows for the efficient storage and retrieval of Python objects within a Spark environment\n",
        "----Client--->DriverPRG+SC-->picked file-->coverted into byte stream object->py4j virtual machone engine-->Python RDD-->master node-->Cluster manager-->Worker node\n",
        "----Data Structures are RDD,DF and dataset---PySpark supports RDD and DF omly--RDD is not having 2-D\n",
        "----RDD how data is distributed means suppose ---one data set is like [1,2,3,4,5,6,7,8,910]\n",
        "----one dataset [1,2,3,4] is allocated for one Worker node and rest of the elements are allocated for another worker node\n",
        "----[5,6,7,8,9,10]---DF means contaon rows and columns---low level versions relased RDD--\n",
        "---1.3 above versions relases DF and 1.6 and above dataset\n",
        "---need to install --java 1.8---pyspark---hadoop\n",
        "---set SPARK_HOME=C:\\spark-3.5.2-bin-hadoop3\\spark-3.5.2-bin-hadoop3\n",
        "---set PYSPARK_PYTHON=E:\\anaconda\\python.exe\n",
        "---run pyspark command from command promt then you can see spark env in jupyter notebook and immediately SC object is automatically created\n",
        "---take jupyter notebook URL from command prompt and see in the browser---\n",
        "---in jupyter notebook type the below code and see\n",
        "---\n",
        "\n",
        "----import pyspark\n",
        "----run sc in another jupyter notebook cell and you also run spark means spark session\n",
        "----if you want to work with hive ue spark session other wise we can use SC\n",
        "----if you want to execute SQL related queries SPARK session is necessary.\n",
        "---'''"
      ],
      "metadata": {
        "id": "Wwebiyq7xqU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pysprak.sql import SparkSession\n",
        "spark=SparkSession.builder.appName('practice').getOrCreate()\n",
        "print(spark.version)"
      ],
      "metadata": {
        "id": "ZRf59mNKRBs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "metadata": {
        "id": "mlSLzXNlRBqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "#initialize Spark Session\n",
        "spark=SparkSession.builder.appName('PySpark Test').getOrCreate()\n",
        "print(spark.version)\n",
        "#Create a Sample DF\n",
        "data =[('Ram',45),('Shatha',13),('Vamsi',17)]\n",
        "columns=['Name','Age']\n",
        "df=spark.createDataFrame(data,columns)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-VQMJ9mRBnb",
        "outputId": "2a6bc77e-34a7-423e-951f-442839f8701b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.5.1\n",
            "+------+---+\n",
            "|  Name|Age|\n",
            "+------+---+\n",
            "|   Ram| 45|\n",
            "|Shatha| 13|\n",
            "| Vamsi| 17|\n",
            "+------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark\n",
        "#Click on Spark UI in below you will get the spark contect details"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "iCP5-RTBzwzr",
        "outputId": "0b088736-88ce-4855-bf79-3ddaf65c9ddb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7a1ec4afca10>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://daaa661da5fe:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>PySpark Test</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sc.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "NdEh94nl5L3N",
        "outputId": "419d0b4b-828a-4fa4-b9a5-6f0c4efc15f3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'sc' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4-4134826275.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'sc' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from threading import local\n",
        "from pyspark import SparkContext\n",
        "sc=SparkContext(master='local[4]',\n",
        "                appName='Sample')\n",
        "\n",
        "#will get error because already SC object was created in previous cells\n",
        "#stop the SC and re-run the above code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "kvPBOZN1zwwE",
        "outputId": "5cc36483-b731-41d3-8fe5-36b3fb33efdc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=PySpark Test, master=local[*]) created by getOrCreate at /tmp/ipython-input-1-3384325210.py:3 ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3-2809705833.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthreading\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m sc=SparkContext(master='local[4]',\n\u001b[0m\u001b[1;32m      4\u001b[0m                 appName='Sample')\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[1;32m    199\u001b[0m             )\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             self._do_init(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0;31m# Raise error if there is already a running Spark context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m    450\u001b[0m                         \u001b[0;34m\"Cannot run multiple SparkContexts at once; \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m                         \u001b[0;34m\"existing SparkContext(app=%s, master=%s)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=PySpark Test, master=local[*]) created by getOrCreate at /tmp/ipython-input-1-3384325210.py:3 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "metadata": {
        "id": "GLwSPQgHzwtN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from threading import local\n",
        "from pyspark import SparkContext\n",
        "sc=SparkContext(master='local[4]',\n",
        "                appName='Sample')"
      ],
      "metadata": {
        "id": "cjSfyGhxzwmU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "AE60oTO3zwjE",
        "outputId": "6e964eeb-e63b-432c-e067-0f43a3198cb5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SparkContext master=local[4] appName=Sample>"
            ],
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://daaa661da5fe:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[4]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Sample</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RDD---"
      ],
      "metadata": {
        "id": "iRrFiq7YzweQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc.stop()"
      ],
      "metadata": {
        "id": "5AAX_Xn_zwcC"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "metadata": {
        "id": "D_9m1HC6OrfB"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkContext\n",
        "import numpy as np\n",
        "sc=SparkContext(master='local[4]')\n",
        "lst=np.random.randint(0,10,20)\n",
        "A=sc.parallelize(lst)\n",
        "print(A)\n",
        "#Here will get parallel collection RDD"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgTIl8bgzwZn",
        "outputId": "78ab9b46-67fe-4598-ed9a-7cfdd139bf85"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:289\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(lst)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DXhDuljzwXQ",
        "outputId": "a668f170-f6f5-4e5d-936e-16e8a6b5da63"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 4 7 8 0 8 5 9 0 3 5 7 1 8 2 7 4 1 8 8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A.glom().collect()#glom is transformation and collect is action method"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZJTwUzozwUy",
        "outputId": "fd90e72b-fa78-4547-8d7c-7aa2af0907e6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[np.int64(1), np.int64(4), np.int64(7), np.int64(8), np.int64(0)],\n",
              " [np.int64(8), np.int64(5), np.int64(9), np.int64(0), np.int64(3)],\n",
              " [np.int64(5), np.int64(7), np.int64(1), np.int64(8), np.int64(2)],\n",
              " [np.int64(7), np.int64(4), np.int64(1), np.int64(8), np.int64(8)]]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A.glom()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qK6Zil6JzwSN",
        "outputId": "6d673d71-2043-494c-fe8e-649135ce0d61"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PythonRDD[5] at RDD at PythonRDD.scala:53"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sc.stop()"
      ],
      "metadata": {
        "id": "WR9z2PKTzwQC"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "metadata": {
        "id": "ruHw6U03zvqs"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc=SparkContext('local[4]','Shatha')"
      ],
      "metadata": {
        "id": "9d7G4YtbKCWd"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark=SparkSession(sc)"
      ],
      "metadata": {
        "id": "UAckxsyEKCS2"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "li=[('Java',10),('Python',20),('C',30)]"
      ],
      "metadata": {
        "id": "z4hPe5BtKCQV"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rdd=sc.parallelize(li)"
      ],
      "metadata": {
        "id": "josvHqsPKCOA"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rdd2=sc.textFile('cars.csv')"
      ],
      "metadata": {
        "id": "TJ1hnSzWKCLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rdd.glom()\n",
        "#Here will get PythonRDD object"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efGHlk7cPNTj",
        "outputId": "2f5421a6-fd87-4e6b-b9b3-b9cefd8436fc"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PythonRDD[1] at RDD at PythonRDD.scala:53"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd.glom().collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEkjCU3oPxra",
        "outputId": "36392453-8c8a-489c-da6a-b3e47f29c5d8"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[], [('Java', 10)], [('Python', 20)], [('C', 30)]]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(rdd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "ElANV8NqKCI7",
        "outputId": "fac39c1b-f178-40a4-cfac-013a7f464038"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.rdd.RDD"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.rdd.RDD</b><br/>def __init__(jrdd: &#x27;JavaObject&#x27;, ctx: &#x27;SparkContext&#x27;, jrdd_deserializer: Serializer=AutoBatchedSerializer(CPickleSerializer()))</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/pyspark/rdd.py</a>A Resilient Distributed Dataset (RDD), the basic abstraction in Spark.\n",
              "Represents an immutable, partitioned collection of elements that can be\n",
              "operated on in parallel.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 336);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pyspark.rdd.RDD"
      ],
      "metadata": {
        "id": "U9aOy7psKCGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark=SparkSession.builder.appName('PySpark Test')\\\n",
        ".config('spark.executor.memory','4g')\\#worker node\n",
        ".config('spark.executor.cores','2')\\\n",
        ".config('spark.driver.memory','4g')\\#master node\n",
        ".config('spark.driver.cores','2')\\\n",
        ".getOrCreate()"
      ],
      "metadata": {
        "id": "bXX7jpR6LwST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "1.Transformation\n",
        "2.Actions\n",
        "RDD\n",
        "-----[1,2,3,4,5]==>RDD==>worker node paertition==>\n",
        "-----Transformations--lazy evaluated (sum of list element reduce())\n",
        "-----new RDD doesnt return any value )---Actions (return value)"
      ],
      "metadata": {
        "id": "07yFnAFxLwO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#04-09-2024--Pyspark session\n",
        "'''\n",
        "RDD transformation and RDD Actions\n",
        "convert normal spark RDD (parallel RDD) object into python object RDD\n",
        "map(),flatmap(),reduce(),filter(),sortbykey()---After applying these transformation methods it will create another RDD\n",
        "if you want to see the values after these methods we can use action methods(collect(),max,count,reduce,first) --\n",
        "Action will return value --Transormation will convert one(Spark) RDD into another RDD (Python)--\n",
        "rdd.glom()---glom will convert the spark rdd into python RDD\n",
        "data=[(),(),(),()]\n",
        "data is spark oriented RDD ---data spark understandable object which will be converted into python understandable object using glom\n",
        "'''"
      ],
      "metadata": {
        "id": "AWbL37mOLwMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from threading import local\n",
        "from pyspark import SparkContext\n",
        "sc=SparkContext(master='local[4]',\n",
        "                appName='Sample')\n"
      ],
      "metadata": {
        "id": "wquXR86U351X"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0n6fwr_V3uO0",
        "outputId": "d0a3f934-1075-4d5c-e24d-e31141046f03"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "names=sc.parallelize(['Ram','Shatha','Vamsi','kiran','Sai','Krish','veena','vaibhav','veera'])\n"
      ],
      "metadata": {
        "id": "DYBGQWscLwJ6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "names.glom()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbP7tjBILwHe",
        "outputId": "cfcef24b-d70b-426e-dfe3-5f639abd0520"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PythonRDD[1] at RDD at PythonRDD.scala:53"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "MX1BN8sB4YJN",
        "outputId": "2f53f420-a49b-438a-8501-ebacb17697bb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.rdd.RDD"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.rdd.RDD</b><br/>def __init__(jrdd: &#x27;JavaObject&#x27;, ctx: &#x27;SparkContext&#x27;, jrdd_deserializer: Serializer=AutoBatchedSerializer(CPickleSerializer()))</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/pyspark/rdd.py</a>A Resilient Distributed Dataset (RDD), the basic abstraction in Spark.\n",
              "Represents an immutable, partitioned collection of elements that can be\n",
              "operated on in parallel.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 336);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "names.glom().collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w34D6lFyLwFI",
        "outputId": "9ea892dd-6a77-44c3-baa9-fa3be6c7084e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Ram', 'Shatha'],\n",
              " ['Vamsi', 'kiran'],\n",
              " ['Sai', 'Krish'],\n",
              " ['veena', 'vaibhav', 'veera']]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "pyspark\n",
        "1.Transformations ---spark rdd object ---transfirmation method--another RDD obj(Python RDD object)--\n",
        "------Lazy Evaluation\n",
        "------Actions --return a values----action methods---\n",
        "-----Spark RDD object---transformation---->Python RDD object ---Action method---return a values\n",
        "-----DAG---Directed acyclic graph for visualisation\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "cGVa30ECLwCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "names.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gv8ymOyE4foz",
        "outputId": "91b683de-4253-48f3-cfeb-610d143b2e78"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Ram',\n",
              " 'Shatha',\n",
              " 'Vamsi',\n",
              " 'kiran',\n",
              " 'Sai',\n",
              " 'Krish',\n",
              " 'veena',\n",
              " 'vaibhav',\n",
              " 'veera']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a=sc.parallelize([1,2,3,4,5,6,7]).foreach(lambda x: print(x))\n",
        "a\n",
        "#here it doent return any value because it is spark RDD object"
      ],
      "metadata": {
        "id": "od2sttEV4fli"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SparkSession"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "NjsRPBiR-1-Z",
        "outputId": "503e3d56-02ae-4fc5-bc94-57dbc01152b2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'SparkSession' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-27-2556589330.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mSparkSession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'SparkSession' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import Row\n",
        "from pyspark.sql import SparkSession\n",
        "spark=SparkSession(sc)\n"
      ],
      "metadata": {
        "id": "K-2X_nWp4fiQ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a=spark.createDataFrame([1,2,3,4,5,6,7],\"int\").(\"Name\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "2R78M3GT4ffi",
        "outputId": "7150913e-0000-4ee9-9cf4-c6eb07ef3b95"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'DataFrame' object has no attribute 'DF'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-34-191945722.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"int\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Name\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   3125\u001b[0m         \"\"\"\n\u001b[1;32m   3126\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3127\u001b[0;31m             raise AttributeError(\n\u001b[0m\u001b[1;32m   3128\u001b[0m                 \u001b[0;34m\"'%s' object has no attribute '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3129\u001b[0m             )\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'DF'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a"
      ],
      "metadata": {
        "id": "tP78Y5iX4fcq"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num=sc.parallelize([5,5,3,4,9,5,2],9)"
      ],
      "metadata": {
        "id": "a3_HGbO84fZj"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(num)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "odSkwHEg4fWk",
        "outputId": "c6147a05-4dc5-4d0a-b1f2-2be11acc4bf0"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.rdd.RDD"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.rdd.RDD</b><br/>def __init__(jrdd: &#x27;JavaObject&#x27;, ctx: &#x27;SparkContext&#x27;, jrdd_deserializer: Serializer=AutoBatchedSerializer(CPickleSerializer()))</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/pyspark/rdd.py</a>A Resilient Distributed Dataset (RDD), the basic abstraction in Spark.\n",
              "Represents an immutable, partitioned collection of elements that can be\n",
              "operated on in parallel.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 336);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGNaC6cV4fTW",
        "outputId": "a22b3ce7-ac2e-4262-c7a2-75fdeae92fee"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5, 5, 3, 4, 9, 5, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num.glom().collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4QVERsX4fQn",
        "outputId": "1e4f9914-dc5e-48b3-d7fc-076fca86bc90"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[], [5], [5], [3], [], [4], [9], [5], [2]]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AX8wdYF0Lv_m",
        "outputId": "5a4a0a77-779e-4040-efb7-224d54caa8b0"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5, 5, 3, 4, 9, 5, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num.take(4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObrE2-rpBo_V",
        "outputId": "8acae364-c47c-4b74-cb75-ef974a966f35"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5, 5, 3, 4]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num.countByValue()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yq3G30ymBo76",
        "outputId": "6e45a027-58a2-4bae-9fec-af563d049192"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(int, {5: 3, 3: 1, 4: 1, 9: 1, 2: 1})"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num.glom()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDZO-qaLBo4o",
        "outputId": "2fba4068-8d3e-42e3-99a2-ea601a3d2e2b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PythonRDD[35] at RDD at PythonRDD.scala:53"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num.glom().collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqGSwwSeBo1g",
        "outputId": "82f44409-6e48-4356-dde0-63af99d60bb1"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[], [5], [5], [3], [], [4], [9], [5], [2]]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(num)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "faAyvwT2BoyS",
        "outputId": "634540a6-7ea0-4d8f-b849-e3e09767523a"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.rdd.RDD"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.rdd.RDD</b><br/>def __init__(jrdd: &#x27;JavaObject&#x27;, ctx: &#x27;SparkContext&#x27;, jrdd_deserializer: Serializer=AutoBatchedSerializer(CPickleSerializer()))</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/pyspark/rdd.py</a>A Resilient Distributed Dataset (RDD), the basic abstraction in Spark.\n",
              "Represents an immutable, partitioned collection of elements that can be\n",
              "operated on in parallel.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 336);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(num.glom)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDqm7YMeBovA",
        "outputId": "c59a4182-8951-44a2-bd5c-5124eb863614"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "method"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(num.glom())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "O-p7SlgXBoru",
        "outputId": "ec21c1f4-bac4-4c13-f176-437582d90010"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.rdd.PipelinedRDD"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.rdd.PipelinedRDD</b><br/>def __init__(prev: RDD[T], func: Callable[[int, Iterable[T]], Iterable[U]], preservesPartitioning: bool=False, isFromBarrier: bool=False)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/pyspark/rdd.py</a>Examples\n",
              "--------\n",
              "Pipelined maps:\n",
              "\n",
              "&gt;&gt;&gt; rdd = sc.parallelize([1, 2, 3, 4])\n",
              "&gt;&gt;&gt; rdd.map(lambda x: 2 * x).cache().map(lambda x: 2 * x).collect()\n",
              "[4, 8, 12, 16]\n",
              "&gt;&gt;&gt; rdd.map(lambda x: 2 * x).map(lambda x: 2 * x).collect()\n",
              "[4, 8, 12, 16]\n",
              "\n",
              "Pipelined reduces:\n",
              "\n",
              "&gt;&gt;&gt; from operator import add\n",
              "&gt;&gt;&gt; rdd.map(lambda x: 2 * x).reduce(add)\n",
              "20\n",
              "&gt;&gt;&gt; rdd.flatMap(lambda x: [x, x]).reduce(add)\n",
              "20</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 5395);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num.max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUB1iuSzBooS",
        "outputId": "ad2c6ed0-59c0-49d6-c984-b5921c2adc76"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num.min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLFM2G0sBolA",
        "outputId": "dcc071d1-9777-49f5-b433-e649e8c8bbba"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vsz0XHZsBohd",
        "outputId": "7f42a752-2f80-4112-a28e-d8b6d7dbe03e"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.714285714285714"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-qX2bjq2BoeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num.reduce(lambda x,y:x+y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psUVEfpTDb5X",
        "outputId": "a90a40f8-905b-4c11-c66d-93c856fdba19"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import add,sub,mul,div\n",
        "num.reduce(add)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWCZWPWxDb2h",
        "outputId": "28f1220c-2a56-459b-d308-250fb79f85d5"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num.reduce(lambda x,y:x if x>y else y )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsiGpfgcDbzJ",
        "outputId": "15fe4616-e30a-41f0-8bfc-78f03244602e"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def myfunc(a,b):\n",
        "  if a>b:\n",
        "    return a\n",
        "  else:\n",
        "    return b\n",
        "num.reduce(myfunc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4vqGGBIDbwm",
        "outputId": "728e60e7-78aa-409d-ca2d-932b2fb35761"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num.takeOrdered(4)#after sorting the values first three values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vq9YJA9ZDbuA",
        "outputId": "006e2e8a-4bb4-4b80-ca45-3b8143ed1344"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 3, 4, 5]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Fold method ---performs accumulated values ---\n",
        "num=sc.parallelize([5,5,4,3,2,9,2],2)\n",
        "num.collect()\n",
        "#num.fold(0,lambda x,y:x+y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoI7kQfJDbrV",
        "outputId": "4b83f9a3-f40c-41fd-a539-3cafd3a34a8f"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5, 5, 4, 3, 2, 9, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num.glom().collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1nMlcQyDboj",
        "outputId": "f948a856-6c82-4942-eada-501183ffd6a8"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[5, 5, 4], [3, 2, 9, 2]]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num.fold(2,lambda x,y:x+y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OkG_fY3Dblx",
        "outputId": "65373972-1cff-45b0-8351-04fcba9ea56d"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RDD Trandormation --lazy evaluation means computations not done immediately\n",
        "'''\n",
        "map()\n",
        "'''\n",
        "num=sc.parallelize([5,5,4,3,2,9,2])\n",
        "num.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTqHzvBXDbi3",
        "outputId": "bcd3845f-d2d1-418a-e259-d1c2c0381878"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5, 5, 4, 3, 2, 9, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num.map(lambda a:a*2).collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCuFXIHvDbgC",
        "outputId": "bfa8d625-a2ad-4e24-957f-f49649bc38a2"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[10, 10, 8, 6, 4, 18, 4]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num.map(lambda a:a**2).collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmW-NtflDbdF",
        "outputId": "c8c5c251-477c-4cb7-c396-ecf533b6f0dd"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[25, 25, 16, 9, 4, 81, 4]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Narrow (pipeline) and wide tansformatiosn  go through the theory and examples  in google\n",
        "'''\n",
        "in narrow transformation no shuffling of adat accross the nodes or partitions ,data in partitiones in suach way that\n",
        "data in each node is independent of other nodes .\n",
        "--Wide transformation with shuffling of adata accross the nodes ,computations aspects are veru expensive"
      ],
      "metadata": {
        "id": "TAauqxYqDbaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc"
      ],
      "metadata": {
        "id": "RUpYtN53ITaP",
        "outputId": "5596c9f4-62e1-438a-a6f5-bb640cd62fa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from threading import local\n",
        "from pyspark import SparkContext\n",
        "sc=SparkContext(master='local[4]',\n",
        "                appName='Sample')"
      ],
      "metadata": {
        "id": "auJyF5kfIi2n"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##06-09-2024 Pyspark Session\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql import SparkSession\n",
        "spark=SparkSession(sc)\n"
      ],
      "metadata": {
        "id": "mEd5V3iVKgmX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num=sc.parallelize([5,5,3,4,9,5,2],9)"
      ],
      "metadata": {
        "id": "RJgHuvGLKgi1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUGSBlJFKggK",
        "outputId": "cfced0b2-fbfa-41a5-a541-34a3f5200280"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5, 5, 3, 4, 9, 5, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num.glom().collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3TF9LM7Kgdv",
        "outputId": "4eddcada-ba9f-4767-e7c1-aa0f6eb387cf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[], [5], [5], [3], [], [4], [9], [5], [2]]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(num)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "1sfWiJeaKgbA",
        "outputId": "628fc4cc-0ab5-4660-8b08-70f7ef84526d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.rdd.RDD"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.rdd.RDD</b><br/>def __init__(jrdd: &#x27;JavaObject&#x27;, ctx: &#x27;SparkContext&#x27;, jrdd_deserializer: Serializer=AutoBatchedSerializer(CPickleSerializer()))</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/pyspark/rdd.py</a>A Resilient Distributed Dataset (RDD), the basic abstraction in Spark.\n",
              "Represents an immutable, partitioned collection of elements that can be\n",
              "operated on in parallel.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 336);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(num.glom())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "ehHx_vTYKgYs",
        "outputId": "7ce587cc-9e25-4587-acb1-9a32cd79fd64"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.rdd.PipelinedRDD"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.rdd.PipelinedRDD</b><br/>def __init__(prev: RDD[T], func: Callable[[int, Iterable[T]], Iterable[U]], preservesPartitioning: bool=False, isFromBarrier: bool=False)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/pyspark/rdd.py</a>Examples\n",
              "--------\n",
              "Pipelined maps:\n",
              "\n",
              "&gt;&gt;&gt; rdd = sc.parallelize([1, 2, 3, 4])\n",
              "&gt;&gt;&gt; rdd.map(lambda x: 2 * x).cache().map(lambda x: 2 * x).collect()\n",
              "[4, 8, 12, 16]\n",
              "&gt;&gt;&gt; rdd.map(lambda x: 2 * x).map(lambda x: 2 * x).collect()\n",
              "[4, 8, 12, 16]\n",
              "\n",
              "Pipelined reduces:\n",
              "\n",
              "&gt;&gt;&gt; from operator import add\n",
              "&gt;&gt;&gt; rdd.map(lambda x: 2 * x).reduce(add)\n",
              "20\n",
              "&gt;&gt;&gt; rdd.flatMap(lambda x: [x, x]).reduce(add)\n",
              "20</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 5395);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=['Apache Spark','Spark','Python','Spark','Scala']\n"
      ],
      "metadata": {
        "id": "LHDuRsQIKgWA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_bigdata=sc.parallelize(text)"
      ],
      "metadata": {
        "id": "HW7TqhE8KgTo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_bigdata.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iubbWzS2KgRL",
        "outputId": "910c93fa-9295-4a02-eb20-fba43ea4b4ad"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Apache Spark', 'Spark', 'Python', 'Spark', 'Scala']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_bigdata.glom().collect()"
      ],
      "metadata": {
        "id": "3r05Zbt-KQyc",
        "outputId": "f00ee5d1-6a74-400e-c5b0-4b448ec097e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Apache Spark'], ['Spark'], ['Python'], ['Spark', 'Scala']]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lines=text_bigdata.filter(lambda line:'Spark' in line) #filter is narrow transformation method"
      ],
      "metadata": {
        "id": "92nc3xeDKQuY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines"
      ],
      "metadata": {
        "id": "8C9Khve2KQq1",
        "outputId": "76bc9f67-add0-4ce0-97db-248b51a7bd7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PythonRDD[4] at RDD at PythonRDD.scala:53"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(lines)"
      ],
      "metadata": {
        "id": "ny6LzdW-KQmP",
        "outputId": "f13f4a3e-c53c-4fa9-ab46-5b53e0bf8138",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.rdd.PipelinedRDD"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.rdd.PipelinedRDD</b><br/>def __init__(prev: RDD[T], func: Callable[[int, Iterable[T]], Iterable[U]], preservesPartitioning: bool=False, isFromBarrier: bool=False)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/pyspark/rdd.py</a>Examples\n",
              "--------\n",
              "Pipelined maps:\n",
              "\n",
              "&gt;&gt;&gt; rdd = sc.parallelize([1, 2, 3, 4])\n",
              "&gt;&gt;&gt; rdd.map(lambda x: 2 * x).cache().map(lambda x: 2 * x).collect()\n",
              "[4, 8, 12, 16]\n",
              "&gt;&gt;&gt; rdd.map(lambda x: 2 * x).map(lambda x: 2 * x).collect()\n",
              "[4, 8, 12, 16]\n",
              "\n",
              "Pipelined reduces:\n",
              "\n",
              "&gt;&gt;&gt; from operator import add\n",
              "&gt;&gt;&gt; rdd.map(lambda x: 2 * x).reduce(add)\n",
              "20\n",
              "&gt;&gt;&gt; rdd.flatMap(lambda x: [x, x]).reduce(add)\n",
              "20</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 5395);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lines.count()"
      ],
      "metadata": {
        "id": "EUuCiWUtKQgV",
        "outputId": "880df717-c8d1-4e3a-ae4b-a356a202308f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lines.collect()"
      ],
      "metadata": {
        "id": "Apr1k8mwKQQ2",
        "outputId": "f13979b0-36fe-46ed-e7ab-785f63d94bdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Apache Spark', 'Spark', 'Spark']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lines.first()"
      ],
      "metadata": {
        "id": "oIzrJCEyeBvB",
        "outputId": "418fc44e-d92d-4fed-9128-0442bba4cd3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Apache Spark'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "TCe2pYy5fYR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init('C:\\spark-3.5.2-bin-hadoop3\\spark-3.5.2-bin-hadoop3')"
      ],
      "metadata": {
        "id": "Snm2e6lWfYPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-Ilrub05fYMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZXSZ0qK3fYJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#stop the spark session\n",
        "spark.stop()"
      ],
      "metadata": {
        "id": "u90qwCe0eBrg"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark=SparkSession.builder.master('local').appName('narrow').getOrCreate()"
      ],
      "metadata": {
        "id": "UGcrdULVeBoG"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc=spark.sparkContext"
      ],
      "metadata": {
        "id": "Lb4wv2g4eBlW"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num=sc.parallelize([5,5,3,4,9,5,2])"
      ],
      "metadata": {
        "id": "RJfLDxwueBUi"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num.glom().collect()\n",
        "#here after glom also it is storing everything in single partition,because the reason we are not given cores in master node spark session while creating spark session,so the entire elements are stored in only one partition\n"
      ],
      "metadata": {
        "id": "u0wub2o2eBRj",
        "outputId": "e86b1a51-ed91-4731-987f-c6cea80edf4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[5, 5, 3, 4, 9, 5, 2]]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num.map(lambda a:a*2).collect()"
      ],
      "metadata": {
        "id": "V3xp1QfmeBOn",
        "outputId": "cddbe409-fd38-4a85-ef91-bc3d65d1cf71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[10, 10, 6, 8, 18, 10, 4]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "names=sc.parallelize(['Ram','Shatha','Vamsi','kiran','Sai','Krish','veena','vaibhav','veera'])"
      ],
      "metadata": {
        "id": "4bHTKQB0eBMP"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "names.glom().collect()"
      ],
      "metadata": {
        "id": "3gGLN_0zeBJz",
        "outputId": "43d500de-f47c-417c-a7ab-fc86f018dc7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Ram',\n",
              "  'Shatha',\n",
              "  'Vamsi',\n",
              "  'kiran',\n",
              "  'Sai',\n",
              "  'Krish',\n",
              "  'veena',\n",
              "  'vaibhav',\n",
              "  'veera']]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "names=sc.parallelize(['Ram','Shatha','Vamsi','kiran','Sai','Krish','veena','vaibhav','veera'],2)"
      ],
      "metadata": {
        "id": "Px_OncUKeBHJ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "names.glom().collect()"
      ],
      "metadata": {
        "id": "rA6gefjXeBEb",
        "outputId": "e24dee66-25ba-40f6-b3da-92196ce0ac82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Ram', 'Shatha', 'Vamsi', 'kiran'],\n",
              " ['Sai', 'Krish', 'veena', 'vaibhav', 'veera']]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "names.map(lambda a:\"mr.\"+a).collect()\n",
        "#wide transformation is nothing but groupby map() is narrow transformation method"
      ],
      "metadata": {
        "id": "uakJaZKtnpyJ",
        "outputId": "a4485bd3-b209-4f6c-9081-4373f4369e9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['mr.Ram',\n",
              " 'mr.Shatha',\n",
              " 'mr.Vamsi',\n",
              " 'mr.kiran',\n",
              " 'mr.Sai',\n",
              " 'mr.Krish',\n",
              " 'mr.veena',\n",
              " 'mr.vaibhav',\n",
              " 'mr.veera']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#flatmap --use is flatmap is similar to map\n",
        "rdd=sc.parallelize([2,3,4])\n",
        "rdd.collect()\n"
      ],
      "metadata": {
        "id": "h3xAcVzlnpu0",
        "outputId": "fa28d0cd-4a35-4e49-d35b-9dfbdbc0fd37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 3, 4]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a=range(1,3)\n",
        "for i in a:\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "tR3VNpcfnpsE",
        "outputId": "396d6dd3-405a-49b1-e143-bc1bd54c8396",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd.flatMap(lambda x:range(1,x)).collect()"
      ],
      "metadata": {
        "id": "rXhADwjdnppS",
        "outputId": "f7799dec-b68c-4e8c-dfaf-de131d126c99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 1, 2, 1, 2, 3]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Diff map VS flatmap\n",
        "in_rdd=sc.textfile('mapvsflat.csv')\n"
      ],
      "metadata": {
        "id": "RNZjkQJvnpmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "in_rdd.collect()"
      ],
      "metadata": {
        "id": "CnXuDrp-npjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "in_rdd.count()"
      ],
      "metadata": {
        "id": "_bqptf9M0Fse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "map_rdd=in_rdd.map(lambda x:x.split(','))"
      ],
      "metadata": {
        "id": "2aY1FkRW0FpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "map_rdd.collect()"
      ],
      "metadata": {
        "id": "os62DKNH0FmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=map_rdd=in_rdd.map(lambda x:x.split(',')).toDF()"
      ],
      "metadata": {
        "id": "MoWaavek0Fjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "id": "padwdLz_0FhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flat_map=rdd.flatMap(lambda x:x.split(','))"
      ],
      "metadata": {
        "id": "Iox5d2Be0Fen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "in_rdd.collect()"
      ],
      "metadata": {
        "id": "oDOi1FWf0FcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flat_map.collect()"
      ],
      "metadata": {
        "id": "c-9T0zeA0FZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jd5zhy4R0FXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tLli1jL_0FUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1_XB43Rh0FSQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome to Colab",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}