{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramnagella/Demo/blob/master/DA_PS_Day1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#DA with PySpark 30-08-2024--\n",
        "#Installing PySpark ---https://medium.com/@uzzaman.ahmed/setup-pyspark-on-local-machine-and-link-it-with-jupyter-notebook-windows-e08349e792db\n",
        "#Check the concepts of hadoop,bigdata and Spark\n",
        "#Structured  data --RDBMS--SQL,oracle ,mysql---Client/Server arch\n",
        "#Semi Structured----XML,JSON,email,text\n",
        "#un-strcurued -----audio,video,pdf's ,images,animated pictures--hadoop is master/slave arch--multiple Master(controller) nodes and slave nodes\n",
        "#no-sql---mangodb,cassandra,hbase\n",
        "#Any data(SD/SSD/USD) which is beyond the storage and processing capabilities of RDBMS\n",
        "#only 20% data is SD rest 80 % data is SSD and USD\n",
        "#GB means better to use RDBMS ---PB and TB means Bid data -Twitter 30 TB /Month\n",
        "#Velocity means the rate at which data is genrated ---is data mb/sec means RDBMS--GB or TB/Sec means big data\n",
        "#Verocity how far data is reliable ---RDBMS --only SD ---Big data --accepts any type of data\n",
        "#haddop is framework developed by apache opensource\n",
        "#Hadoop horizontal scaling --supports parallel processing and distributed storage --map/reduce programming\n",
        "#Drawback of hadoop is ---hadoop supports batch processing  and HDFS---storage and processing happens in Hard disk\n",
        "#In real time it is difficult--hadoop doesnt support realtime processing of data\n",
        "#Real time data processing --in memory data processing and data processing applications ---master/slave -SPARK better choice -- RDD ---\n",
        "#in SPARK initial read and write happens in hard disk --further reads and writes in memory of the data nodes\n",
        "#intermediate R/W happens from ---RAM --and final writes happens into Hard disk\n",
        "#in real we can cal spark is advanced one of hadoop\n",
        "#Spark supports Resilient distribution dataset---RDD"
      ],
      "metadata": {
        "id": "E33s6I6zRB1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uzEwYjb8RBxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "opreKqO0RBvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZRf59mNKRBs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mlSLzXNlRBqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V-VQMJ9mRBnb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome to Colab",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}